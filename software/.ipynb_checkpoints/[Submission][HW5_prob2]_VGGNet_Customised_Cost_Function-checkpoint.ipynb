{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "    \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *   # bring everything in the folder models\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "\n",
    "model_name = \"vggnet_gamma_x\"\n",
    "model = VGG16()\n",
    "\n",
    "#print(model)\n",
    "        \n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()   ## at the begining of each epoch, this should be reset\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    \n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()  # measure current time\n",
    "    \n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)  # data loading time\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss1 = criterion(output, target)\n",
    "        loss2 = model.features[0].weight.abs().sum()\n",
    "        \n",
    "        #loss = loss1 #only accuracy loss\n",
    "        #loss = loss1 + loss2 #  1:1 accuracy:energy loss\n",
    "        gamma = 1\n",
    "        loss = loss1 + gamma*loss2 # 1:gamma accuracy:energy loss\n",
    "        \n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end) # time spent to process one batch\n",
    "        end = time.time()\n",
    "        \n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Loss1 {loss1:4f}\\t'\n",
    "                  'Loss2 {loss2:.4f}\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, loss1=loss1,loss2=loss2, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            #loss = criterion(output, target)\n",
    "            loss1 = criterion(output, target)\n",
    "            loss2 = model.features[0].weight.abs().sum()\n",
    "            \n",
    "            loss = loss1 #only accuracy loss\n",
    "            #loss = loss1 + loss2 #  1:1 accuracy:energy loss\n",
    "            #gamma = 0.2\n",
    "            #loss = loss1 + gamma*loss2 # 1:gamma accuracy:energy loss\n",
    "            \n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Loss1 {loss1:.4f}\\t'\n",
    "                  'Loss2 {loss2:.4f}\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,loss1=loss1, loss2=loss2,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n    ## n is impact factor\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir, customised_cost_gamma=0):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best and (customised_cost_gamma == 0):\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "    #if is_best and (customised_cost_gamma == 1):\n",
    "    #    shutil.copyfile(filepath, os.path.join(fdir, 'customised_cost_gamma_1.pth.tar'))\n",
    "    #if is_best and (customised_cost_gamma == 2):\n",
    "    #    shutil.copyfile(filepath, os.path.join(fdir, 'customised_cost_gamma_x.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [25, 65]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "#all_params = checkpoint['state_dict']\n",
    "#model.load_state_dict(all_params, strict=False)\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "#validate(testloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter) ## If you run this line, the next data batch is called subsequently.\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-favorite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 1.970 (1.970)\tData 0.332 (0.332)\tLoss 35.8755 (35.8755)\tLoss1 2.539712\tLoss2 166.6788\tPrec 12.500% (12.500%)\n",
      "Epoch: [0][100/391]\tTime 0.024 (0.044)\tData 0.007 (0.008)\tLoss 3.8670 (8.7214)\tLoss1 1.791746\tLoss2 10.3765\tPrec 32.812% (30.128%)\n",
      "Epoch: [0][200/391]\tTime 0.023 (0.034)\tData 0.005 (0.006)\tLoss 3.4716 (6.2210)\tLoss1 1.748529\tLoss2 8.6152\tPrec 34.375% (33.714%)\n",
      "Epoch: [0][300/391]\tTime 0.026 (0.031)\tData 0.008 (0.006)\tLoss 3.3102 (5.3077)\tLoss1 1.692913\tLoss2 8.0865\tPrec 43.750% (36.145%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.355 (0.355)\tLoss 4.4639 (4.4639)\tLoss1 1.7515\tLoss2 13.5620\tPrec 38.281% (38.281%)\n",
      " * Prec 40.800% \n",
      "best acc: 40.800000\n",
      "Epoch: [1][0/391]\tTime 0.467 (0.467)\tData 0.442 (0.442)\tLoss 4.2277 (4.2277)\tLoss1 1.515310\tLoss2 13.5620\tPrec 35.938% (35.938%)\n",
      "Epoch: [1][100/391]\tTime 0.023 (0.028)\tData 0.002 (0.007)\tLoss 3.3544 (3.5980)\tLoss1 1.569272\tLoss2 8.9257\tPrec 36.719% (46.078%)\n",
      "Epoch: [1][200/391]\tTime 0.028 (0.026)\tData 0.010 (0.006)\tLoss 3.5387 (3.5730)\tLoss1 1.623211\tLoss2 9.5774\tPrec 39.844% (47.753%)\n",
      "Epoch: [1][300/391]\tTime 0.023 (0.026)\tData 0.006 (0.006)\tLoss 3.1115 (3.5349)\tLoss1 1.329659\tLoss2 8.9092\tPrec 50.000% (48.705%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.448 (0.448)\tLoss 3.6175 (3.6175)\tLoss1 1.7958\tLoss2 9.1085\tPrec 39.062% (39.062%)\n",
      " * Prec 38.190% \n",
      "best acc: 40.800000\n",
      "Epoch: [2][0/391]\tTime 0.402 (0.402)\tData 0.379 (0.379)\tLoss 3.1772 (3.1772)\tLoss1 1.355536\tLoss2 9.1085\tPrec 53.906% (53.906%)\n",
      "Epoch: [2][100/391]\tTime 0.023 (0.027)\tData 0.002 (0.006)\tLoss 3.1993 (4.1349)\tLoss1 1.336785\tLoss2 9.3125\tPrec 55.469% (53.837%)\n",
      "Epoch: [2][200/391]\tTime 0.023 (0.026)\tData 0.001 (0.006)\tLoss 4.0485 (3.7333)\tLoss1 1.191396\tLoss2 14.2857\tPrec 55.469% (55.422%)\n",
      "Epoch: [2][300/391]\tTime 0.025 (0.025)\tData 0.003 (0.006)\tLoss 3.2280 (3.5679)\tLoss1 1.015692\tLoss2 11.0616\tPrec 64.062% (56.512%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.515 (0.515)\tLoss 3.0333 (3.0333)\tLoss1 1.2307\tLoss2 9.0131\tPrec 57.031% (57.031%)\n",
      " * Prec 57.970% \n",
      "best acc: 57.970000\n",
      "Epoch: [3][0/391]\tTime 0.423 (0.423)\tData 0.404 (0.404)\tLoss 2.8169 (2.8169)\tLoss1 1.014273\tLoss2 9.0131\tPrec 63.281% (63.281%)\n",
      "Epoch: [3][100/391]\tTime 0.029 (0.028)\tData 0.006 (0.008)\tLoss 3.4008 (2.8561)\tLoss1 1.065254\tLoss2 11.6777\tPrec 58.594% (61.564%)\n",
      "Epoch: [3][200/391]\tTime 0.029 (0.027)\tData 0.010 (0.007)\tLoss 4.4514 (3.0271)\tLoss1 1.171077\tLoss2 16.4016\tPrec 57.812% (61.999%)\n",
      "Epoch: [3][300/391]\tTime 0.024 (0.026)\tData 0.007 (0.007)\tLoss 2.5564 (3.0714)\tLoss1 0.761262\tLoss2 8.9759\tPrec 73.438% (62.648%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.377 (0.377)\tLoss 3.1474 (3.1474)\tLoss1 1.4573\tLoss2 8.4506\tPrec 48.438% (48.438%)\n",
      " * Prec 46.560% \n",
      "best acc: 57.970000\n",
      "Epoch: [4][0/391]\tTime 0.371 (0.371)\tData 0.348 (0.348)\tLoss 2.9075 (2.9075)\tLoss1 1.217335\tLoss2 8.4506\tPrec 58.594% (58.594%)\n",
      "Epoch: [4][100/391]\tTime 0.023 (0.027)\tData 0.003 (0.007)\tLoss 3.4694 (3.2601)\tLoss1 0.968860\tLoss2 12.5025\tPrec 62.500% (66.662%)\n",
      "Epoch: [4][200/391]\tTime 0.023 (0.025)\tData 0.003 (0.005)\tLoss 2.8405 (2.9764)\tLoss1 0.780225\tLoss2 10.3015\tPrec 72.656% (66.678%)\n",
      "Epoch: [4][300/391]\tTime 0.024 (0.025)\tData 0.001 (0.006)\tLoss 2.4931 (2.8602)\tLoss1 0.860715\tLoss2 8.1619\tPrec 69.531% (67.190%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.348 (0.348)\tLoss 4.4983 (4.4983)\tLoss1 1.1465\tLoss2 16.7590\tPrec 60.156% (60.156%)\n",
      " * Prec 59.640% \n",
      "best acc: 59.640000\n",
      "Epoch: [5][0/391]\tTime 0.624 (0.624)\tData 0.603 (0.603)\tLoss 4.0441 (4.0441)\tLoss1 0.692255\tLoss2 16.7590\tPrec 78.125% (78.125%)\n",
      "Epoch: [5][100/391]\tTime 0.027 (0.031)\tData 0.010 (0.013)\tLoss 2.7778 (3.1030)\tLoss1 0.975274\tLoss2 9.0128\tPrec 64.844% (69.183%)\n",
      "Epoch: [5][200/391]\tTime 0.024 (0.027)\tData 0.005 (0.009)\tLoss 4.0069 (2.9161)\tLoss1 0.858022\tLoss2 15.7443\tPrec 71.094% (69.523%)\n",
      "Epoch: [5][300/391]\tTime 0.026 (0.026)\tData 0.010 (0.008)\tLoss 2.7506 (2.9286)\tLoss1 0.913017\tLoss2 9.1880\tPrec 70.312% (69.863%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.432 (0.432)\tLoss 3.1504 (3.1504)\tLoss1 1.0395\tLoss2 10.5543\tPrec 65.625% (65.625%)\n",
      " * Prec 64.260% \n",
      "best acc: 64.260000\n",
      "Epoch: [6][0/391]\tTime 0.485 (0.485)\tData 0.467 (0.467)\tLoss 2.8409 (2.8409)\tLoss1 0.730030\tLoss2 10.5543\tPrec 76.562% (76.562%)\n",
      "Epoch: [6][100/391]\tTime 0.023 (0.029)\tData 0.007 (0.009)\tLoss 3.6107 (4.0954)\tLoss1 0.868692\tLoss2 13.7102\tPrec 70.312% (71.829%)\n",
      "Epoch: [6][200/391]\tTime 0.024 (0.026)\tData 0.007 (0.007)\tLoss 2.9102 (3.3397)\tLoss1 0.882081\tLoss2 10.1407\tPrec 69.531% (72.069%)\n",
      "Epoch: [6][300/391]\tTime 0.025 (0.026)\tData 0.008 (0.006)\tLoss 3.2512 (3.1367)\tLoss1 0.736997\tLoss2 12.5709\tPrec 72.656% (72.353%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.518 (0.518)\tLoss 4.0592 (4.0592)\tLoss1 1.2529\tLoss2 14.0312\tPrec 55.469% (55.469%)\n",
      " * Prec 58.280% \n",
      "best acc: 64.260000\n",
      "Epoch: [7][0/391]\tTime 0.684 (0.684)\tData 0.659 (0.659)\tLoss 3.4955 (3.4955)\tLoss1 0.689295\tLoss2 14.0312\tPrec 74.219% (74.219%)\n",
      "Epoch: [7][100/391]\tTime 0.023 (0.031)\tData 0.001 (0.011)\tLoss 3.0864 (2.9819)\tLoss1 0.783244\tLoss2 11.5160\tPrec 71.875% (73.515%)\n",
      "Epoch: [7][200/391]\tTime 0.024 (0.028)\tData 0.006 (0.008)\tLoss 2.2866 (2.7244)\tLoss1 0.680086\tLoss2 8.0324\tPrec 74.219% (73.748%)\n",
      "Epoch: [7][300/391]\tTime 0.024 (0.027)\tData 0.004 (0.007)\tLoss 2.7276 (2.7332)\tLoss1 0.657349\tLoss2 10.3510\tPrec 77.344% (74.019%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.374 (0.374)\tLoss 2.5278 (2.5278)\tLoss1 0.9203\tLoss2 8.0375\tPrec 67.969% (67.969%)\n",
      " * Prec 65.240% \n",
      "best acc: 65.240000\n",
      "Epoch: [8][0/391]\tTime 0.496 (0.496)\tData 0.478 (0.478)\tLoss 2.4276 (2.4276)\tLoss1 0.820059\tLoss2 8.0375\tPrec 69.531% (69.531%)\n",
      "Epoch: [8][100/391]\tTime 0.024 (0.029)\tData 0.005 (0.009)\tLoss 2.2032 (2.4255)\tLoss1 0.649924\tLoss2 7.7664\tPrec 76.562% (75.835%)\n",
      "Epoch: [8][200/391]\tTime 0.023 (0.027)\tData 0.001 (0.007)\tLoss 2.6750 (2.4432)\tLoss1 0.815688\tLoss2 9.2964\tPrec 72.656% (75.937%)\n",
      "Epoch: [8][300/391]\tTime 0.023 (0.026)\tData 0.000 (0.006)\tLoss 3.5642 (2.6621)\tLoss1 0.792246\tLoss2 13.8598\tPrec 72.656% (75.963%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.392 (0.392)\tLoss 2.4964 (2.4964)\tLoss1 0.7701\tLoss2 8.6313\tPrec 74.219% (74.219%)\n",
      " * Prec 69.700% \n",
      "best acc: 69.700000\n",
      "Epoch: [9][0/391]\tTime 0.518 (0.518)\tData 0.492 (0.492)\tLoss 2.4200 (2.4200)\tLoss1 0.693751\tLoss2 8.6313\tPrec 73.438% (73.438%)\n",
      "Epoch: [9][100/391]\tTime 0.023 (0.028)\tData 0.001 (0.007)\tLoss 2.1220 (2.5970)\tLoss1 0.556373\tLoss2 7.8283\tPrec 77.344% (77.460%)\n",
      "Epoch: [9][200/391]\tTime 0.023 (0.026)\tData 0.002 (0.005)\tLoss 2.4254 (2.5526)\tLoss1 0.627203\tLoss2 8.9909\tPrec 76.562% (77.181%)\n",
      "Epoch: [9][300/391]\tTime 0.025 (0.025)\tData 0.002 (0.004)\tLoss 6.4581 (2.9324)\tLoss1 0.746380\tLoss2 28.5584\tPrec 75.000% (77.261%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.355 (0.355)\tLoss 2.5882 (2.5882)\tLoss1 0.6468\tLoss2 9.7069\tPrec 79.688% (79.688%)\n",
      " * Prec 71.430% \n",
      "best acc: 71.430000\n",
      "Epoch: [10][0/391]\tTime 0.412 (0.412)\tData 0.378 (0.378)\tLoss 2.5761 (2.5761)\tLoss1 0.634753\tLoss2 9.7069\tPrec 77.344% (77.344%)\n",
      "Epoch: [10][100/391]\tTime 0.023 (0.028)\tData 0.005 (0.008)\tLoss 2.3197 (3.6037)\tLoss1 0.536567\tLoss2 8.9156\tPrec 78.906% (78.868%)\n",
      "Epoch: [10][200/391]\tTime 0.021 (0.027)\tData 0.002 (0.006)\tLoss 3.2952 (3.0928)\tLoss1 0.693270\tLoss2 13.0096\tPrec 74.219% (78.444%)\n",
      "Epoch: [10][300/391]\tTime 0.024 (0.026)\tData 0.001 (0.005)\tLoss 2.2008 (2.9068)\tLoss1 0.487024\tLoss2 8.5691\tPrec 80.469% (78.509%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.263 (0.263)\tLoss 3.4666 (3.4666)\tLoss1 0.8814\tLoss2 12.9260\tPrec 71.094% (71.094%)\n",
      " * Prec 69.720% \n",
      "best acc: 71.430000\n",
      "Epoch: [11][0/391]\tTime 0.473 (0.473)\tData 0.448 (0.448)\tLoss 3.2584 (3.2584)\tLoss1 0.673215\tLoss2 12.9260\tPrec 78.906% (78.906%)\n",
      "Epoch: [11][100/391]\tTime 0.023 (0.028)\tData 0.002 (0.007)\tLoss 6.8735 (2.8948)\tLoss1 0.592867\tLoss2 31.4034\tPrec 78.906% (79.154%)\n",
      "Epoch: [11][200/391]\tTime 0.024 (0.026)\tData 0.001 (0.005)\tLoss 3.3225 (3.3671)\tLoss1 0.625341\tLoss2 13.4858\tPrec 79.688% (79.454%)\n",
      "Epoch: [11][300/391]\tTime 0.024 (0.026)\tData 0.002 (0.004)\tLoss 2.1015 (3.1729)\tLoss1 0.541284\tLoss2 7.8010\tPrec 80.469% (79.345%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.373 (0.373)\tLoss 2.8210 (2.8210)\tLoss1 1.0560\tLoss2 8.8253\tPrec 66.406% (66.406%)\n",
      " * Prec 62.560% \n",
      "best acc: 71.430000\n",
      "Epoch: [12][0/391]\tTime 0.482 (0.482)\tData 0.457 (0.457)\tLoss 2.1692 (2.1692)\tLoss1 0.404181\tLoss2 8.8253\tPrec 85.156% (85.156%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [12][100/391]\tTime 0.026 (0.029)\tData 0.009 (0.009)\tLoss 2.7734 (2.5930)\tLoss1 0.561801\tLoss2 11.0582\tPrec 81.250% (80.159%)\n",
      "Epoch: [12][200/391]\tTime 0.024 (0.027)\tData 0.002 (0.006)\tLoss 2.1488 (2.4269)\tLoss1 0.634251\tLoss2 7.5730\tPrec 79.688% (80.675%)\n",
      "Epoch: [12][300/391]\tTime 0.025 (0.026)\tData 0.002 (0.005)\tLoss 3.0816 (2.5189)\tLoss1 0.721417\tLoss2 11.8009\tPrec 71.094% (80.552%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.199 (0.199)\tLoss 2.5586 (2.5586)\tLoss1 0.9082\tLoss2 8.2520\tPrec 71.094% (71.094%)\n",
      " * Prec 69.840% \n",
      "best acc: 71.430000\n",
      "Epoch: [13][0/391]\tTime 0.537 (0.537)\tData 0.514 (0.514)\tLoss 2.1887 (2.1887)\tLoss1 0.538275\tLoss2 8.2520\tPrec 81.250% (81.250%)\n",
      "Epoch: [13][100/391]\tTime 0.025 (0.029)\tData 0.002 (0.008)\tLoss 1.9351 (2.1359)\tLoss1 0.483884\tLoss2 7.2560\tPrec 81.250% (81.799%)\n",
      "Epoch: [13][200/391]\tTime 0.025 (0.027)\tData 0.002 (0.005)\tLoss 2.1469 (2.3577)\tLoss1 0.480329\tLoss2 8.3329\tPrec 85.156% (81.456%)\n",
      "Epoch: [13][300/391]\tTime 0.023 (0.026)\tData 0.002 (0.004)\tLoss 3.3025 (2.8919)\tLoss1 0.499822\tLoss2 14.0134\tPrec 82.031% (81.315%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.368 (0.368)\tLoss 2.2956 (2.2956)\tLoss1 0.7049\tLoss2 7.9536\tPrec 78.906% (78.906%)\n",
      " * Prec 74.510% \n",
      "best acc: 74.510000\n",
      "Epoch: [14][0/391]\tTime 0.450 (0.450)\tData 0.431 (0.431)\tLoss 2.0498 (2.0498)\tLoss1 0.459054\tLoss2 7.9536\tPrec 80.469% (80.469%)\n",
      "Epoch: [14][100/391]\tTime 0.024 (0.029)\tData 0.002 (0.008)\tLoss 2.2252 (2.9896)\tLoss1 0.482452\tLoss2 8.7139\tPrec 82.812% (82.673%)\n",
      "Epoch: [14][200/391]\tTime 0.025 (0.027)\tData 0.003 (0.005)\tLoss 1.9983 (2.8700)\tLoss1 0.396523\tLoss2 8.0091\tPrec 86.719% (82.070%)\n",
      "Epoch: [14][300/391]\tTime 0.025 (0.026)\tData 0.002 (0.004)\tLoss 2.3568 (2.6340)\tLoss1 0.570298\tLoss2 8.9326\tPrec 82.812% (82.005%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.394 (0.394)\tLoss 2.2815 (2.2815)\tLoss1 0.6917\tLoss2 7.9489\tPrec 77.344% (77.344%)\n",
      " * Prec 73.200% \n",
      "best acc: 74.510000\n",
      "Epoch: [15][0/391]\tTime 0.665 (0.665)\tData 0.642 (0.642)\tLoss 2.0636 (2.0636)\tLoss1 0.473830\tLoss2 7.9489\tPrec 81.250% (81.250%)\n",
      "Epoch: [15][100/391]\tTime 0.024 (0.030)\tData 0.000 (0.009)\tLoss 3.3647 (2.5794)\tLoss1 0.506144\tLoss2 14.2928\tPrec 81.250% (83.168%)\n",
      "Epoch: [15][200/391]\tTime 0.025 (0.027)\tData 0.005 (0.006)\tLoss 2.9495 (2.5397)\tLoss1 0.474138\tLoss2 12.3769\tPrec 83.594% (83.139%)\n",
      "Epoch: [15][300/391]\tTime 0.027 (0.027)\tData 0.003 (0.005)\tLoss 2.1625 (2.6389)\tLoss1 0.475777\tLoss2 8.4335\tPrec 81.250% (82.740%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.384 (0.384)\tLoss 2.4652 (2.4652)\tLoss1 0.9847\tLoss2 7.4022\tPrec 69.531% (69.531%)\n",
      " * Prec 67.520% \n",
      "best acc: 74.510000\n",
      "Epoch: [16][0/391]\tTime 0.432 (0.432)\tData 0.409 (0.409)\tLoss 2.0023 (2.0023)\tLoss1 0.521816\tLoss2 7.4022\tPrec 83.594% (83.594%)\n",
      "Epoch: [16][100/391]\tTime 0.024 (0.029)\tData 0.003 (0.007)\tLoss 1.9163 (2.0930)\tLoss1 0.442842\tLoss2 7.3674\tPrec 86.719% (84.004%)\n",
      "Epoch: [16][200/391]\tTime 0.025 (0.027)\tData 0.002 (0.005)\tLoss 2.3290 (2.0614)\tLoss1 0.686998\tLoss2 8.2102\tPrec 78.125% (83.928%)\n",
      "Epoch: [16][300/391]\tTime 0.025 (0.026)\tData 0.002 (0.004)\tLoss 2.0464 (2.2070)\tLoss1 0.408677\tLoss2 8.1885\tPrec 87.500% (83.674%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.530 (0.530)\tLoss 2.4965 (2.4965)\tLoss1 0.9567\tLoss2 7.6991\tPrec 69.531% (69.531%)\n",
      " * Prec 70.360% \n",
      "best acc: 74.510000\n",
      "Epoch: [17][0/391]\tTime 0.630 (0.630)\tData 0.612 (0.612)\tLoss 2.0280 (2.0280)\tLoss1 0.488151\tLoss2 7.6991\tPrec 85.156% (85.156%)\n",
      "Epoch: [17][100/391]\tTime 0.025 (0.031)\tData 0.003 (0.009)\tLoss 2.2777 (2.1171)\tLoss1 0.570922\tLoss2 8.5341\tPrec 79.688% (83.810%)\n",
      "Epoch: [17][200/391]\tTime 0.025 (0.028)\tData 0.001 (0.005)\tLoss 2.2051 (2.1677)\tLoss1 0.432419\tLoss2 8.8633\tPrec 85.938% (83.951%)\n",
      "Epoch: [17][300/391]\tTime 0.025 (0.027)\tData 0.002 (0.004)\tLoss 1.9574 (2.2411)\tLoss1 0.418607\tLoss2 7.6940\tPrec 84.375% (83.939%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.296 (0.296)\tLoss 4.1923 (4.1923)\tLoss1 0.7039\tLoss2 17.4417\tPrec 75.000% (75.000%)\n",
      " * Prec 74.340% \n",
      "best acc: 74.510000\n",
      "Epoch: [18][0/391]\tTime 0.586 (0.586)\tData 0.562 (0.562)\tLoss 3.9349 (3.9349)\tLoss1 0.446565\tLoss2 17.4417\tPrec 82.812% (82.812%)\n",
      "Epoch: [18][100/391]\tTime 0.022 (0.030)\tData 0.002 (0.008)\tLoss 3.2920 (2.7470)\tLoss1 0.402984\tLoss2 14.4450\tPrec 84.375% (85.102%)\n",
      "Epoch: [18][200/391]\tTime 0.027 (0.028)\tData 0.002 (0.005)\tLoss 2.3111 (2.4552)\tLoss1 0.374724\tLoss2 9.6817\tPrec 86.719% (84.919%)\n",
      "Epoch: [18][300/391]\tTime 0.025 (0.027)\tData 0.002 (0.004)\tLoss 2.0447 (2.3315)\tLoss1 0.575855\tLoss2 7.3442\tPrec 81.250% (84.793%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.419 (0.419)\tLoss 2.1919 (2.1919)\tLoss1 0.7196\tLoss2 7.3614\tPrec 77.344% (77.344%)\n",
      " * Prec 76.150% \n",
      "best acc: 76.150000\n",
      "Epoch: [19][0/391]\tTime 0.653 (0.653)\tData 0.626 (0.626)\tLoss 1.8281 (1.8281)\tLoss1 0.355782\tLoss2 7.3614\tPrec 86.719% (86.719%)\n",
      "Epoch: [19][100/391]\tTime 0.025 (0.031)\tData 0.002 (0.009)\tLoss 1.9799 (2.3322)\tLoss1 0.259671\tLoss2 8.6013\tPrec 91.406% (86.278%)\n",
      "Epoch: [19][200/391]\tTime 0.025 (0.028)\tData 0.002 (0.005)\tLoss 3.2582 (2.3030)\tLoss1 0.438891\tLoss2 14.0964\tPrec 84.375% (85.662%)\n",
      "Epoch: [19][300/391]\tTime 0.025 (0.027)\tData 0.002 (0.004)\tLoss 2.9631 (2.4169)\tLoss1 0.293903\tLoss2 13.3461\tPrec 89.844% (85.335%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.393 (0.393)\tLoss 2.1388 (2.1388)\tLoss1 0.5985\tLoss2 7.7012\tPrec 83.594% (83.594%)\n",
      " * Prec 76.420% \n",
      "best acc: 76.420000\n",
      "Epoch: [20][0/391]\tTime 0.492 (0.492)\tData 0.479 (0.479)\tLoss 1.8790 (1.8790)\tLoss1 0.338765\tLoss2 7.7012\tPrec 86.719% (86.719%)\n",
      "Epoch: [20][100/391]\tTime 0.022 (0.030)\tData 0.002 (0.007)\tLoss 3.9906 (6.2598)\tLoss1 0.375251\tLoss2 18.0769\tPrec 87.500% (86.054%)\n",
      "Epoch: [20][200/391]\tTime 0.023 (0.028)\tData 0.001 (0.005)\tLoss 2.0385 (4.4827)\tLoss1 0.460716\tLoss2 7.8890\tPrec 85.156% (86.077%)\n",
      "Epoch: [20][300/391]\tTime 0.025 (0.027)\tData 0.002 (0.004)\tLoss 2.2978 (3.8569)\tLoss1 0.291186\tLoss2 10.0331\tPrec 89.844% (85.963%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.364 (0.364)\tLoss 2.8922 (2.8922)\tLoss1 1.4553\tLoss2 7.1846\tPrec 54.688% (54.688%)\n",
      " * Prec 52.260% \n",
      "best acc: 76.420000\n",
      "Epoch: [21][0/391]\tTime 0.629 (0.629)\tData 0.606 (0.606)\tLoss 1.9375 (1.9375)\tLoss1 0.500536\tLoss2 7.1846\tPrec 80.469% (80.469%)\n",
      "Epoch: [21][100/391]\tTime 0.027 (0.031)\tData 0.002 (0.008)\tLoss 1.7615 (2.0455)\tLoss1 0.385367\tLoss2 6.8807\tPrec 85.938% (86.773%)\n",
      "Epoch: [21][200/391]\tTime 0.026 (0.028)\tData 0.009 (0.005)\tLoss 2.0403 (1.9512)\tLoss1 0.315457\tLoss2 8.6244\tPrec 89.062% (86.715%)\n",
      "Epoch: [21][300/391]\tTime 0.025 (0.027)\tData 0.003 (0.004)\tLoss 2.0867 (2.1087)\tLoss1 0.490870\tLoss2 7.9791\tPrec 84.375% (86.446%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.287 (0.287)\tLoss 2.5578 (2.5578)\tLoss1 0.6291\tLoss2 9.6435\tPrec 81.250% (81.250%)\n",
      " * Prec 73.950% \n",
      "best acc: 76.420000\n",
      "Epoch: [22][0/391]\tTime 0.587 (0.587)\tData 0.565 (0.565)\tLoss 2.2202 (2.2202)\tLoss1 0.291549\tLoss2 9.6435\tPrec 90.625% (90.625%)\n",
      "Epoch: [22][100/391]\tTime 0.024 (0.030)\tData 0.003 (0.008)\tLoss 2.2380 (2.3653)\tLoss1 0.415733\tLoss2 9.1115\tPrec 84.375% (86.796%)\n",
      "Epoch: [22][200/391]\tTime 0.025 (0.028)\tData 0.002 (0.005)\tLoss 5.8665 (2.6023)\tLoss1 0.383039\tLoss2 27.4174\tPrec 85.938% (86.684%)\n",
      "Epoch: [22][300/391]\tTime 0.025 (0.027)\tData 0.001 (0.005)\tLoss 1.9512 (2.9854)\tLoss1 0.403159\tLoss2 7.7403\tPrec 84.375% (86.851%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.387 (0.387)\tLoss 2.1585 (2.1585)\tLoss1 0.7644\tLoss2 6.9709\tPrec 77.344% (77.344%)\n",
      " * Prec 72.680% \n",
      "best acc: 76.420000\n",
      "Epoch: [23][0/391]\tTime 0.493 (0.493)\tData 0.470 (0.470)\tLoss 1.8426 (1.8426)\tLoss1 0.448466\tLoss2 6.9709\tPrec 86.719% (86.719%)\n",
      "Epoch: [23][100/391]\tTime 0.024 (0.029)\tData 0.002 (0.007)\tLoss 1.8752 (2.2153)\tLoss1 0.396459\tLoss2 7.3939\tPrec 83.594% (87.794%)\n",
      "Epoch: [23][200/391]\tTime 0.027 (0.027)\tData 0.002 (0.005)\tLoss 1.9658 (2.3808)\tLoss1 0.353853\tLoss2 8.0595\tPrec 85.156% (87.508%)\n",
      "Epoch: [23][300/391]\tTime 0.025 (0.026)\tData 0.001 (0.004)\tLoss 1.9289 (2.2599)\tLoss1 0.497588\tLoss2 7.1565\tPrec 81.250% (87.422%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.379 (0.379)\tLoss 2.2303 (2.2303)\tLoss1 0.7994\tLoss2 7.1546\tPrec 71.875% (71.875%)\n",
      " * Prec 70.460% \n",
      "best acc: 76.420000\n",
      "Epoch: [24][0/391]\tTime 0.557 (0.557)\tData 0.532 (0.532)\tLoss 1.7425 (1.7425)\tLoss1 0.311562\tLoss2 7.1546\tPrec 89.844% (89.844%)\n",
      "Epoch: [24][100/391]\tTime 0.025 (0.030)\tData 0.002 (0.008)\tLoss 2.0818 (1.8336)\tLoss1 0.336863\tLoss2 8.7247\tPrec 89.062% (88.506%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [24][200/391]\tTime 0.025 (0.027)\tData 0.002 (0.005)\tLoss 1.7586 (1.8283)\tLoss1 0.318010\tLoss2 7.2028\tPrec 89.844% (88.293%)\n",
      "Epoch: [24][300/391]\tTime 0.024 (0.026)\tData 0.002 (0.004)\tLoss 1.8596 (2.0129)\tLoss1 0.397657\tLoss2 7.3099\tPrec 89.844% (87.985%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.406 (0.406)\tLoss 9.5642 (9.5642)\tLoss1 0.6360\tLoss2 44.6412\tPrec 79.688% (79.688%)\n",
      " * Prec 79.280% \n",
      "best acc: 79.280000\n",
      "Epoch: [25][0/391]\tTime 0.628 (0.628)\tData 0.603 (0.603)\tLoss 9.3369 (9.3369)\tLoss1 0.408697\tLoss2 44.6412\tPrec 84.375% (84.375%)\n",
      "Epoch: [25][100/391]\tTime 0.031 (0.031)\tData 0.009 (0.011)\tLoss 7.6841 (8.0569)\tLoss1 0.219823\tLoss2 37.3214\tPrec 90.625% (90.787%)\n",
      "Epoch: [25][200/391]\tTime 0.024 (0.028)\tData 0.003 (0.007)\tLoss 7.2841 (7.7811)\tLoss1 0.214545\tLoss2 35.3476\tPrec 92.188% (91.192%)\n",
      "Epoch: [25][300/391]\tTime 0.024 (0.027)\tData 0.002 (0.006)\tLoss 6.8758 (7.5412)\tLoss1 0.284605\tLoss2 32.9557\tPrec 89.062% (91.383%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.325 (0.325)\tLoss 6.7014 (6.7014)\tLoss1 0.4933\tLoss2 31.0405\tPrec 82.031% (82.031%)\n",
      " * Prec 81.200% \n",
      "best acc: 81.200000\n",
      "Epoch: [26][0/391]\tTime 0.476 (0.476)\tData 0.456 (0.456)\tLoss 6.4848 (6.4848)\tLoss1 0.276660\tLoss2 31.0405\tPrec 89.062% (89.062%)\n",
      "Epoch: [26][100/391]\tTime 0.025 (0.028)\tData 0.002 (0.007)\tLoss 6.0540 (6.2252)\tLoss1 0.290758\tLoss2 28.8163\tPrec 91.406% (92.481%)\n",
      "Epoch: [26][200/391]\tTime 0.027 (0.026)\tData 0.000 (0.005)\tLoss 5.6588 (6.0077)\tLoss1 0.292887\tLoss2 26.8294\tPrec 90.625% (92.421%)\n",
      "Epoch: [26][300/391]\tTime 0.022 (0.026)\tData 0.004 (0.004)\tLoss 5.1654 (5.8038)\tLoss1 0.282964\tLoss2 24.4120\tPrec 89.844% (92.372%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.283 (0.283)\tLoss 5.0679 (5.0679)\tLoss1 0.4894\tLoss2 22.8927\tPrec 86.719% (86.719%)\n",
      " * Prec 83.930% \n",
      "best acc: 83.930000\n",
      "Epoch: [27][0/391]\tTime 0.443 (0.443)\tData 0.424 (0.424)\tLoss 4.7562 (4.7562)\tLoss1 0.177641\tLoss2 22.8927\tPrec 93.750% (93.750%)\n",
      "Epoch: [27][100/391]\tTime 0.023 (0.028)\tData 0.004 (0.006)\tLoss 4.2662 (4.5061)\tLoss1 0.170203\tLoss2 20.4799\tPrec 92.188% (92.953%)\n",
      "Epoch: [27][200/391]\tTime 0.024 (0.026)\tData 0.002 (0.004)\tLoss 3.7981 (4.2958)\tLoss1 0.139427\tLoss2 18.2934\tPrec 96.094% (93.151%)\n",
      "Epoch: [27][300/391]\tTime 0.024 (0.026)\tData 0.002 (0.004)\tLoss 3.6434 (4.0874)\tLoss1 0.395051\tLoss2 16.2419\tPrec 86.719% (93.000%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.391 (0.391)\tLoss 3.4389 (3.4389)\tLoss1 0.6033\tLoss2 14.1781\tPrec 84.375% (84.375%)\n",
      " * Prec 81.920% \n",
      "best acc: 83.930000\n",
      "Epoch: [28][0/391]\tTime 0.461 (0.461)\tData 0.437 (0.437)\tLoss 3.0670 (3.0670)\tLoss1 0.231428\tLoss2 14.1781\tPrec 90.625% (90.625%)\n",
      "Epoch: [28][100/391]\tTime 0.023 (0.029)\tData 0.001 (0.008)\tLoss 2.6080 (2.8383)\tLoss1 0.149155\tLoss2 12.2943\tPrec 95.312% (93.123%)\n",
      "Epoch: [28][200/391]\tTime 0.024 (0.027)\tData 0.003 (0.005)\tLoss 2.2435 (2.6342)\tLoss1 0.218099\tLoss2 10.1268\tPrec 92.188% (93.078%)\n",
      "Epoch: [28][300/391]\tTime 0.024 (0.026)\tData 0.001 (0.004)\tLoss 1.8307 (2.4270)\tLoss1 0.205636\tLoss2 8.1253\tPrec 92.969% (93.091%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.287 (0.287)\tLoss 1.8915 (1.8915)\tLoss1 0.5993\tLoss2 6.4609\tPrec 82.031% (82.031%)\n",
      " * Prec 82.170% \n",
      "best acc: 83.930000\n",
      "Epoch: [29][0/391]\tTime 0.554 (0.554)\tData 0.530 (0.530)\tLoss 1.4907 (1.4907)\tLoss1 0.198512\tLoss2 6.4609\tPrec 93.750% (93.750%)\n",
      "Epoch: [29][100/391]\tTime 0.024 (0.029)\tData 0.003 (0.007)\tLoss 1.1247 (1.3023)\tLoss1 0.140383\tLoss2 4.9218\tPrec 96.094% (93.402%)\n",
      "Epoch: [29][200/391]\tTime 0.025 (0.027)\tData 0.002 (0.005)\tLoss 0.9752 (1.1743)\tLoss1 0.195350\tLoss2 3.8993\tPrec 92.969% (93.630%)\n",
      "Epoch: [29][300/391]\tTime 0.024 (0.026)\tData 0.002 (0.004)\tLoss 0.8693 (1.0615)\tLoss1 0.231763\tLoss2 3.1879\tPrec 92.188% (93.742%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.398 (0.398)\tLoss 0.9267 (0.9267)\tLoss1 0.3807\tLoss2 2.7298\tPrec 85.938% (85.938%)\n",
      " * Prec 82.720% \n",
      "best acc: 83.930000\n",
      "Epoch: [30][0/391]\tTime 0.534 (0.534)\tData 0.510 (0.510)\tLoss 0.6608 (0.6608)\tLoss1 0.114873\tLoss2 2.7298\tPrec 94.531% (94.531%)\n",
      "Epoch: [30][100/391]\tTime 0.024 (0.029)\tData 0.002 (0.007)\tLoss 0.5658 (0.6394)\tLoss1 0.181456\tLoss2 1.9216\tPrec 93.750% (93.874%)\n",
      "Epoch: [30][200/391]\tTime 0.026 (0.027)\tData 0.002 (0.005)\tLoss 0.5967 (0.6170)\tLoss1 0.172701\tLoss2 2.1202\tPrec 92.969% (94.022%)\n",
      "Epoch: [30][300/391]\tTime 0.024 (0.026)\tData 0.000 (0.004)\tLoss 0.6922 (0.6229)\tLoss1 0.118162\tLoss2 2.8703\tPrec 95.312% (93.864%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.397 (0.397)\tLoss 1.1991 (1.1991)\tLoss1 0.8314\tLoss2 1.8384\tPrec 75.781% (75.781%)\n",
      " * Prec 71.610% \n",
      "best acc: 83.930000\n",
      "Epoch: [31][0/391]\tTime 0.594 (0.594)\tData 0.571 (0.571)\tLoss 0.5461 (0.5461)\tLoss1 0.178468\tLoss2 1.8384\tPrec 92.969% (92.969%)\n",
      "Epoch: [31][100/391]\tTime 0.025 (0.030)\tData 0.001 (0.008)\tLoss 0.6071 (0.5786)\tLoss1 0.209054\tLoss2 1.9901\tPrec 92.188% (94.276%)\n",
      "Epoch: [31][200/391]\tTime 0.024 (0.027)\tData 0.001 (0.006)\tLoss 0.5606 (0.5843)\tLoss1 0.178669\tLoss2 1.9097\tPrec 95.312% (94.115%)\n",
      "Epoch: [31][300/391]\tTime 0.025 (0.027)\tData 0.002 (0.004)\tLoss 0.6084 (0.5923)\tLoss1 0.172223\tLoss2 2.1809\tPrec 94.531% (94.098%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.192 (0.192)\tLoss 1.0160 (1.0160)\tLoss1 0.5171\tLoss2 2.4945\tPrec 85.938% (85.938%)\n",
      " * Prec 83.320% \n",
      "best acc: 83.930000\n",
      "Epoch: [32][0/391]\tTime 0.657 (0.657)\tData 0.634 (0.634)\tLoss 0.6599 (0.6599)\tLoss1 0.161005\tLoss2 2.4945\tPrec 94.531% (94.531%)\n",
      "Epoch: [32][100/391]\tTime 0.025 (0.031)\tData 0.002 (0.009)\tLoss 0.5035 (0.6281)\tLoss1 0.106520\tLoss2 1.9847\tPrec 97.656% (94.338%)\n",
      "Epoch: [32][200/391]\tTime 0.025 (0.028)\tData 0.005 (0.006)\tLoss 0.5953 (0.6070)\tLoss1 0.180465\tLoss2 2.0743\tPrec 94.531% (94.279%)\n",
      "Epoch: [32][300/391]\tTime 0.025 (0.027)\tData 0.002 (0.005)\tLoss 0.5644 (0.6031)\tLoss1 0.142112\tLoss2 2.1117\tPrec 96.094% (94.295%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.459 (0.459)\tLoss 1.0622 (1.0622)\tLoss1 0.6686\tLoss2 1.9685\tPrec 82.031% (82.031%)\n",
      " * Prec 82.180% \n",
      "best acc: 83.930000\n",
      "Epoch: [33][0/391]\tTime 0.800 (0.800)\tData 0.785 (0.785)\tLoss 0.5284 (0.5284)\tLoss1 0.134700\tLoss2 1.9685\tPrec 92.188% (92.188%)\n",
      "Epoch: [33][100/391]\tTime 0.025 (0.032)\tData 0.003 (0.010)\tLoss 0.5457 (0.5820)\tLoss1 0.157331\tLoss2 1.9416\tPrec 95.312% (94.485%)\n",
      "Epoch: [33][200/391]\tTime 0.025 (0.029)\tData 0.005 (0.007)\tLoss 0.4749 (0.5788)\tLoss1 0.108887\tLoss2 1.8301\tPrec 96.875% (94.500%)\n",
      "Epoch: [33][300/391]\tTime 0.025 (0.027)\tData 0.002 (0.005)\tLoss 0.6425 (0.5804)\tLoss1 0.219877\tLoss2 2.1131\tPrec 91.406% (94.466%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.371 (0.371)\tLoss 1.4133 (1.4133)\tLoss1 1.0411\tLoss2 1.8609\tPrec 67.188% (67.188%)\n",
      " * Prec 70.110% \n",
      "best acc: 83.930000\n",
      "Epoch: [34][0/391]\tTime 0.605 (0.605)\tData 0.581 (0.581)\tLoss 0.5150 (0.5150)\tLoss1 0.142842\tLoss2 1.8609\tPrec 94.531% (94.531%)\n",
      "Epoch: [34][100/391]\tTime 0.025 (0.031)\tData 0.000 (0.010)\tLoss 0.6334 (0.5947)\tLoss1 0.185817\tLoss2 2.2380\tPrec 92.969% (94.307%)\n",
      "Epoch: [34][200/391]\tTime 0.025 (0.028)\tData 0.001 (0.007)\tLoss 0.6131 (0.6055)\tLoss1 0.167335\tLoss2 2.2286\tPrec 93.750% (94.104%)\n",
      "Epoch: [34][300/391]\tTime 0.025 (0.027)\tData 0.003 (0.005)\tLoss 0.4872 (0.6058)\tLoss1 0.102150\tLoss2 1.9254\tPrec 95.312% (94.183%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.474 (0.474)\tLoss 0.8408 (0.8408)\tLoss1 0.4003\tLoss2 2.2029\tPrec 89.062% (89.062%)\n",
      " * Prec 84.310% \n",
      "best acc: 84.310000\n",
      "Epoch: [35][0/391]\tTime 0.440 (0.440)\tData 0.426 (0.426)\tLoss 0.5841 (0.5841)\tLoss1 0.143502\tLoss2 2.2029\tPrec 95.312% (95.312%)\n",
      "Epoch: [35][100/391]\tTime 0.025 (0.029)\tData 0.002 (0.007)\tLoss 0.5665 (0.5977)\tLoss1 0.160284\tLoss2 2.0310\tPrec 95.312% (94.802%)\n",
      "Epoch: [35][200/391]\tTime 0.024 (0.027)\tData 0.005 (0.005)\tLoss 0.5945 (0.5773)\tLoss1 0.118365\tLoss2 2.3809\tPrec 96.094% (94.819%)\n",
      "Epoch: [35][300/391]\tTime 0.024 (0.027)\tData 0.005 (0.005)\tLoss 0.7434 (0.5857)\tLoss1 0.232273\tLoss2 2.5558\tPrec 92.188% (94.739%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.742 (0.742)\tLoss 0.8642 (0.8642)\tLoss1 0.4734\tLoss2 1.9541\tPrec 87.500% (87.500%)\n",
      " * Prec 84.410% \n",
      "best acc: 84.410000\n",
      "Epoch: [36][0/391]\tTime 0.393 (0.393)\tData 0.368 (0.368)\tLoss 0.5342 (0.5342)\tLoss1 0.143417\tLoss2 1.9541\tPrec 94.531% (94.531%)\n",
      "Epoch: [36][100/391]\tTime 0.025 (0.028)\tData 0.002 (0.006)\tLoss 0.5794 (0.6050)\tLoss1 0.157788\tLoss2 2.1080\tPrec 92.969% (94.562%)\n",
      "Epoch: [36][200/391]\tTime 0.025 (0.026)\tData 0.001 (0.005)\tLoss 0.5681 (0.5894)\tLoss1 0.153183\tLoss2 2.0747\tPrec 93.750% (94.675%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [36][300/391]\tTime 0.025 (0.026)\tData 0.004 (0.004)\tLoss 0.6134 (0.5956)\tLoss1 0.149792\tLoss2 2.3183\tPrec 96.094% (94.635%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.459 (0.459)\tLoss 0.9601 (0.9601)\tLoss1 0.5394\tLoss2 2.1033\tPrec 83.594% (83.594%)\n",
      " * Prec 82.180% \n",
      "best acc: 84.410000\n",
      "Epoch: [37][0/391]\tTime 0.439 (0.439)\tData 0.416 (0.416)\tLoss 0.5444 (0.5444)\tLoss1 0.123734\tLoss2 2.1033\tPrec 95.312% (95.312%)\n",
      "Epoch: [37][100/391]\tTime 0.025 (0.029)\tData 0.002 (0.007)\tLoss 0.5207 (0.5874)\tLoss1 0.116944\tLoss2 2.0187\tPrec 96.875% (94.802%)\n",
      "Epoch: [37][200/391]\tTime 0.027 (0.027)\tData 0.000 (0.005)\tLoss 0.6424 (0.5778)\tLoss1 0.172227\tLoss2 2.3510\tPrec 92.969% (94.978%)\n",
      "Epoch: [37][300/391]\tTime 0.025 (0.026)\tData 0.006 (0.004)\tLoss 0.7405 (0.5944)\tLoss1 0.197247\tLoss2 2.7164\tPrec 93.750% (94.900%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.366 (0.366)\tLoss 0.9495 (0.9495)\tLoss1 0.5404\tLoss2 2.0459\tPrec 82.812% (82.812%)\n",
      " * Prec 84.040% \n",
      "best acc: 84.410000\n",
      "Epoch: [38][0/391]\tTime 0.589 (0.589)\tData 0.566 (0.566)\tLoss 0.5023 (0.5023)\tLoss1 0.093119\tLoss2 2.0459\tPrec 96.094% (96.094%)\n",
      "Epoch: [38][100/391]\tTime 0.025 (0.030)\tData 0.001 (0.008)\tLoss 0.5119 (0.5465)\tLoss1 0.100582\tLoss2 2.0567\tPrec 95.312% (95.413%)\n",
      "Epoch: [38][200/391]\tTime 0.025 (0.027)\tData 0.003 (0.005)\tLoss 0.5603 (0.5747)\tLoss1 0.127079\tLoss2 2.1660\tPrec 95.312% (95.161%)\n",
      "Epoch: [38][300/391]\tTime 0.025 (0.026)\tData 0.002 (0.004)\tLoss 0.5007 (0.5777)\tLoss1 0.116269\tLoss2 1.9220\tPrec 94.531% (95.191%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.391 (0.391)\tLoss 0.9389 (0.9389)\tLoss1 0.5442\tLoss2 1.9735\tPrec 81.250% (81.250%)\n",
      " * Prec 80.830% \n",
      "best acc: 84.410000\n",
      "Epoch: [39][0/391]\tTime 0.516 (0.516)\tData 0.495 (0.495)\tLoss 0.5284 (0.5284)\tLoss1 0.133720\tLoss2 1.9735\tPrec 95.312% (95.312%)\n",
      "Epoch: [39][100/391]\tTime 0.025 (0.030)\tData 0.000 (0.008)\tLoss 0.5418 (0.5792)\tLoss1 0.097637\tLoss2 2.2207\tPrec 97.656% (95.050%)\n",
      "Epoch: [39][200/391]\tTime 0.024 (0.027)\tData 0.002 (0.006)\tLoss 0.5618 (0.5739)\tLoss1 0.109002\tLoss2 2.2642\tPrec 96.875% (95.064%)\n",
      "Epoch: [39][300/391]\tTime 0.024 (0.027)\tData 0.002 (0.004)\tLoss 0.5766 (0.5692)\tLoss1 0.170246\tLoss2 2.0317\tPrec 93.750% (95.043%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.407 (0.407)\tLoss 0.7634 (0.7634)\tLoss1 0.4010\tLoss2 1.8122\tPrec 89.062% (89.062%)\n",
      " * Prec 84.240% \n",
      "best acc: 84.410000\n",
      "Epoch: [40][0/391]\tTime 0.445 (0.445)\tData 0.421 (0.421)\tLoss 0.5651 (0.5651)\tLoss1 0.202689\tLoss2 1.8122\tPrec 90.625% (90.625%)\n",
      "Epoch: [40][100/391]\tTime 0.023 (0.031)\tData 0.006 (0.010)\tLoss 0.5288 (0.5591)\tLoss1 0.101615\tLoss2 2.1359\tPrec 96.875% (95.343%)\n",
      "Epoch: [40][200/391]\tTime 0.025 (0.028)\tData 0.002 (0.006)\tLoss 0.5421 (0.5598)\tLoss1 0.129804\tLoss2 2.0617\tPrec 96.094% (95.406%)\n",
      "Epoch: [40][300/391]\tTime 0.025 (0.027)\tData 0.002 (0.005)\tLoss 0.5172 (0.5619)\tLoss1 0.089086\tLoss2 2.1407\tPrec 96.875% (95.284%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.426 (0.426)\tLoss 1.4767 (1.4767)\tLoss1 1.0287\tLoss2 2.2403\tPrec 74.219% (74.219%)\n",
      " * Prec 76.240% \n",
      "best acc: 84.410000\n",
      "Epoch: [41][0/391]\tTime 0.468 (0.468)\tData 0.448 (0.448)\tLoss 0.5004 (0.5004)\tLoss1 0.052293\tLoss2 2.2403\tPrec 98.438% (98.438%)\n",
      "Epoch: [41][100/391]\tTime 0.024 (0.029)\tData 0.001 (0.007)\tLoss 0.5308 (0.5495)\tLoss1 0.123951\tLoss2 2.0345\tPrec 95.312% (95.282%)\n",
      "Epoch: [41][200/391]\tTime 0.024 (0.027)\tData 0.001 (0.005)\tLoss 0.5138 (0.5557)\tLoss1 0.077695\tLoss2 2.1803\tPrec 96.094% (95.340%)\n",
      "Epoch: [41][300/391]\tTime 0.026 (0.026)\tData 0.002 (0.004)\tLoss 0.6382 (0.5513)\tLoss1 0.192348\tLoss2 2.2291\tPrec 95.312% (95.429%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.488 (0.488)\tLoss 1.1165 (1.1165)\tLoss1 0.5837\tLoss2 2.6641\tPrec 83.594% (83.594%)\n",
      " * Prec 83.080% \n",
      "best acc: 84.410000\n",
      "Epoch: [42][0/391]\tTime 0.439 (0.439)\tData 0.414 (0.414)\tLoss 0.6402 (0.6402)\tLoss1 0.107355\tLoss2 2.6641\tPrec 96.875% (96.875%)\n",
      "Epoch: [42][100/391]\tTime 0.025 (0.029)\tData 0.002 (0.006)\tLoss 0.5356 (0.5650)\tLoss1 0.119810\tLoss2 2.0791\tPrec 96.875% (95.606%)\n",
      "Epoch: [42][200/391]\tTime 0.026 (0.027)\tData 0.002 (0.004)\tLoss 0.6394 (0.5528)\tLoss1 0.157302\tLoss2 2.4106\tPrec 93.750% (95.573%)\n",
      "Epoch: [42][300/391]\tTime 0.025 (0.026)\tData 0.002 (0.003)\tLoss 0.6181 (0.5542)\tLoss1 0.130067\tLoss2 2.4403\tPrec 96.094% (95.577%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.291 (0.291)\tLoss 1.0785 (1.0785)\tLoss1 0.6324\tLoss2 2.2304\tPrec 84.375% (84.375%)\n",
      " * Prec 83.920% \n",
      "best acc: 84.410000\n",
      "Epoch: [43][0/391]\tTime 0.487 (0.487)\tData 0.464 (0.464)\tLoss 0.6532 (0.6532)\tLoss1 0.207137\tLoss2 2.2304\tPrec 91.406% (91.406%)\n",
      "Epoch: [43][100/391]\tTime 0.025 (0.029)\tData 0.002 (0.007)\tLoss 0.5155 (0.5329)\tLoss1 0.135335\tLoss2 1.9009\tPrec 97.656% (95.730%)\n",
      "Epoch: [43][200/391]\tTime 0.025 (0.027)\tData 0.002 (0.004)\tLoss 0.5615 (0.5458)\tLoss1 0.097271\tLoss2 2.3210\tPrec 96.875% (95.717%)\n",
      "Epoch: [43][300/391]\tTime 0.025 (0.026)\tData 0.002 (0.004)\tLoss 0.6287 (0.5434)\tLoss1 0.206652\tLoss2 2.1103\tPrec 92.969% (95.710%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.248 (0.248)\tLoss 1.1091 (1.1091)\tLoss1 0.6629\tLoss2 2.2310\tPrec 79.688% (79.688%)\n",
      " * Prec 84.300% \n",
      "best acc: 84.410000\n",
      "Epoch: [44][0/391]\tTime 0.509 (0.509)\tData 0.488 (0.488)\tLoss 0.5228 (0.5228)\tLoss1 0.076569\tLoss2 2.2310\tPrec 96.875% (96.875%)\n",
      "Epoch: [44][100/391]\tTime 0.026 (0.030)\tData 0.004 (0.008)\tLoss 0.5468 (0.5375)\tLoss1 0.139694\tLoss2 2.0354\tPrec 95.312% (96.009%)\n",
      "Epoch: [44][200/391]\tTime 0.024 (0.027)\tData 0.001 (0.005)\tLoss 0.5460 (0.5530)\tLoss1 0.113371\tLoss2 2.1633\tPrec 97.656% (95.915%)\n",
      "Epoch: [44][300/391]\tTime 0.024 (0.026)\tData 0.002 (0.004)\tLoss 0.5129 (0.5607)\tLoss1 0.082054\tLoss2 2.1545\tPrec 96.875% (95.884%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.502 (0.502)\tLoss 1.2482 (1.2482)\tLoss1 0.8387\tLoss2 2.0477\tPrec 79.688% (79.688%)\n",
      " * Prec 80.850% \n",
      "best acc: 84.410000\n",
      "Epoch: [45][0/391]\tTime 0.523 (0.523)\tData 0.498 (0.498)\tLoss 0.6303 (0.6303)\tLoss1 0.220735\tLoss2 2.0477\tPrec 90.625% (90.625%)\n",
      "Epoch: [45][100/391]\tTime 0.025 (0.029)\tData 0.001 (0.007)\tLoss 0.5318 (0.5554)\tLoss1 0.065454\tLoss2 2.3318\tPrec 98.438% (96.032%)\n",
      "Epoch: [45][200/391]\tTime 0.025 (0.027)\tData 0.002 (0.004)\tLoss 0.4879 (0.5422)\tLoss1 0.122368\tLoss2 1.8279\tPrec 95.312% (95.927%)\n",
      "Epoch: [45][300/391]\tTime 0.025 (0.026)\tData 0.000 (0.004)\tLoss 0.5328 (0.5431)\tLoss1 0.120673\tLoss2 2.0606\tPrec 94.531% (95.959%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.488 (0.488)\tLoss 0.8072 (0.8072)\tLoss1 0.4303\tLoss2 1.8844\tPrec 85.156% (85.156%)\n",
      " * Prec 83.610% \n",
      "best acc: 84.410000\n",
      "Epoch: [46][0/391]\tTime 0.614 (0.614)\tData 0.590 (0.590)\tLoss 0.4800 (0.4800)\tLoss1 0.103143\tLoss2 1.8844\tPrec 96.875% (96.875%)\n",
      "Epoch: [46][100/391]\tTime 0.025 (0.030)\tData 0.004 (0.009)\tLoss 0.5668 (0.5548)\tLoss1 0.086125\tLoss2 2.4035\tPrec 96.094% (95.900%)\n",
      "Epoch: [46][200/391]\tTime 0.025 (0.027)\tData 0.002 (0.006)\tLoss 0.4514 (0.5560)\tLoss1 0.083595\tLoss2 1.8389\tPrec 97.656% (96.028%)\n",
      "Epoch: [46][300/391]\tTime 0.026 (0.027)\tData 0.001 (0.005)\tLoss 0.4977 (0.5540)\tLoss1 0.088076\tLoss2 2.0480\tPrec 96.094% (95.961%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.363 (0.363)\tLoss 0.8825 (0.8825)\tLoss1 0.4773\tLoss2 2.0261\tPrec 85.156% (85.156%)\n",
      " * Prec 83.860% \n",
      "best acc: 84.410000\n",
      "Epoch: [47][0/391]\tTime 0.558 (0.558)\tData 0.539 (0.539)\tLoss 0.5325 (0.5325)\tLoss1 0.127264\tLoss2 2.0261\tPrec 95.312% (95.312%)\n",
      "Epoch: [47][100/391]\tTime 0.024 (0.029)\tData 0.001 (0.008)\tLoss 0.5733 (0.5384)\tLoss1 0.091369\tLoss2 2.4099\tPrec 97.656% (96.481%)\n",
      "Epoch: [47][200/391]\tTime 0.025 (0.027)\tData 0.002 (0.005)\tLoss 0.5646 (0.5515)\tLoss1 0.066188\tLoss2 2.4922\tPrec 98.438% (96.346%)\n",
      "Epoch: [47][300/391]\tTime 0.025 (0.026)\tData 0.002 (0.004)\tLoss 0.5711 (0.5459)\tLoss1 0.098132\tLoss2 2.3650\tPrec 97.656% (96.185%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.328 (0.328)\tLoss 1.0509 (1.0509)\tLoss1 0.5775\tLoss2 2.3670\tPrec 82.031% (82.031%)\n",
      " * Prec 80.980% \n",
      "best acc: 84.410000\n",
      "Epoch: [48][0/391]\tTime 0.515 (0.515)\tData 0.493 (0.493)\tLoss 0.5620 (0.5620)\tLoss1 0.088591\tLoss2 2.3670\tPrec 96.875% (96.875%)\n",
      "Epoch: [48][100/391]\tTime 0.024 (0.029)\tData 0.002 (0.008)\tLoss 0.5086 (0.5224)\tLoss1 0.090753\tLoss2 2.0892\tPrec 96.875% (96.287%)\n",
      "Epoch: [48][200/391]\tTime 0.025 (0.027)\tData 0.001 (0.005)\tLoss 0.5112 (0.5199)\tLoss1 0.090949\tLoss2 2.1010\tPrec 95.312% (96.339%)\n",
      "Epoch: [48][300/391]\tTime 0.024 (0.026)\tData 0.001 (0.004)\tLoss 0.5428 (0.5290)\tLoss1 0.085062\tLoss2 2.2886\tPrec 96.875% (96.291%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation starts\n",
      "Test: [0/79]\tTime 0.348 (0.348)\tLoss 1.0681 (1.0681)\tLoss1 0.6253\tLoss2 2.2140\tPrec 84.375% (84.375%)\n",
      " * Prec 83.940% \n",
      "best acc: 84.410000\n",
      "Epoch: [49][0/391]\tTime 0.583 (0.583)\tData 0.564 (0.564)\tLoss 0.5858 (0.5858)\tLoss1 0.142948\tLoss2 2.2140\tPrec 95.312% (95.312%)\n",
      "Epoch: [49][100/391]\tTime 0.024 (0.030)\tData 0.002 (0.008)\tLoss 0.4474 (0.5435)\tLoss1 0.054607\tLoss2 1.9638\tPrec 98.438% (96.279%)\n",
      "Epoch: [49][200/391]\tTime 0.025 (0.027)\tData 0.000 (0.005)\tLoss 0.4864 (0.5252)\tLoss1 0.086178\tLoss2 2.0013\tPrec 96.094% (96.362%)\n",
      "Epoch: [49][300/391]\tTime 0.025 (0.027)\tData 0.002 (0.004)\tLoss 0.5944 (0.5327)\tLoss1 0.096726\tLoss2 2.4884\tPrec 97.656% (96.278%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.346 (0.346)\tLoss 0.9540 (0.9540)\tLoss1 0.4702\tLoss2 2.4190\tPrec 86.719% (86.719%)\n",
      " * Prec 83.320% \n",
      "best acc: 84.410000\n",
      "Epoch: [50][0/391]\tTime 0.601 (0.601)\tData 0.576 (0.576)\tLoss 0.6000 (0.6000)\tLoss1 0.116173\tLoss2 2.4190\tPrec 96.875% (96.875%)\n",
      "Epoch: [50][100/391]\tTime 0.024 (0.030)\tData 0.002 (0.008)\tLoss 0.5218 (0.5176)\tLoss1 0.105429\tLoss2 2.0818\tPrec 96.094% (96.434%)\n",
      "Epoch: [50][200/391]\tTime 0.025 (0.028)\tData 0.002 (0.005)\tLoss 0.5812 (0.5241)\tLoss1 0.070827\tLoss2 2.5519\tPrec 97.656% (96.471%)\n",
      "Epoch: [50][300/391]\tTime 0.025 (0.027)\tData 0.001 (0.004)\tLoss 0.4902 (0.5268)\tLoss1 0.025438\tLoss2 2.3236\tPrec 99.219% (96.335%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.434 (0.434)\tLoss 0.9987 (0.9987)\tLoss1 0.5713\tLoss2 2.1369\tPrec 83.594% (83.594%)\n",
      " * Prec 79.210% \n",
      "best acc: 84.410000\n",
      "Epoch: [51][0/391]\tTime 0.489 (0.489)\tData 0.465 (0.465)\tLoss 0.5713 (0.5713)\tLoss1 0.143868\tLoss2 2.1369\tPrec 94.531% (94.531%)\n",
      "Epoch: [51][100/391]\tTime 0.025 (0.029)\tData 0.002 (0.007)\tLoss 0.5737 (0.5239)\tLoss1 0.096283\tLoss2 2.3869\tPrec 96.875% (96.620%)\n",
      "Epoch: [51][200/391]\tTime 0.027 (0.027)\tData 0.003 (0.004)\tLoss 0.5157 (0.5206)\tLoss1 0.093470\tLoss2 2.1109\tPrec 97.656% (96.502%)\n",
      "Epoch: [51][300/391]\tTime 0.025 (0.026)\tData 0.002 (0.004)\tLoss 0.4708 (0.5174)\tLoss1 0.088676\tLoss2 1.9107\tPrec 99.219% (96.571%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.375 (0.375)\tLoss 1.0090 (1.0090)\tLoss1 0.5063\tLoss2 2.5136\tPrec 85.156% (85.156%)\n",
      " * Prec 85.210% \n",
      "best acc: 85.210000\n",
      "Epoch: [52][0/391]\tTime 0.464 (0.464)\tData 0.437 (0.437)\tLoss 0.5601 (0.5601)\tLoss1 0.057355\tLoss2 2.5136\tPrec 97.656% (97.656%)\n",
      "Epoch: [52][100/391]\tTime 0.024 (0.029)\tData 0.002 (0.006)\tLoss 0.5238 (0.5460)\tLoss1 0.086863\tLoss2 2.1848\tPrec 97.656% (96.535%)\n",
      "Epoch: [52][200/391]\tTime 0.025 (0.027)\tData 0.002 (0.004)\tLoss 0.5056 (0.5378)\tLoss1 0.066101\tLoss2 2.1975\tPrec 96.875% (96.517%)\n",
      "Epoch: [52][300/391]\tTime 0.025 (0.026)\tData 0.001 (0.003)\tLoss 0.4205 (0.5344)\tLoss1 0.035803\tLoss2 1.9234\tPrec 99.219% (96.509%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.375 (0.375)\tLoss 1.0982 (1.0982)\tLoss1 0.6458\tLoss2 2.2620\tPrec 82.812% (82.812%)\n",
      " * Prec 80.040% \n",
      "best acc: 85.210000\n",
      "Epoch: [53][0/391]\tTime 0.460 (0.460)\tData 0.435 (0.435)\tLoss 0.5439 (0.5439)\tLoss1 0.091521\tLoss2 2.2620\tPrec 97.656% (97.656%)\n",
      "Epoch: [53][100/391]\tTime 0.024 (0.029)\tData 0.002 (0.007)\tLoss 0.5238 (0.5135)\tLoss1 0.108968\tLoss2 2.0742\tPrec 96.094% (96.689%)\n",
      "Epoch: [53][200/391]\tTime 0.025 (0.027)\tData 0.002 (0.004)\tLoss 0.5677 (0.5274)\tLoss1 0.103410\tLoss2 2.3214\tPrec 96.875% (96.677%)\n",
      "Epoch: [53][300/391]\tTime 0.026 (0.026)\tData 0.002 (0.004)\tLoss 0.5109 (0.5242)\tLoss1 0.090751\tLoss2 2.1007\tPrec 96.875% (96.628%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.459 (0.459)\tLoss 1.3141 (1.3141)\tLoss1 0.8299\tLoss2 2.4208\tPrec 80.469% (80.469%)\n",
      " * Prec 82.520% \n",
      "best acc: 85.210000\n",
      "Epoch: [54][0/391]\tTime 0.513 (0.513)\tData 0.493 (0.493)\tLoss 0.6021 (0.6021)\tLoss1 0.117967\tLoss2 2.4208\tPrec 96.875% (96.875%)\n",
      "Epoch: [54][100/391]\tTime 0.025 (0.030)\tData 0.000 (0.009)\tLoss 0.5761 (0.5617)\tLoss1 0.065371\tLoss2 2.5538\tPrec 96.875% (96.658%)\n",
      "Epoch: [54][200/391]\tTime 0.024 (0.028)\tData 0.001 (0.006)\tLoss 0.5170 (0.5604)\tLoss1 0.133589\tLoss2 1.9172\tPrec 96.094% (96.587%)\n",
      "Epoch: [54][300/391]\tTime 0.023 (0.027)\tData 0.000 (0.005)\tLoss 0.4692 (0.5597)\tLoss1 0.076355\tLoss2 1.9641\tPrec 96.875% (96.623%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.279 (0.279)\tLoss 1.1656 (1.1656)\tLoss1 0.7267\tLoss2 2.1946\tPrec 82.031% (82.031%)\n",
      " * Prec 82.500% \n",
      "best acc: 85.210000\n",
      "Epoch: [55][0/391]\tTime 0.535 (0.535)\tData 0.512 (0.512)\tLoss 0.4680 (0.4680)\tLoss1 0.029059\tLoss2 2.1946\tPrec 99.219% (99.219%)\n",
      "Epoch: [55][100/391]\tTime 0.025 (0.030)\tData 0.001 (0.007)\tLoss 0.5660 (0.5110)\tLoss1 0.125540\tLoss2 2.2024\tPrec 96.094% (96.697%)\n",
      "Epoch: [55][200/391]\tTime 0.025 (0.027)\tData 0.000 (0.004)\tLoss 0.5052 (0.5155)\tLoss1 0.065197\tLoss2 2.1999\tPrec 97.656% (96.673%)\n",
      "Epoch: [55][300/391]\tTime 0.025 (0.027)\tData 0.001 (0.004)\tLoss 0.4273 (0.5213)\tLoss1 0.062746\tLoss2 1.8225\tPrec 98.438% (96.693%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.383 (0.383)\tLoss 1.0835 (1.0835)\tLoss1 0.6375\tLoss2 2.2300\tPrec 85.156% (85.156%)\n",
      " * Prec 83.170% \n",
      "best acc: 85.210000\n",
      "Epoch: [56][0/391]\tTime 0.500 (0.500)\tData 0.479 (0.479)\tLoss 0.4739 (0.4739)\tLoss1 0.027906\tLoss2 2.2300\tPrec 100.000% (100.000%)\n",
      "Epoch: [56][100/391]\tTime 0.023 (0.029)\tData 0.008 (0.008)\tLoss 0.5809 (0.4972)\tLoss1 0.095927\tLoss2 2.4249\tPrec 97.656% (97.014%)\n",
      "Epoch: [56][200/391]\tTime 0.019 (0.027)\tData 0.002 (0.005)\tLoss 0.4351 (0.5063)\tLoss1 0.052247\tLoss2 1.9142\tPrec 97.656% (97.027%)\n",
      "Epoch: [56][300/391]\tTime 0.024 (0.026)\tData 0.002 (0.004)\tLoss 0.4838 (0.5179)\tLoss1 0.125551\tLoss2 1.7915\tPrec 93.750% (96.859%)\n"
     ]
    }
   ],
   "source": [
    "# This cell is from the website\n",
    "\n",
    "lr = 4e-3\n",
    "weight_decay = 1e-4\n",
    "epochs = 80\n",
    "best_prec = 0\n",
    "\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "# weight decay: for regularization to prevent overfitting\n",
    "\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "    \n",
    "fdir = 'result/'+str(model_name)\n",
    "\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "        \n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6638c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/79]\tTime 0.231 (0.231)\tLoss 0.2937 (0.2937)\tLoss1 0.2937\tLoss2 194.8504\tPrec 95.312% (95.312%)\n",
      " * Prec 91.260% \n",
      "Absolute sum of conv1 weights:  tensor(194.8504, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "##Accuracy wiht Customised cost function\n",
    "fdir = 'result/vggnet/model_best.pth.tar'\n",
    "\n",
    "checkpoint = torch.load(fdir)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "\n",
    "prec = validate(testloader, model, criterion)\n",
    "energy_loss_initial = model.features[0].weight.abs().sum()\n",
    "print(\"Absolute sum of conv1 weights: \", energy_loss_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Accuracy wiht Customised cost function, gamma=1\n",
    "fdir = 'result/vggnet_gamma_1/model_best.pth.tar'\n",
    "\n",
    "checkpoint = torch.load(fdir)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "\n",
    "prec = validate(testloader, model, criterion)\n",
    "energy_loss_gamma_1 = model.features[0].weight.abs().sum()\n",
    "print(\"Absolute sum of conv1 weights: \", energy_loss_gamma_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW\n",
    "\n",
    "#  1. train resnet20 and vgg16 to achieve >90% accuracy \n",
    "#  2. save your trained model in the result folder \n",
    "#  3. Restart your jupyter notebook by \"Kernel - Restart & Clear Output\"\n",
    "#  4. Load your saved model for vgg16 and validate to see the accuracy\n",
    "#  5. such as the last part of \"[W2S2_example2]_CNN_for_MNIST.ipynb\", prehook the input layers of all the conv layers.\n",
    "#  6. from the first prehooked input, compute to get the second prehooked input. \n",
    "#  7. Compare your computed second input vs. the prehooked second input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "interior-oxygen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/79]\tTime 0.228 (0.228)\tLoss 0.5841 (0.5841)\tLoss1 0.5841\tLoss2 0.5295\tPrec 82.031% (82.031%)\n",
      " * Prec 84.190% \n",
      "Absolute sum of conv1 weights:  tensor(0.5295, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "##Accuracy wiht Customised cost function, gamma=x\n",
    "fdir = 'result/vggnet_gamma_x/model_best.pth.tar'\n",
    "\n",
    "checkpoint = torch.load(fdir)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "\n",
    "prec = validate(testloader, model, criterion)\n",
    "energy_loss_gamma_x = model.features[0].weight.abs().sum()\n",
    "print(\"Absolute sum of conv1 weights: \", energy_loss_gamma_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "sorted-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "\n",
    "for layer in model.modules():\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        layer.register_forward_pre_hook(save_output)       ## Input for the module will be grapped\n",
    "        \n",
    "for i, (input, target) in enumerate(trainloader):\n",
    "    input, target = input.cuda(), target.cuda() ## transfer to gpu\n",
    "    output = model(input)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "blond-builder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 32, 32])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_input = save_output.outputs[0][0]\n",
    "my_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45613575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1 = model.features[0](my_input)\n",
    "out2 = model.features[1](out1)\n",
    "my_output = model.features[2](out2)\n",
    "(my_output - save_output.outputs[1][0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518ed9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83ba056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
