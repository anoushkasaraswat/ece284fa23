{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "radical-fifty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "ResNet_Cifar(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantConv2d(\n",
      "          16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (weight_quant): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantConv2d(\n",
      "          32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (weight_quant): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "     \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "    \n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "model_name = \"resnet20_quant_4bit\"\n",
    "model = resnet20_quant()\n",
    "\n",
    "print(model)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [150, 225]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "#all_params = checkpoint['state_dict']\n",
    "#model.load_state_dict(all_params, strict=False)\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "#validate(testloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "junior-reminder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 1.857 (1.857)\tData 0.395 (0.395)\tLoss 2.4027 (2.4027)\tPrec 9.375% (9.375%)\n",
      "Epoch: [0][100/391]\tTime 0.051 (0.065)\tData 0.002 (0.006)\tLoss 1.7648 (1.9438)\tPrec 34.375% (26.485%)\n",
      "Epoch: [0][200/391]\tTime 0.043 (0.059)\tData 0.002 (0.005)\tLoss 1.5944 (1.7695)\tPrec 42.969% (33.524%)\n",
      "Epoch: [0][300/391]\tTime 0.047 (0.056)\tData 0.002 (0.004)\tLoss 1.4068 (1.6573)\tPrec 55.469% (38.131%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.215 (0.215)\tLoss 1.3712 (1.3712)\tPrec 49.219% (49.219%)\n",
      " * Prec 52.710% \n",
      "best acc: 52.710000\n",
      "Epoch: [1][0/391]\tTime 0.453 (0.453)\tData 0.403 (0.403)\tLoss 1.2976 (1.2976)\tPrec 53.125% (53.125%)\n",
      "Epoch: [1][100/391]\tTime 0.060 (0.054)\tData 0.003 (0.007)\tLoss 1.1733 (1.1974)\tPrec 55.469% (56.954%)\n",
      "Epoch: [1][200/391]\tTime 0.054 (0.053)\tData 0.002 (0.005)\tLoss 1.0209 (1.1631)\tPrec 68.750% (58.182%)\n",
      "Epoch: [1][300/391]\tTime 0.058 (0.051)\tData 0.003 (0.004)\tLoss 1.0806 (1.1293)\tPrec 57.812% (59.502%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.217 (0.217)\tLoss 1.1765 (1.1765)\tPrec 58.594% (58.594%)\n",
      " * Prec 57.350% \n",
      "best acc: 57.350000\n",
      "Epoch: [2][0/391]\tTime 0.392 (0.392)\tData 0.330 (0.330)\tLoss 1.0337 (1.0337)\tPrec 64.062% (64.062%)\n",
      "Epoch: [2][100/391]\tTime 0.065 (0.055)\tData 0.003 (0.006)\tLoss 0.9334 (0.9644)\tPrec 69.531% (65.818%)\n",
      "Epoch: [2][200/391]\tTime 0.037 (0.051)\tData 0.002 (0.004)\tLoss 0.8400 (0.9457)\tPrec 70.312% (66.709%)\n",
      "Epoch: [2][300/391]\tTime 0.051 (0.050)\tData 0.002 (0.004)\tLoss 0.9378 (0.9268)\tPrec 65.625% (67.255%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.211 (0.211)\tLoss 0.8153 (0.8153)\tPrec 73.438% (73.438%)\n",
      " * Prec 67.450% \n",
      "best acc: 67.450000\n",
      "Epoch: [3][0/391]\tTime 0.439 (0.439)\tData 0.395 (0.395)\tLoss 0.8534 (0.8534)\tPrec 69.531% (69.531%)\n",
      "Epoch: [3][100/391]\tTime 0.047 (0.055)\tData 0.002 (0.007)\tLoss 0.9157 (0.8350)\tPrec 68.750% (71.272%)\n",
      "Epoch: [3][200/391]\tTime 0.056 (0.051)\tData 0.002 (0.005)\tLoss 0.5479 (0.8080)\tPrec 83.594% (71.661%)\n",
      "Epoch: [3][300/391]\tTime 0.054 (0.051)\tData 0.003 (0.004)\tLoss 0.8124 (0.7972)\tPrec 75.000% (72.101%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.263 (0.263)\tLoss 0.8297 (0.8297)\tPrec 71.094% (71.094%)\n",
      " * Prec 66.720% \n",
      "best acc: 67.450000\n",
      "Epoch: [4][0/391]\tTime 0.509 (0.509)\tData 0.449 (0.449)\tLoss 0.7229 (0.7229)\tPrec 74.219% (74.219%)\n",
      "Epoch: [4][100/391]\tTime 0.052 (0.047)\tData 0.003 (0.007)\tLoss 0.8189 (0.7195)\tPrec 71.875% (74.930%)\n",
      "Epoch: [4][200/391]\tTime 0.055 (0.048)\tData 0.003 (0.005)\tLoss 0.6682 (0.7206)\tPrec 74.219% (74.751%)\n",
      "Epoch: [4][300/391]\tTime 0.063 (0.049)\tData 0.003 (0.004)\tLoss 0.6738 (0.7087)\tPrec 75.781% (75.101%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.223 (0.223)\tLoss 0.7501 (0.7501)\tPrec 73.438% (73.438%)\n",
      " * Prec 70.580% \n",
      "best acc: 70.580000\n",
      "Epoch: [5][0/391]\tTime 0.494 (0.494)\tData 0.430 (0.430)\tLoss 0.7783 (0.7783)\tPrec 72.656% (72.656%)\n",
      "Epoch: [5][100/391]\tTime 0.052 (0.055)\tData 0.002 (0.007)\tLoss 0.7813 (0.6707)\tPrec 72.656% (76.926%)\n",
      "Epoch: [5][200/391]\tTime 0.049 (0.051)\tData 0.002 (0.005)\tLoss 0.6839 (0.6599)\tPrec 75.000% (77.114%)\n",
      "Epoch: [5][300/391]\tTime 0.050 (0.049)\tData 0.002 (0.004)\tLoss 0.5350 (0.6534)\tPrec 78.906% (77.211%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 0.5247 (0.5247)\tPrec 80.469% (80.469%)\n",
      " * Prec 77.420% \n",
      "best acc: 77.420000\n",
      "Epoch: [6][0/391]\tTime 0.487 (0.487)\tData 0.422 (0.422)\tLoss 0.5607 (0.5607)\tPrec 81.250% (81.250%)\n",
      "Epoch: [6][100/391]\tTime 0.036 (0.049)\tData 0.002 (0.006)\tLoss 0.7723 (0.6014)\tPrec 68.750% (78.852%)\n",
      "Epoch: [6][200/391]\tTime 0.043 (0.048)\tData 0.002 (0.004)\tLoss 0.6174 (0.6090)\tPrec 82.031% (78.961%)\n",
      "Epoch: [6][300/391]\tTime 0.051 (0.049)\tData 0.002 (0.004)\tLoss 0.6268 (0.6126)\tPrec 80.469% (78.867%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.236 (0.236)\tLoss 0.6025 (0.6025)\tPrec 82.031% (82.031%)\n",
      " * Prec 77.080% \n",
      "best acc: 77.420000\n",
      "Epoch: [7][0/391]\tTime 0.521 (0.521)\tData 0.460 (0.460)\tLoss 0.5820 (0.5820)\tPrec 84.375% (84.375%)\n",
      "Epoch: [7][100/391]\tTime 0.042 (0.049)\tData 0.002 (0.007)\tLoss 0.6089 (0.5760)\tPrec 76.562% (80.268%)\n",
      "Epoch: [7][200/391]\tTime 0.037 (0.046)\tData 0.002 (0.005)\tLoss 0.7506 (0.5679)\tPrec 72.656% (80.539%)\n",
      "Epoch: [7][300/391]\tTime 0.045 (0.046)\tData 0.003 (0.004)\tLoss 0.3566 (0.5694)\tPrec 83.594% (80.310%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.306 (0.306)\tLoss 0.5845 (0.5845)\tPrec 73.438% (73.438%)\n",
      " * Prec 76.920% \n",
      "best acc: 77.420000\n",
      "Epoch: [8][0/391]\tTime 0.609 (0.609)\tData 0.545 (0.545)\tLoss 0.4661 (0.4661)\tPrec 85.156% (85.156%)\n",
      "Epoch: [8][100/391]\tTime 0.035 (0.050)\tData 0.002 (0.008)\tLoss 0.4531 (0.5416)\tPrec 86.719% (81.389%)\n",
      "Epoch: [8][200/391]\tTime 0.046 (0.047)\tData 0.002 (0.005)\tLoss 0.3353 (0.5416)\tPrec 88.281% (81.102%)\n",
      "Epoch: [8][300/391]\tTime 0.038 (0.046)\tData 0.002 (0.004)\tLoss 0.5937 (0.5483)\tPrec 75.000% (80.837%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.359 (0.359)\tLoss 0.5396 (0.5396)\tPrec 80.469% (80.469%)\n",
      " * Prec 77.390% \n",
      "best acc: 77.420000\n",
      "Epoch: [9][0/391]\tTime 0.538 (0.538)\tData 0.475 (0.475)\tLoss 0.4401 (0.4401)\tPrec 86.719% (86.719%)\n",
      "Epoch: [9][100/391]\tTime 0.048 (0.049)\tData 0.002 (0.007)\tLoss 0.4893 (0.5257)\tPrec 80.469% (81.923%)\n",
      "Epoch: [9][200/391]\tTime 0.039 (0.046)\tData 0.001 (0.005)\tLoss 0.5250 (0.5229)\tPrec 80.469% (81.934%)\n",
      "Epoch: [9][300/391]\tTime 0.042 (0.045)\tData 0.002 (0.004)\tLoss 0.4687 (0.5176)\tPrec 82.812% (82.107%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.253 (0.253)\tLoss 0.4815 (0.4815)\tPrec 80.469% (80.469%)\n",
      " * Prec 78.080% \n",
      "best acc: 78.080000\n",
      "Epoch: [10][0/391]\tTime 0.602 (0.602)\tData 0.543 (0.543)\tLoss 0.6719 (0.6719)\tPrec 75.000% (75.000%)\n",
      "Epoch: [10][100/391]\tTime 0.038 (0.052)\tData 0.003 (0.008)\tLoss 0.4705 (0.4912)\tPrec 82.031% (82.488%)\n",
      "Epoch: [10][200/391]\tTime 0.049 (0.048)\tData 0.003 (0.005)\tLoss 0.5954 (0.4867)\tPrec 78.906% (82.847%)\n",
      "Epoch: [10][300/391]\tTime 0.044 (0.047)\tData 0.002 (0.004)\tLoss 0.5393 (0.4935)\tPrec 76.562% (82.685%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.279 (0.279)\tLoss 0.4111 (0.4111)\tPrec 83.594% (83.594%)\n",
      " * Prec 80.500% \n",
      "best acc: 80.500000\n",
      "Epoch: [11][0/391]\tTime 0.527 (0.527)\tData 0.470 (0.470)\tLoss 0.4137 (0.4137)\tPrec 83.594% (83.594%)\n",
      "Epoch: [11][100/391]\tTime 0.060 (0.049)\tData 0.003 (0.007)\tLoss 0.4899 (0.4792)\tPrec 82.812% (83.308%)\n",
      "Epoch: [11][200/391]\tTime 0.044 (0.046)\tData 0.002 (0.005)\tLoss 0.4851 (0.4757)\tPrec 82.031% (83.357%)\n",
      "Epoch: [11][300/391]\tTime 0.039 (0.045)\tData 0.002 (0.004)\tLoss 0.4134 (0.4793)\tPrec 85.938% (83.345%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.452 (0.452)\tLoss 0.6504 (0.6504)\tPrec 76.562% (76.562%)\n",
      " * Prec 78.350% \n",
      "best acc: 80.500000\n",
      "Epoch: [12][0/391]\tTime 0.537 (0.537)\tData 0.492 (0.492)\tLoss 0.4765 (0.4765)\tPrec 85.156% (85.156%)\n",
      "Epoch: [12][100/391]\tTime 0.026 (0.048)\tData 0.002 (0.007)\tLoss 0.3103 (0.4516)\tPrec 88.281% (84.336%)\n",
      "Epoch: [12][200/391]\tTime 0.040 (0.038)\tData 0.002 (0.004)\tLoss 0.3648 (0.4517)\tPrec 89.062% (84.220%)\n",
      "Epoch: [12][300/391]\tTime 0.036 (0.040)\tData 0.002 (0.004)\tLoss 0.4807 (0.4545)\tPrec 82.812% (84.235%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.337 (0.337)\tLoss 0.4096 (0.4096)\tPrec 84.375% (84.375%)\n",
      " * Prec 79.780% \n",
      "best acc: 80.500000\n",
      "Epoch: [13][0/391]\tTime 0.758 (0.758)\tData 0.697 (0.697)\tLoss 0.3255 (0.3255)\tPrec 85.156% (85.156%)\n",
      "Epoch: [13][100/391]\tTime 0.041 (0.052)\tData 0.002 (0.009)\tLoss 0.5453 (0.4469)\tPrec 80.469% (84.661%)\n",
      "Epoch: [13][200/391]\tTime 0.047 (0.048)\tData 0.002 (0.006)\tLoss 0.5171 (0.4509)\tPrec 79.688% (84.379%)\n",
      "Epoch: [13][300/391]\tTime 0.041 (0.047)\tData 0.002 (0.005)\tLoss 0.4282 (0.4450)\tPrec 84.375% (84.531%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.480 (0.480)\tLoss 0.4174 (0.4174)\tPrec 85.938% (85.938%)\n",
      " * Prec 82.210% \n",
      "best acc: 82.210000\n",
      "Epoch: [14][0/391]\tTime 0.532 (0.532)\tData 0.481 (0.481)\tLoss 0.3776 (0.3776)\tPrec 88.281% (88.281%)\n",
      "Epoch: [14][100/391]\tTime 0.050 (0.050)\tData 0.003 (0.007)\tLoss 0.3907 (0.4173)\tPrec 85.156% (85.195%)\n",
      "Epoch: [14][200/391]\tTime 0.039 (0.048)\tData 0.003 (0.005)\tLoss 0.4925 (0.4262)\tPrec 85.156% (85.250%)\n",
      "Epoch: [14][300/391]\tTime 0.054 (0.047)\tData 0.003 (0.004)\tLoss 0.3957 (0.4256)\tPrec 84.375% (85.278%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.284 (0.284)\tLoss 0.6175 (0.6175)\tPrec 76.562% (76.562%)\n",
      " * Prec 77.890% \n",
      "best acc: 82.210000\n",
      "Epoch: [15][0/391]\tTime 0.438 (0.438)\tData 0.378 (0.378)\tLoss 0.4827 (0.4827)\tPrec 85.156% (85.156%)\n",
      "Epoch: [15][100/391]\tTime 0.041 (0.047)\tData 0.002 (0.006)\tLoss 0.4218 (0.4241)\tPrec 85.938% (85.427%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15][200/391]\tTime 0.047 (0.046)\tData 0.002 (0.004)\tLoss 0.3556 (0.4192)\tPrec 86.719% (85.592%)\n",
      "Epoch: [15][300/391]\tTime 0.052 (0.046)\tData 0.002 (0.004)\tLoss 0.4418 (0.4200)\tPrec 83.594% (85.569%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.472 (0.472)\tLoss 0.7146 (0.7146)\tPrec 75.781% (75.781%)\n",
      " * Prec 76.980% \n",
      "best acc: 82.210000\n",
      "Epoch: [16][0/391]\tTime 0.511 (0.511)\tData 0.454 (0.454)\tLoss 0.4209 (0.4209)\tPrec 87.500% (87.500%)\n",
      "Epoch: [16][100/391]\tTime 0.049 (0.050)\tData 0.002 (0.007)\tLoss 0.3505 (0.3928)\tPrec 90.625% (86.425%)\n",
      "Epoch: [16][200/391]\tTime 0.051 (0.047)\tData 0.003 (0.005)\tLoss 0.5026 (0.3955)\tPrec 79.688% (86.315%)\n",
      "Epoch: [16][300/391]\tTime 0.045 (0.046)\tData 0.002 (0.004)\tLoss 0.4013 (0.4006)\tPrec 90.625% (86.091%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.389 (0.389)\tLoss 0.4487 (0.4487)\tPrec 89.844% (89.844%)\n",
      " * Prec 82.570% \n",
      "best acc: 82.570000\n",
      "Epoch: [17][0/391]\tTime 0.734 (0.734)\tData 0.673 (0.673)\tLoss 0.3904 (0.3904)\tPrec 87.500% (87.500%)\n",
      "Epoch: [17][100/391]\tTime 0.062 (0.056)\tData 0.003 (0.009)\tLoss 0.3978 (0.3879)\tPrec 83.594% (86.680%)\n",
      "Epoch: [17][200/391]\tTime 0.055 (0.052)\tData 0.003 (0.006)\tLoss 0.3850 (0.3913)\tPrec 86.719% (86.357%)\n",
      "Epoch: [17][300/391]\tTime 0.047 (0.050)\tData 0.003 (0.005)\tLoss 0.4373 (0.3929)\tPrec 82.812% (86.345%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.234 (0.234)\tLoss 0.6211 (0.6211)\tPrec 83.594% (83.594%)\n",
      " * Prec 79.910% \n",
      "best acc: 82.570000\n",
      "Epoch: [18][0/391]\tTime 0.455 (0.455)\tData 0.397 (0.397)\tLoss 0.4089 (0.4089)\tPrec 87.500% (87.500%)\n",
      "Epoch: [18][100/391]\tTime 0.043 (0.051)\tData 0.003 (0.006)\tLoss 0.3026 (0.3757)\tPrec 89.844% (86.750%)\n",
      "Epoch: [18][200/391]\tTime 0.035 (0.048)\tData 0.002 (0.004)\tLoss 0.4891 (0.3785)\tPrec 82.812% (86.789%)\n",
      "Epoch: [18][300/391]\tTime 0.042 (0.047)\tData 0.001 (0.004)\tLoss 0.4195 (0.3800)\tPrec 88.281% (86.833%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.206 (0.206)\tLoss 0.3451 (0.3451)\tPrec 89.062% (89.062%)\n",
      " * Prec 82.850% \n",
      "best acc: 82.850000\n",
      "Epoch: [19][0/391]\tTime 0.468 (0.468)\tData 0.407 (0.407)\tLoss 0.2827 (0.2827)\tPrec 89.062% (89.062%)\n",
      "Epoch: [19][100/391]\tTime 0.035 (0.052)\tData 0.002 (0.007)\tLoss 0.2891 (0.3655)\tPrec 92.188% (87.307%)\n",
      "Epoch: [19][200/391]\tTime 0.053 (0.049)\tData 0.004 (0.005)\tLoss 0.3591 (0.3700)\tPrec 87.500% (87.104%)\n",
      "Epoch: [19][300/391]\tTime 0.053 (0.048)\tData 0.002 (0.004)\tLoss 0.3081 (0.3726)\tPrec 89.844% (86.968%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.242 (0.242)\tLoss 0.4028 (0.4028)\tPrec 86.719% (86.719%)\n",
      " * Prec 84.170% \n",
      "best acc: 84.170000\n"
     ]
    }
   ],
   "source": [
    "# This cell won't be given, but students will complete the training\n",
    "\n",
    "lr = 4e-2\n",
    "weight_decay = 1e-4\n",
    "epochs = 20\n",
    "best_prec = 0\n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "#cudnn.benchmark = True\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "fdir = 'result/'+str(model_name)\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "        \n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW\n",
    "\n",
    "#  1. Train with 4 bits for both weight and activation to achieve >90% accuracy\n",
    "#  2. Find x_int and w_int for the 2nd convolution layer\n",
    "#  3. Check the recovered psum has similar value to the un-quantized original psum\n",
    "#     (such as example 1 in W3S2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "entertaining-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 8417/10000 (84%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = \"result/\"+str(model_name)+\"/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceramic-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicBlock(\n",
      "  (conv1): QuantConv2d(\n",
      "    16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "    (weight_quant): weight_quantize_fn()\n",
      "  )\n",
      "  (conv2): QuantConv2d(\n",
      "    16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "    (weight_quant): weight_quantize_fn()\n",
      "  )\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#send an input and grap the value by using prehook like HW3\n",
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "print(model.layer1[0])\n",
    "model.layer1[0].conv1.register_forward_pre_hook(save_output)       ## Input for the module will be grapped\n",
    "model.layer1[1].conv1.register_forward_pre_hook(save_output)   \n",
    "        \n",
    "for i, (input, target) in enumerate(trainloader):\n",
    "    input, target = input.cuda(), target.cuda() ## transfer to gpu\n",
    "    output = model(input)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spoken-worst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-3.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000, -4.0000,  2.0000],\n",
      "          [-1.0000,  3.0000,  1.0000]],\n",
      "\n",
      "         [[-1.0000, -3.0000,  1.0000],\n",
      "          [-3.0000, -4.0000, -1.0000],\n",
      "          [ 1.0000,  4.0000,  1.0000]],\n",
      "\n",
      "         [[-1.0000, -4.0000,  1.0000],\n",
      "          [-0.0000,  0.0000,  2.0000],\n",
      "          [ 1.0000, -2.0000, -1.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.0000, -7.0000, -0.0000],\n",
      "          [-7.0000,  7.0000,  2.0000],\n",
      "          [ 7.0000, -7.0000, -3.0000]],\n",
      "\n",
      "         [[-1.0000,  1.0000,  2.0000],\n",
      "          [ 2.0000, -5.0000, -1.0000],\n",
      "          [ 1.0000,  3.0000,  1.0000]],\n",
      "\n",
      "         [[ 2.0000,  1.0000,  1.0000],\n",
      "          [-1.0000, -5.0000, -5.0000],\n",
      "          [-3.0000, -2.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000,  1.0000, -0.0000],\n",
      "          [-4.0000, -1.0000,  0.0000],\n",
      "          [-3.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[ 0.0000, -3.0000,  0.0000],\n",
      "          [ 0.0000, -1.0000,  2.0000],\n",
      "          [ 4.0000,  2.0000,  1.0000]],\n",
      "\n",
      "         [[-2.0000,  0.0000,  4.0000],\n",
      "          [-1.0000,  1.0000, -1.0000],\n",
      "          [-3.0000,  2.0000,  1.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0000, -5.0000,  5.0000],\n",
      "          [ 3.0000, -6.0000,  2.0000],\n",
      "          [-3.0000, -6.0000,  1.0000]],\n",
      "\n",
      "         [[ 2.0000,  1.0000, -3.0000],\n",
      "          [-3.0000,  2.0000, -4.0000],\n",
      "          [-1.0000,  4.0000, -6.0000]],\n",
      "\n",
      "         [[ 1.0000,  4.0000, -1.0000],\n",
      "          [-5.0000, -5.0000, -1.0000],\n",
      "          [-3.0000, -1.0000, -2.0000]]],\n",
      "\n",
      "\n",
      "        [[[-2.0000, -4.0000, -4.0000],\n",
      "          [ 2.0000,  1.0000,  2.0000],\n",
      "          [ 0.0000, -2.0000, -3.0000]],\n",
      "\n",
      "         [[ 1.0000, -1.0000, -1.0000],\n",
      "          [ 7.0000,  0.0000, -2.0000],\n",
      "          [ 2.0000,  0.0000, -1.0000]],\n",
      "\n",
      "         [[ 3.0000,  3.0000,  1.0000],\n",
      "          [-0.0000,  2.0000,  4.0000],\n",
      "          [-3.0000, -3.0000, -2.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0000,  2.0000, -2.0000],\n",
      "          [-1.0000, -2.0000, -1.0000],\n",
      "          [ 3.0000,  4.0000,  5.0000]],\n",
      "\n",
      "         [[-4.0000, -0.0000,  0.0000],\n",
      "          [ 6.0000,  1.0000,  2.0000],\n",
      "          [-1.0000, -2.0000, -0.0000]],\n",
      "\n",
      "         [[-2.0000, -5.0000, -4.0000],\n",
      "          [-2.0000, -4.0000, -2.0000],\n",
      "          [-1.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.0000, -2.0000, -1.0000],\n",
      "          [-4.0000, -0.0000,  0.0000],\n",
      "          [-3.0000, -1.0000, -2.0000]],\n",
      "\n",
      "         [[ 1.0000, -0.0000, -2.0000],\n",
      "          [ 0.0000,  4.0000, -1.0000],\n",
      "          [-0.0000,  2.0000, -0.0000]],\n",
      "\n",
      "         [[-2.0000,  3.0000,  1.0000],\n",
      "          [ 2.0000, -0.0000,  5.0000],\n",
      "          [-1.0000, -1.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.0000, -1.0000,  4.0000],\n",
      "          [-1.0000, -4.0000, -1.0000],\n",
      "          [-5.0000,  0.0000, -5.0000]],\n",
      "\n",
      "         [[-4.0000, -3.0000, -5.0000],\n",
      "          [ 4.0000,  7.0000,  2.0000],\n",
      "          [ 3.0000,  1.0000,  3.0000]],\n",
      "\n",
      "         [[ 3.0000, -0.0000, -4.0000],\n",
      "          [ 1.0000, -1.0000,  1.0000],\n",
      "          [-3.0000, -4.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -2.0000,  2.0000],\n",
      "          [ 1.0000,  1.0000,  3.0000],\n",
      "          [ 5.0000,  2.0000,  5.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  0.0000],\n",
      "          [ 1.0000, -2.0000, -2.0000],\n",
      "          [-0.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000, -1.0000,  2.0000],\n",
      "          [ 4.0000,  6.0000,  0.0000],\n",
      "          [ 3.0000,  5.0000,  1.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0000, -1.0000, -1.0000],\n",
      "          [ 1.0000,  2.0000, -0.0000],\n",
      "          [-3.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[-1.0000,  1.0000,  3.0000],\n",
      "          [ 1.0000,  3.0000,  0.0000],\n",
      "          [ 3.0000,  2.0000, -2.0000]],\n",
      "\n",
      "         [[-1.0000,  2.0000, -1.0000],\n",
      "          [ 2.0000, -1.0000, -5.0000],\n",
      "          [ 2.0000,  0.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000,  1.0000,  0.0000],\n",
      "          [ 1.0000,  1.0000, -1.0000],\n",
      "          [ 2.0000,  1.0000, -2.0000]],\n",
      "\n",
      "         [[-5.0000,  1.0000,  5.0000],\n",
      "          [-0.0000, -0.0000, -1.0000],\n",
      "          [-4.0000, -3.0000, -1.0000]],\n",
      "\n",
      "         [[-4.0000, -5.0000, -0.0000],\n",
      "          [-3.0000, -4.0000, -1.0000],\n",
      "          [ 1.0000,  2.0000,  6.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.0000, -5.0000,  0.0000],\n",
      "          [-1.0000,  4.0000, -7.0000],\n",
      "          [-2.0000, -7.0000,  7.0000]],\n",
      "\n",
      "         [[ 1.0000, -5.0000, -2.0000],\n",
      "          [-3.0000, -6.0000, -4.0000],\n",
      "          [-3.0000, -6.0000, -3.0000]],\n",
      "\n",
      "         [[-0.0000,  1.0000, -0.0000],\n",
      "          [-1.0000,  1.0000,  2.0000],\n",
      "          [-3.0000,  2.0000, -1.0000]]]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "w_bit = 4\n",
    "weight_q = model.layer1[0].conv1.weight_q # quantized value is stored during the training\n",
    "w_alpha = model.layer1[0].conv1.weight_quant.wgt_alpha.data.item()   # alpha is defined in your model already. bring it out here\n",
    "w_delta = w_alpha/(2**(w_bit-1)-1)   # delta can be calculated by using alpha and w_bit\n",
    "weight_int = weight_q/w_delta # w_int can be calculated by weight_q and w_delta\n",
    "print(weight_int) # you should see clean integer numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "interior-oxygen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  3.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  3.0000,  0.0000,  2.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  4.0000,  3.0000,  2.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 1.0000,  2.0000,  2.0000,  ...,  2.0000,  2.0000,  0.0000]],\n",
      "\n",
      "         [[ 4.0000,  9.0000, 11.0000,  ...,  0.0000,  2.0000,  2.0000],\n",
      "          [ 0.0000,  2.0000,  6.0000,  ...,  1.0000,  1.0000,  0.0000],\n",
      "          [ 0.0000,  2.0000,  6.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  2.0000,  3.0000,  ...,  4.0000,  3.0000,  6.0000],\n",
      "          [ 0.0000,  2.0000,  3.0000,  ...,  6.0000,  6.0000,  9.0000],\n",
      "          [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  2.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  3.0000,  0.0000,  ...,  1.0000,  1.0000,  3.0000],\n",
      "          [ 1.0000,  3.0000,  0.0000,  ...,  2.0000,  4.0000,  4.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  3.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 1.0000,  3.0000,  1.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 6.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000,  3.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[15.0000,  3.0000, 11.0000,  ...,  0.0000, 15.0000,  0.0000],\n",
      "          [15.0000,  3.0000, 12.0000,  ..., 15.0000,  7.0000,  0.0000],\n",
      "          [15.0000,  3.0000, 12.0000,  ..., 15.0000,  0.0000,  9.0000],\n",
      "          ...,\n",
      "          [15.0000,  3.0000,  8.0000,  ...,  5.0000,  5.0000, 11.0000],\n",
      "          [15.0000,  3.0000,  4.0000,  ...,  4.0000,  4.0000, 12.0000],\n",
      "          [15.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  9.0000]],\n",
      "\n",
      "         [[ 0.0000,  1.0000,  4.0000,  ...,  3.0000,  0.0000,  8.0000],\n",
      "          [ 0.0000,  3.0000,  6.0000,  ...,  0.0000,  1.0000,  9.0000],\n",
      "          [ 0.0000,  3.0000,  7.0000,  ...,  0.0000,  6.0000,  2.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  3.0000,  6.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 0.0000,  3.0000,  4.0000,  ...,  2.0000,  2.0000,  4.0000],\n",
      "          [ 0.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000, 11.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  2.0000,  0.0000,  4.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  2.0000,  2.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  3.0000,  4.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 1.0000,  2.0000,  2.0000,  ...,  2.0000,  2.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  2.0000,  4.0000,  ...,  6.0000,  6.0000,  5.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  5.0000,  4.0000,  5.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  5.0000,  5.0000,  5.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 1.0000,  2.0000,  2.0000,  ...,  2.0000,  2.0000,  0.0000]],\n",
      "\n",
      "         [[ 7.0000,  7.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 3.0000,  5.0000,  6.0000,  ...,  1.0000,  1.0000,  0.0000],\n",
      "          [ 3.0000,  5.0000,  6.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  3.0000,  3.0000,  ...,  8.0000,  8.0000, 10.0000],\n",
      "          [ 0.0000,  2.0000,  2.0000,  ...,  2.0000,  2.0000,  5.0000],\n",
      "          [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  3.0000,  ...,  5.0000,  6.0000,  7.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  2.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  2.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  2.0000,  1.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 1.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  0.0000],\n",
      "          [ 6.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000,  3.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[15.0000,  0.0000,  5.0000,  ...,  2.0000,  3.0000,  0.0000],\n",
      "          [15.0000,  0.0000,  6.0000,  ...,  6.0000,  6.0000,  1.0000],\n",
      "          [15.0000,  0.0000,  2.0000,  ...,  8.0000,  6.0000,  0.0000],\n",
      "          ...,\n",
      "          [15.0000,  4.0000,  4.0000,  ...,  3.0000,  3.0000, 11.0000],\n",
      "          [15.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000, 12.0000],\n",
      "          [15.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  9.0000]],\n",
      "\n",
      "         [[ 0.0000, 15.0000,  5.0000,  ...,  6.0000,  6.0000,  4.0000],\n",
      "          [ 0.0000, 15.0000,  4.0000,  ...,  5.0000,  5.0000,  2.0000],\n",
      "          [ 0.0000, 14.0000,  5.0000,  ...,  5.0000,  6.0000,  2.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  3.0000,  3.0000,  ...,  1.0000,  2.0000,  4.0000],\n",
      "          [ 0.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  6.0000],\n",
      "          [ 0.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000, 11.0000]],\n",
      "\n",
      "         [[ 0.0000,  9.0000,  3.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  3.0000,  4.0000,  ...,  3.0000,  3.0000,  2.0000],\n",
      "          [ 0.0000,  0.0000,  1.0000,  ...,  4.0000,  4.0000,  4.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 1.0000,  2.0000,  2.0000,  ...,  2.0000,  2.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  3.0000,  ...,  6.0000,  6.0000,  5.0000],\n",
      "          [ 0.0000,  0.0000,  2.0000,  ...,  4.0000,  4.0000,  5.0000],\n",
      "          [ 0.0000,  0.0000,  2.0000,  ...,  4.0000,  4.0000,  5.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 1.0000,  2.0000,  2.0000,  ...,  2.0000,  2.0000,  0.0000]],\n",
      "\n",
      "         [[ 4.0000, 14.0000,  6.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  9.0000,  6.0000,  ...,  1.0000,  2.0000,  0.0000],\n",
      "          [ 0.0000,  9.0000,  5.0000,  ...,  1.0000,  1.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  2.0000,  3.0000,  ...,  7.0000,  8.0000, 11.0000],\n",
      "          [ 0.0000,  2.0000,  4.0000,  ...,  7.0000,  8.0000, 11.0000],\n",
      "          [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  2.0000,  ...,  6.0000,  6.0000,  7.0000],\n",
      "          [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  2.0000],\n",
      "          [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  2.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 1.0000,  2.0000,  2.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 6.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000,  3.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[15.0000, 15.0000,  0.0000,  ...,  4.0000,  5.0000,  0.0000],\n",
      "          [15.0000, 15.0000,  0.0000,  ...,  6.0000,  6.0000,  0.0000],\n",
      "          [15.0000, 15.0000,  0.0000,  ...,  6.0000,  6.0000,  0.0000],\n",
      "          ...,\n",
      "          [15.0000,  6.0000,  0.0000,  ...,  1.0000,  1.0000,  4.0000],\n",
      "          [15.0000,  4.0000,  6.0000,  ...,  2.0000,  2.0000, 11.0000],\n",
      "          [15.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  9.0000]],\n",
      "\n",
      "         [[ 0.0000,  6.0000, 15.0000,  ...,  6.0000,  6.0000,  4.0000],\n",
      "          [ 0.0000, 10.0000, 15.0000,  ...,  4.0000,  4.0000,  1.0000],\n",
      "          [ 0.0000, 10.0000, 15.0000,  ...,  4.0000,  4.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  5.0000,  8.0000,  ...,  2.0000,  3.0000,  1.0000],\n",
      "          [ 0.0000,  4.0000,  3.0000,  ...,  3.0000,  3.0000,  5.0000],\n",
      "          [ 0.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000, 11.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, 12.0000,  ...,  4.0000,  4.0000,  3.0000],\n",
      "          [ 0.0000,  0.0000,  7.0000,  ...,  2.0000,  3.0000,  3.0000],\n",
      "          [ 0.0000,  0.0000,  8.0000,  ...,  3.0000,  3.0000,  3.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 1.0000,  2.0000,  2.0000,  ...,  2.0000,  2.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  6.0000,  6.0000,  5.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  4.0000,  4.0000,  5.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  4.0000,  4.0000,  4.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 1.0000,  2.0000,  2.0000,  ...,  2.0000,  2.0000,  0.0000]],\n",
      "\n",
      "         [[ 4.0000,  9.0000,  9.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  2.0000,  2.0000,  ...,  1.0000,  1.0000,  0.0000],\n",
      "          [ 0.0000,  2.0000,  2.0000,  ...,  1.0000,  1.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  2.0000,  2.0000,  ...,  9.0000,  9.0000, 11.0000],\n",
      "          [ 0.0000,  2.0000,  2.0000,  ...,  2.0000,  2.0000,  5.0000],\n",
      "          [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  6.0000,  6.0000,  7.0000],\n",
      "          [ 1.0000,  3.0000,  3.0000,  ...,  0.0000,  0.0000,  1.0000],\n",
      "          [ 1.0000,  3.0000,  3.0000,  ...,  0.0000,  0.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  3.0000,  3.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 1.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  0.0000],\n",
      "          [ 6.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000,  3.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[15.0000,  3.0000,  3.0000,  ...,  4.0000,  3.0000,  0.0000],\n",
      "          [15.0000,  3.0000,  3.0000,  ...,  5.0000,  6.0000,  0.0000],\n",
      "          [15.0000,  3.0000,  3.0000,  ...,  5.0000,  5.0000,  0.0000],\n",
      "          ...,\n",
      "          [15.0000,  3.0000,  3.0000,  ...,  6.0000,  5.0000, 12.0000],\n",
      "          [15.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000, 12.0000],\n",
      "          [15.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  9.0000]],\n",
      "\n",
      "         [[ 0.0000,  1.0000,  1.0000,  ...,  6.0000,  6.0000,  3.0000],\n",
      "          [ 0.0000,  3.0000,  3.0000,  ...,  4.0000,  4.0000,  1.0000],\n",
      "          [ 0.0000,  3.0000,  3.0000,  ...,  4.0000,  4.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  3.0000,  3.0000,  ...,  1.0000,  1.0000,  3.0000],\n",
      "          [ 0.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  6.0000],\n",
      "          [ 0.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000, 11.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  2.0000,  2.0000,  2.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  3.0000,  3.0000,  4.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  3.0000,  3.0000,  3.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 1.0000,  2.0000,  2.0000,  ...,  2.0000,  2.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  2.0000,  2.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  2.0000,  2.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 1.0000,  2.0000,  2.0000,  ...,  2.0000,  2.0000,  0.0000]],\n",
      "\n",
      "         [[ 2.0000,  5.0000,  5.0000,  ...,  2.0000,  0.0000,  6.0000],\n",
      "          [ 1.0000,  2.0000,  3.0000,  ...,  1.0000,  0.0000,  2.0000],\n",
      "          [ 1.0000,  1.0000,  3.0000,  ...,  1.0000,  0.0000,  3.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  4.0000,  4.0000,  ...,  4.0000,  4.0000,  6.0000],\n",
      "          [ 2.0000,  6.0000,  6.0000,  ...,  6.0000,  5.0000,  7.0000],\n",
      "          [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  2.0000,  0.0000],\n",
      "          [ 1.0000,  0.0000,  0.0000,  ...,  2.0000,  5.0000,  0.0000],\n",
      "          [ 2.0000,  1.0000,  0.0000,  ...,  1.0000,  4.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 6.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000,  3.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[11.0000,  7.0000,  0.0000,  ...,  4.0000,  0.0000, 15.0000],\n",
      "          [ 8.0000,  9.0000,  1.0000,  ...,  5.0000,  0.0000, 15.0000],\n",
      "          [ 7.0000,  7.0000,  6.0000,  ...,  4.0000,  0.0000, 15.0000],\n",
      "          ...,\n",
      "          [ 7.0000,  5.0000,  4.0000,  ...,  5.0000,  2.0000, 15.0000],\n",
      "          [15.0000,  3.0000,  3.0000,  ...,  3.0000,  2.0000,  9.0000],\n",
      "          [15.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  9.0000]],\n",
      "\n",
      "         [[ 0.0000,  2.0000,  6.0000,  ...,  3.0000,  1.0000,  0.0000],\n",
      "          [ 0.0000,  2.0000,  7.0000,  ...,  4.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  1.0000,  4.0000,  ...,  4.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  1.0000,  1.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  2.0000,  2.0000,  ...,  2.0000,  2.0000,  5.0000],\n",
      "          [ 0.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000, 11.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  1.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  1.0000,  ...,  2.0000,  2.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  2.0000,  2.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 1.0000,  2.0000,  2.0000,  ...,  2.0000,  2.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  2.0000,  1.0000,  1.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  2.0000,  2.0000,  2.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 1.0000,  2.0000,  2.0000,  ...,  2.0000,  2.0000,  0.0000]],\n",
      "\n",
      "         [[ 5.0000,  6.0000,  3.0000,  ...,  0.0000,  0.0000,  1.0000],\n",
      "          [ 2.0000,  2.0000,  1.0000,  ...,  2.0000,  4.0000,  4.0000],\n",
      "          [ 2.0000,  1.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  2.0000,  3.0000,  ...,  4.0000,  4.0000,  7.0000],\n",
      "          [ 1.0000,  3.0000,  5.0000,  ...,  5.0000,  5.0000,  8.0000],\n",
      "          [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.0000,  0.0000],\n",
      "          [ 0.0000,  4.0000,  2.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  4.0000,  1.0000,  ...,  3.0000,  2.0000,  2.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  2.0000,  2.0000,  ...,  2.0000,  2.0000,  0.0000],\n",
      "          [ 1.0000,  2.0000,  1.0000,  ...,  1.0000,  1.0000,  0.0000],\n",
      "          [ 6.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000,  3.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[15.0000,  0.0000,  6.0000,  ...,  6.0000,  8.0000, 11.0000],\n",
      "          [15.0000,  0.0000,  5.0000,  ..., 11.0000,  5.0000,  7.0000],\n",
      "          [15.0000,  0.0000,  4.0000,  ...,  2.0000,  3.0000,  0.0000],\n",
      "          ...,\n",
      "          [15.0000,  0.0000,  4.0000,  ...,  5.0000,  4.0000, 11.0000],\n",
      "          [15.0000,  5.0000,  3.0000,  ...,  2.0000,  2.0000, 11.0000],\n",
      "          [15.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  9.0000]],\n",
      "\n",
      "         [[ 0.0000, 12.0000,  2.0000,  ...,  1.0000,  1.0000,  0.0000],\n",
      "          [ 0.0000, 15.0000,  3.0000,  ...,  0.0000,  1.0000,  3.0000],\n",
      "          [ 0.0000, 15.0000,  1.0000,  ...,  3.0000,  3.0000,  5.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  6.0000,  2.0000,  ...,  1.0000,  2.0000,  4.0000],\n",
      "          [ 0.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  6.0000],\n",
      "          [ 0.0000,  7.0000,  7.0000,  ...,  7.0000,  7.0000, 11.0000]],\n",
      "\n",
      "         [[ 0.0000,  5.0000,  2.0000,  ...,  7.0000,  6.0000,  3.0000],\n",
      "          [ 0.0000,  4.0000,  1.0000,  ...,  1.0000,  1.0000,  2.0000],\n",
      "          [ 0.0000,  4.0000,  1.0000,  ...,  3.0000,  2.0000,  3.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 1.0000,  2.0000,  2.0000,  ...,  2.0000,  2.0000,  1.0000]]]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x_bit = 4    \n",
    "x = save_output.outputs[0][0]  # input of the 2nd conv layer\n",
    "x_alpha  = model.layer1[0].conv1.act_alpha\n",
    "x_delta = x_alpha/(2**x_bit-1)\n",
    "\n",
    "act_quant_fn = act_quantization(x_bit) # define the quantization function\n",
    "x_q = act_quant_fn(x, x_alpha)         # create the quantized value for x\n",
    "\n",
    "x_int = x_q/x_delta\n",
    "print(x_int) # you should see clean integer numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ranging-porter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.2923e+01, -2.2089e+01, -2.1789e+01,  ..., -1.9835e+01,\n",
      "           -8.7156e+00, -4.1023e+01],\n",
      "          [-1.7431e+01, -3.0354e+01, -2.2691e+01,  ..., -4.3578e+00,\n",
      "            1.6530e+00, -4.1023e+01],\n",
      "          [-1.7281e+01, -3.1256e+01, -3.1857e+01,  ..., -1.2021e+01,\n",
      "           -1.8333e+01,  3.0054e-01],\n",
      "          ...,\n",
      "          [-1.4877e+01, -2.3592e+01, -2.2540e+01,  ..., -1.2472e+01,\n",
      "           -1.0819e+01, -1.8032e+01],\n",
      "          [-1.4726e+01, -2.7950e+01, -3.1857e+01,  ..., -1.4426e+01,\n",
      "           -1.5177e+01, -1.5027e+01],\n",
      "          [-1.8182e+01, -2.8401e+01, -2.4945e+01,  ..., -5.4848e+01,\n",
      "           -5.4848e+01, -5.2143e+01]],\n",
      "\n",
      "         [[-6.0107e+00, -5.3646e+01,  2.3292e+01,  ..., -7.5134e-01,\n",
      "           -2.4494e+01, -2.9152e+01],\n",
      "          [-2.4043e+00, -5.5149e+01,  2.0737e+01,  ...,  1.4726e+01,\n",
      "           -3.2308e+01,  8.1145e+00],\n",
      "          [-2.8551e+00, -5.8905e+01,  2.8100e+01,  ..., -7.0626e+00,\n",
      "           -1.7431e+01,  1.3374e+01],\n",
      "          ...,\n",
      "          [-7.8140e+00, -4.5682e+01,  2.5245e+01,  ..., -6.7621e+00,\n",
      "           -5.7102e+00, -6.0107e-01],\n",
      "          [-7.6637e+00, -3.1256e+01,  9.3166e+00,  ...,  2.1038e+00,\n",
      "            7.5134e-01,  4.9589e+00],\n",
      "          [-1.1120e+01, -2.1338e+01, -4.6583e+00,  ..., -5.7102e+00,\n",
      "           -5.8605e+00, -2.5546e+00]],\n",
      "\n",
      "         [[ 1.2923e+01,  2.3442e+01,  1.2021e+01,  ...,  2.5546e+00,\n",
      "            3.3059e+00,  1.7882e+01],\n",
      "          [ 1.2322e+01,  2.2089e+01,  1.5628e+01,  ..., -7.5134e-01,\n",
      "            2.4343e+01,  1.9385e+01],\n",
      "          [ 1.2623e+01,  2.1939e+01,  1.9385e+01,  ..., -2.2540e+00,\n",
      "            1.4125e+01, -1.3524e+00],\n",
      "          ...,\n",
      "          [ 1.0068e+01,  1.7131e+01,  8.7156e+00,  ...,  2.7199e+01,\n",
      "            2.5846e+01,  2.7649e+01],\n",
      "          [ 7.2129e+00,  1.7131e+01,  1.9535e+00,  ...,  5.4097e+00,\n",
      "            6.4615e+00,  1.3374e+01],\n",
      "          [-7.8140e+00, -1.0218e+01, -2.1338e+01,  ..., -1.0218e+01,\n",
      "           -9.7675e+00, -2.4043e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0519e+00,  1.3073e+01,  2.6447e+01,  ..., -1.3825e+01,\n",
      "           -7.5134e-01, -3.7417e+01],\n",
      "          [-1.0519e+00,  4.5081e+00,  1.6980e+01,  ...,  2.3742e+01,\n",
      "           -1.1120e+01, -1.2172e+01],\n",
      "          [-3.9070e+00,  4.6583e+00,  5.7102e+00,  ...,  4.5081e-01,\n",
      "           -2.8401e+01,  5.1091e+00],\n",
      "          ...,\n",
      "          [ 6.0108e-01,  4.5081e+00,  2.4494e+01,  ...,  1.0519e+00,\n",
      "            1.9535e+00, -1.5027e+00],\n",
      "          [ 4.3578e+00, -1.5327e+01,  1.1270e+01,  ..., -1.9535e+01,\n",
      "           -1.9685e+01, -2.6447e+01],\n",
      "          [-6.6118e+00, -1.8934e+01, -8.4150e+00,  ..., -3.0054e-01,\n",
      "           -1.5027e-01, -1.2021e+00]],\n",
      "\n",
      "         [[ 3.5013e+01,  3.8469e+01,  4.2977e+01,  ...,  3.7417e+01,\n",
      "            3.4411e+01,  2.8551e+01],\n",
      "          [ 3.2608e+01,  3.4111e+01,  3.8018e+01,  ...,  2.9002e+01,\n",
      "            2.2991e+01,  4.7335e+01],\n",
      "          [ 3.3059e+01,  3.4261e+01,  4.5381e+01,  ...,  9.3166e+00,\n",
      "            1.0519e+01,  2.8701e+01],\n",
      "          ...,\n",
      "          [ 3.2308e+01,  3.5463e+01,  4.2376e+01,  ...,  4.1023e+01,\n",
      "            4.1174e+01,  3.9521e+01],\n",
      "          [ 3.1707e+01,  4.0422e+01,  3.6966e+01,  ...,  3.0054e+01,\n",
      "            3.0054e+01,  3.1707e+01],\n",
      "          [ 4.2526e+01,  5.1091e+01,  4.1624e+01,  ...,  3.9521e+01,\n",
      "            3.9521e+01,  3.8018e+01]],\n",
      "\n",
      "         [[-3.8168e+01, -8.1896e+01, -1.0369e+02,  ..., -4.0572e+01,\n",
      "           -2.7800e+01, -3.1556e+00],\n",
      "          [-4.5381e+01, -8.0243e+01, -1.0038e+02,  ..., -7.0476e+01,\n",
      "           -3.5013e+01, -4.4630e+01],\n",
      "          [-4.3277e+01, -7.8741e+01, -7.7238e+01,  ..., -6.0258e+01,\n",
      "           -6.2211e+01, -8.3098e+01],\n",
      "          ...,\n",
      "          [-4.8386e+01, -6.5667e+01, -8.2497e+01,  ..., -5.0190e+01,\n",
      "           -4.8837e+01, -4.5682e+01],\n",
      "          [-5.2894e+01, -4.7034e+01, -9.2415e+01,  ..., -6.0408e+01,\n",
      "           -6.1159e+01, -5.9957e+01],\n",
      "          [-4.0723e+01, -3.6665e+01, -1.4726e+01,  ..., -7.5134e+00,\n",
      "           -8.2648e+00, -1.5027e+01]]],\n",
      "\n",
      "\n",
      "        [[[-2.8701e+01, -2.5846e+01, -2.7048e+01,  ..., -2.1188e+01,\n",
      "           -1.3524e+01, -1.6980e+01],\n",
      "          [-3.1406e+01, -4.8687e+01, -3.1106e+01,  ..., -1.7882e+01,\n",
      "           -2.4043e+01, -2.5546e+01],\n",
      "          [-2.3742e+01, -2.7800e+01, -3.1556e+01,  ..., -8.5653e+00,\n",
      "           -1.2923e+01, -2.1488e+01],\n",
      "          ...,\n",
      "          [-2.0437e+01, -1.0218e+01, -1.6980e+01,  ..., -2.3742e+01,\n",
      "           -2.2691e+01, -2.6147e+01],\n",
      "          [-1.6229e+01, -3.3810e+01, -3.0054e+01,  ..., -6.4916e+01,\n",
      "           -6.4165e+01, -6.2512e+01],\n",
      "          [-1.8784e+01, -2.0887e+01, -2.0136e+01,  ..., -1.6830e+01,\n",
      "           -1.6530e+01, -1.5928e+01]],\n",
      "\n",
      "         [[ 2.4794e+01, -4.3578e+00,  2.1639e+01,  ..., -3.3059e+01,\n",
      "           -3.3360e+01, -2.5245e+01],\n",
      "          [ 1.9535e+01, -4.5081e+00,  8.8658e+00,  ..., -2.9603e+01,\n",
      "           -3.6515e+01, -3.1256e+01],\n",
      "          [ 1.2923e+01, -9.0161e+00, -1.0669e+01,  ..., -1.8784e+01,\n",
      "           -2.6748e+01, -2.4193e+01],\n",
      "          ...,\n",
      "          [-5.8605e+00, -3.9070e+00, -3.7567e+00,  ...,  1.3374e+01,\n",
      "            1.1270e+01,  1.3073e+01],\n",
      "          [-1.9535e+00, -1.5027e-01, -1.5027e+00,  ...,  4.8086e+00,\n",
      "            3.0054e+00,  6.4615e+00],\n",
      "          [-1.3374e+01, -1.4276e+01, -1.4726e+01,  ..., -1.6680e+01,\n",
      "           -1.7131e+01, -1.3374e+01]],\n",
      "\n",
      "         [[ 3.3059e+00, -1.5027e-01,  2.7048e+00,  ...,  2.3442e+01,\n",
      "            2.7499e+01,  2.8852e+01],\n",
      "          [ 1.4276e+01,  1.3975e+01,  6.3113e+00,  ...,  5.8605e+00,\n",
      "            1.1120e+01,  1.2773e+01],\n",
      "          [ 7.2129e+00,  6.6118e+00,  8.4150e+00,  ..., -1.1644e-06,\n",
      "           -2.8661e-06, -7.5134e-01],\n",
      "          ...,\n",
      "          [ 8.5653e+00,  5.5599e+00,  3.4562e+00,  ...,  1.8633e+01,\n",
      "            1.8934e+01,  2.4945e+01],\n",
      "          [ 4.5081e+00,  2.4043e+00,  1.5027e+00,  ...,  1.5478e+01,\n",
      "            1.6079e+01,  2.1338e+01],\n",
      "          [-6.7621e+00, -1.1420e+01, -1.1871e+01,  ..., -1.0369e+01,\n",
      "           -1.0369e+01, -4.6583e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1188e+01,  4.9589e+00, -3.4562e+00,  ..., -2.7349e+01,\n",
      "           -2.5245e+01, -1.8934e+01],\n",
      "          [ 9.4669e+00,  1.2021e+00,  1.1721e+01,  ..., -2.3141e+01,\n",
      "           -2.5095e+01, -1.6079e+01],\n",
      "          [ 7.0626e+00, -2.8551e+00,  9.7674e+00,  ..., -1.2773e+01,\n",
      "           -2.0136e+01, -1.6980e+01],\n",
      "          ...,\n",
      "          [ 6.7621e+00,  3.6064e+00,  1.8032e+00,  ..., -1.9835e+01,\n",
      "           -1.9535e+01, -2.4794e+01],\n",
      "          [ 6.1610e+00,  6.6118e+00,  1.0669e+01,  ...,  1.5027e+01,\n",
      "            1.4576e+01,  1.0819e+01],\n",
      "          [-5.2594e+00, -9.0161e-01, -4.5081e-01,  ...,  3.4562e+00,\n",
      "            2.7048e+00, -1.6530e+00]],\n",
      "\n",
      "         [[ 1.9234e+01,  2.4343e+01,  2.3292e+01,  ...,  4.5982e+01,\n",
      "            4.5081e+01,  4.6733e+01],\n",
      "          [ 1.8784e+01,  2.4193e+01,  1.5478e+01,  ...,  4.5682e+01,\n",
      "            4.4930e+01,  4.7184e+01],\n",
      "          [ 3.1256e+01,  3.9220e+01,  2.0887e+01,  ...,  3.3810e+01,\n",
      "            3.9821e+01,  4.3277e+01],\n",
      "          ...,\n",
      "          [ 3.2007e+01,  3.7567e+01,  3.8769e+01,  ...,  2.1338e+01,\n",
      "            2.0587e+01,  2.4343e+01],\n",
      "          [ 3.0504e+01,  3.5163e+01,  3.6365e+01,  ...,  2.4794e+01,\n",
      "            2.5395e+01,  2.5846e+01],\n",
      "          [ 4.5231e+01,  5.6651e+01,  5.7403e+01,  ...,  6.0408e+01,\n",
      "            6.0859e+01,  5.6050e+01]],\n",
      "\n",
      "         [[-1.0759e+02, -6.9274e+01, -5.3646e+01,  ..., -4.3428e+01,\n",
      "           -4.7034e+01, -4.1925e+01],\n",
      "          [-7.0626e+01, -4.2225e+01, -5.5599e+01,  ..., -4.0122e+01,\n",
      "           -4.0723e+01, -4.0723e+01],\n",
      "          [-6.8823e+01, -2.6598e+01, -2.1338e+01,  ..., -5.5900e+01,\n",
      "           -5.3195e+01, -4.4029e+01],\n",
      "          ...,\n",
      "          [-5.6050e+01, -4.4179e+01, -4.1624e+01,  ..., -4.9739e+01,\n",
      "           -4.6733e+01, -4.0723e+01],\n",
      "          [-3.2759e+01, -2.3292e+01, -2.5546e+01,  ...,  5.2594e+00,\n",
      "            3.1556e+00, -4.3578e+00],\n",
      "          [-3.8920e+01, -3.4712e+01, -3.5013e+01,  ..., -3.3510e+01,\n",
      "           -3.3810e+01, -4.1324e+01]]],\n",
      "\n",
      "\n",
      "        [[[-2.9302e+01, -3.6064e+01, -2.9753e+01,  ..., -1.3524e+01,\n",
      "           -1.3825e+01, -1.7281e+01],\n",
      "          [-3.2458e+01, -4.1023e+01, -3.1707e+01,  ..., -1.2322e+01,\n",
      "           -1.4276e+01, -1.4426e+01],\n",
      "          [-3.4411e+01, -4.1324e+01, -2.8250e+01,  ..., -1.1871e+01,\n",
      "           -1.3224e+01, -1.4726e+01],\n",
      "          ...,\n",
      "          [-2.4343e+01, -3.1106e+01, -1.6830e+01,  ..., -2.7499e+01,\n",
      "           -3.2909e+01, -3.3961e+01],\n",
      "          [-2.6447e+01, -3.1857e+01, -1.8182e+01,  ..., -3.0054e+01,\n",
      "           -3.3660e+01, -2.8852e+01],\n",
      "          [-2.1038e+01, -2.3592e+01, -4.9739e+01,  ..., -4.6283e+01,\n",
      "           -3.8769e+01, -4.4780e+01]],\n",
      "\n",
      "         [[-6.5367e+01,  4.0873e+01, -1.3374e+01,  ..., -8.4150e+00,\n",
      "           -8.7156e+00, -1.1721e+01],\n",
      "          [-6.7320e+01,  2.9753e+01, -1.7581e+01,  ..., -6.1610e+00,\n",
      "           -1.1120e+01, -1.2021e+01],\n",
      "          [-6.7320e+01,  2.9302e+01, -1.7581e+01,  ..., -5.8605e+00,\n",
      "           -1.0669e+01, -1.1420e+01],\n",
      "          ...,\n",
      "          [-3.6515e+01,  2.5546e+01,  8.1145e+00,  ...,  2.7199e+01,\n",
      "            1.7732e+01,  3.3360e+01],\n",
      "          [-1.9986e+01,  1.5628e+01,  9.0161e+00,  ...,  2.5996e+01,\n",
      "            2.2089e+01,  2.6447e+01],\n",
      "          [-1.3374e+01, -4.9589e+00,  9.0161e-01,  ...,  1.8032e+00,\n",
      "            1.2021e+00,  3.0054e+00]],\n",
      "\n",
      "         [[ 2.9603e+01,  1.1270e+01,  3.0054e+00,  ...,  6.0107e+00,\n",
      "            6.9123e+00,  6.0107e+00],\n",
      "          [ 2.8701e+01,  1.4426e+01,  5.8605e+00,  ...,  1.2172e+01,\n",
      "            1.1420e+01,  8.1145e+00],\n",
      "          [ 2.7048e+01,  1.1571e+01,  2.2540e+00,  ...,  9.9177e+00,\n",
      "            1.1120e+01,  7.9642e+00],\n",
      "          ...,\n",
      "          [ 2.0587e+01,  1.8032e+00,  2.4043e+00,  ...,  4.8086e+00,\n",
      "            9.0161e+00,  4.0572e+00],\n",
      "          [ 2.5395e+01,  1.3374e+01,  1.9986e+01,  ...,  1.3975e+01,\n",
      "            1.7281e+01,  2.1188e+01],\n",
      "          [ 1.9535e+00, -5.8605e+00,  3.6064e+00,  ...,  5.5599e+00,\n",
      "            3.4562e+00,  1.0970e+01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.8551e+00,  2.4193e+01, -9.0161e-01,  ..., -1.5928e+01,\n",
      "           -1.6830e+01, -1.3825e+01],\n",
      "          [-2.2540e+00,  1.1871e+01, -3.3059e+00,  ..., -9.9177e+00,\n",
      "           -1.2172e+01, -9.9177e+00],\n",
      "          [-3.0054e+00,  1.3073e+01, -5.5599e+00,  ..., -1.1270e+01,\n",
      "           -1.3975e+01, -1.0068e+01],\n",
      "          ...,\n",
      "          [ 4.2075e+00,  1.9835e+01,  7.5134e+00,  ...,  3.1556e+00,\n",
      "            3.1556e+00,  1.3073e+01],\n",
      "          [-4.6583e+00,  1.8333e+01, -5.2594e+00,  ...,  9.9177e+00,\n",
      "            7.9642e+00, -6.0107e-01],\n",
      "          [-1.2472e+01, -6.1610e+00, -4.0572e+00,  ...,  1.1571e+01,\n",
      "            6.6118e+00,  2.1038e+00]],\n",
      "\n",
      "         [[ 2.5245e+01,  4.8837e+01,  5.1242e+01,  ...,  3.5163e+01,\n",
      "            3.4111e+01,  3.4862e+01],\n",
      "          [ 2.1639e+01,  4.4479e+01,  5.2744e+01,  ...,  3.7717e+01,\n",
      "            3.6966e+01,  3.8920e+01],\n",
      "          [ 1.9385e+01,  4.2826e+01,  4.9889e+01,  ...,  3.7267e+01,\n",
      "            3.6365e+01,  3.7868e+01],\n",
      "          ...,\n",
      "          [ 2.1789e+01,  2.5395e+01,  1.6079e+01,  ...,  1.0369e+01,\n",
      "            1.0369e+01,  1.9535e+01],\n",
      "          [ 2.7349e+01,  2.5095e+01,  1.2923e+01,  ...,  1.7732e+01,\n",
      "            1.8934e+01,  2.0737e+01],\n",
      "          [ 4.1174e+01,  4.2977e+01,  3.8619e+01,  ...,  4.0122e+01,\n",
      "            3.9821e+01,  3.5013e+01]],\n",
      "\n",
      "         [[-1.0263e+02, -1.2367e+02, -6.1760e+01,  ..., -4.6433e+01,\n",
      "           -4.6132e+01, -3.9971e+01],\n",
      "          [-1.0534e+02, -1.1210e+02, -5.6651e+01,  ..., -4.0272e+01,\n",
      "           -4.0272e+01, -3.5914e+01],\n",
      "          [-1.0534e+02, -1.1450e+02, -5.5900e+01,  ..., -4.0723e+01,\n",
      "           -3.8920e+01, -3.6665e+01],\n",
      "          ...,\n",
      "          [-6.7471e+01, -8.8809e+01, -5.4848e+01,  ..., -3.3660e+01,\n",
      "           -4.3878e+01, -5.4848e+01],\n",
      "          [-4.6733e+01, -6.4165e+01, -3.6365e+01,  ..., -2.7349e+01,\n",
      "           -4.2526e+01, -4.1775e+01],\n",
      "          [-3.6966e+01, -1.0819e+01,  7.5134e-01,  ..., -6.9123e+00,\n",
      "           -3.6064e+00, -7.3632e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.3825e+01, -1.4125e+01, -3.1406e+01,  ..., -1.7131e+01,\n",
      "           -1.8483e+01, -1.8784e+01],\n",
      "          [-1.6980e+01, -1.8633e+01, -3.4111e+01,  ..., -1.6229e+01,\n",
      "           -1.4426e+01, -1.7732e+01],\n",
      "          [-1.6980e+01, -1.8784e+01, -3.4411e+01,  ..., -1.5628e+01,\n",
      "           -1.6530e+01, -1.6530e+01],\n",
      "          ...,\n",
      "          [-1.6980e+01, -1.9385e+01, -3.7567e+01,  ..., -1.6830e+01,\n",
      "           -1.7131e+01, -1.8032e+01],\n",
      "          [-1.6980e+01, -2.1639e+01, -2.8551e+01,  ..., -7.5886e+01,\n",
      "           -7.4683e+01, -7.7539e+01],\n",
      "          [-1.7882e+01, -2.2089e+01, -2.2991e+01,  ..., -2.0286e+01,\n",
      "           -2.1939e+01, -1.9084e+01]],\n",
      "\n",
      "         [[-1.0970e+01, -2.5546e+00, -6.3714e+01,  ..., -1.4726e+01,\n",
      "           -1.2773e+01, -1.0819e+01],\n",
      "          [-7.9642e+00, -1.8032e+00, -6.3263e+01,  ..., -1.4576e+01,\n",
      "           -1.1721e+01, -1.2021e+01],\n",
      "          [-7.9642e+00, -1.9535e+00, -6.3864e+01,  ..., -1.1571e+01,\n",
      "           -1.2472e+01, -1.2923e+01],\n",
      "          ...,\n",
      "          [-7.9642e+00, -4.2075e+00, -3.9521e+01,  ..., -1.2322e+01,\n",
      "           -8.4150e+00, -4.3578e+00],\n",
      "          [-7.9642e+00, -5.1091e+00, -1.7882e+01,  ..., -6.0107e-01,\n",
      "           -2.1038e+00,  2.8551e+00],\n",
      "          [-1.2322e+01, -1.5027e+01, -1.2322e+01,  ..., -1.8633e+01,\n",
      "           -2.0737e+01, -1.6229e+01]],\n",
      "\n",
      "         [[ 7.6637e+00,  1.2021e+01,  2.8852e+01,  ...,  1.9835e+01,\n",
      "            1.9234e+01,  1.3524e+01],\n",
      "          [ 7.9642e+00,  1.4426e+01,  2.8100e+01,  ...,  1.6680e+01,\n",
      "            1.6379e+01,  1.3073e+01],\n",
      "          [ 7.9642e+00,  1.4576e+01,  2.7349e+01,  ...,  1.6379e+01,\n",
      "            1.7131e+01,  1.4276e+01],\n",
      "          ...,\n",
      "          [ 7.9642e+00,  9.0161e+00,  2.8401e+01,  ...,  2.1639e+01,\n",
      "            2.0286e+01,  2.5546e+01],\n",
      "          [ 7.9642e+00,  3.4562e+00,  8.2648e+00,  ...,  1.1871e+01,\n",
      "            1.1270e+01,  1.9084e+01],\n",
      "          [-5.5599e+00, -1.0218e+01, -1.5628e+01,  ..., -1.2021e+01,\n",
      "           -1.2322e+01, -6.9124e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.2648e+00,  5.5599e+00,  9.7674e+00,  ..., -2.0136e+01,\n",
      "           -1.9535e+01, -1.5327e+01],\n",
      "          [ 7.3632e+00, -1.6530e+00,  1.5027e+00,  ..., -1.2623e+01,\n",
      "           -1.0970e+01, -1.0369e+01],\n",
      "          [ 7.3632e+00, -1.6530e+00,  1.2021e+00,  ..., -1.1721e+01,\n",
      "           -1.1721e+01, -9.0161e+00],\n",
      "          ...,\n",
      "          [ 7.3632e+00,  6.1610e+00, -1.4426e+01,  ..., -3.8769e+01,\n",
      "           -3.7868e+01, -4.3277e+01],\n",
      "          [ 7.3632e+00,  3.6064e+00, -1.5478e+01,  ...,  1.0819e+01,\n",
      "            1.0970e+01,  7.2129e+00],\n",
      "          [-4.2075e+00, -1.9535e+00, -1.5027e+00,  ...,  4.8086e+00,\n",
      "            4.0572e+00,  3.0054e-01]],\n",
      "\n",
      "         [[ 3.7267e+01,  4.4780e+01,  3.5764e+01,  ...,  3.8920e+01,\n",
      "            3.8619e+01,  3.7717e+01],\n",
      "          [ 3.4261e+01,  4.0422e+01,  2.9753e+01,  ...,  3.6966e+01,\n",
      "            3.7567e+01,  3.8619e+01],\n",
      "          [ 3.4261e+01,  4.0272e+01,  3.0204e+01,  ...,  3.6515e+01,\n",
      "            3.7116e+01,  3.6515e+01],\n",
      "          ...,\n",
      "          [ 3.4261e+01,  3.8318e+01,  3.5914e+01,  ...,  3.5163e+01,\n",
      "            3.5764e+01,  3.4862e+01],\n",
      "          [ 3.4261e+01,  3.9070e+01,  3.6816e+01,  ...,  1.9535e+01,\n",
      "            1.9385e+01,  2.3292e+01],\n",
      "          [ 4.5682e+01,  5.4247e+01,  5.4698e+01,  ...,  6.0408e+01,\n",
      "            6.1009e+01,  5.7403e+01]],\n",
      "\n",
      "         [[-3.1106e+01, -4.2376e+01, -1.0248e+02,  ..., -4.8537e+01,\n",
      "           -5.1392e+01, -4.0272e+01],\n",
      "          [-4.0422e+01, -4.5231e+01, -9.6623e+01,  ..., -4.2977e+01,\n",
      "           -4.2676e+01, -3.5163e+01],\n",
      "          [-4.0422e+01, -4.5081e+01, -9.7073e+01,  ..., -3.7567e+01,\n",
      "           -3.9220e+01, -3.4411e+01],\n",
      "          ...,\n",
      "          [-4.0422e+01, -4.8086e+01, -5.6651e+01,  ..., -7.4383e+01,\n",
      "           -7.4834e+01, -6.5818e+01],\n",
      "          [-4.0422e+01, -3.5914e+01, -3.6064e+01,  ...,  4.5081e+00,\n",
      "            7.9642e+00,  2.2540e+00],\n",
      "          [-4.1174e+01, -3.4261e+01, -3.3961e+01,  ..., -3.6064e+01,\n",
      "           -3.7267e+01, -4.4179e+01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7281e+01, -2.2540e+01, -9.3166e+00,  ..., -1.3073e+01,\n",
      "           -1.1571e+01, -1.3224e+01],\n",
      "          [-1.1871e+01, -1.9986e+01, -1.6079e+01,  ..., -9.9177e+00,\n",
      "           -1.3073e+01, -1.2172e+01],\n",
      "          [-1.6830e+01, -1.5327e+01, -2.2991e+01,  ..., -1.3674e+01,\n",
      "           -1.3524e+01, -1.4276e+01],\n",
      "          ...,\n",
      "          [-1.4726e+01, -2.1639e+01, -2.0737e+01,  ..., -2.0437e+01,\n",
      "           -2.2841e+01, -1.2172e+01],\n",
      "          [ 2.1038e+00, -1.3975e+01, -1.2322e+01,  ..., -1.2172e+01,\n",
      "           -1.1571e+01, -1.0068e+01],\n",
      "          [-4.6433e+01, -4.8537e+01, -4.7034e+01,  ..., -4.7936e+01,\n",
      "           -4.8537e+01, -4.3127e+01]],\n",
      "\n",
      "         [[-3.0054e+01, -6.6118e+00, -4.5081e+00,  ..., -2.0437e+01,\n",
      "           -1.4426e+01,  1.2021e+01],\n",
      "          [-2.1038e+01, -2.4494e+01,  6.3113e+00,  ..., -1.3674e+01,\n",
      "           -8.7156e+00,  1.1270e+01],\n",
      "          [-6.0107e+00, -4.2676e+01,  6.4615e+00,  ..., -1.3224e+01,\n",
      "           -6.6118e+00,  1.4426e+01],\n",
      "          ...,\n",
      "          [-1.5027e-01, -1.0519e+00,  1.5027e+00,  ...,  1.3524e+00,\n",
      "            1.5027e-01,  2.1038e+01],\n",
      "          [-6.0107e+00,  4.5081e+00,  4.8086e+00,  ...,  4.5081e+00,\n",
      "            2.7048e+00,  1.9234e+01],\n",
      "          [-4.6583e+00, -4.5081e+00, -6.1610e+00,  ..., -3.1556e+00,\n",
      "           -7.0626e+00, -7.5134e-01]],\n",
      "\n",
      "         [[ 1.7581e+01,  6.3113e+00,  1.1571e+01,  ...,  1.5027e+01,\n",
      "            1.0068e+01,  6.9123e+00],\n",
      "          [ 1.6830e+01,  3.4562e+00,  6.6118e+00,  ...,  9.0161e+00,\n",
      "            4.2075e+00,  2.8551e+00],\n",
      "          [ 1.2172e+01,  8.4150e+00,  1.0519e+00,  ...,  9.7674e+00,\n",
      "            5.5599e+00,  2.8551e+00],\n",
      "          ...,\n",
      "          [ 9.4669e+00,  1.1721e+01,  1.0369e+01,  ...,  1.3374e+01,\n",
      "            1.3073e+01,  1.1420e+01],\n",
      "          [ 9.6172e+00,  3.7567e+00,  3.3059e+00,  ...,  6.4615e+00,\n",
      "            3.3059e+00,  2.4043e+00],\n",
      "          [-1.8032e+00, -8.5653e+00, -8.4150e+00,  ..., -9.3166e+00,\n",
      "           -9.6172e+00, -3.9070e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0519e+01,  1.4576e+01, -3.0054e+00,  ..., -1.0669e+01,\n",
      "           -2.5546e+00, -1.5027e+01],\n",
      "          [-2.2691e+01,  6.9123e+00, -1.8032e+00,  ..., -1.1571e+01,\n",
      "           -3.7567e+00, -1.4576e+01],\n",
      "          [-1.5478e+01, -7.5134e+00,  1.0519e+01,  ..., -1.0369e+01,\n",
      "           -4.0572e+00, -1.5628e+01],\n",
      "          ...,\n",
      "          [ 5.1091e+00,  2.1496e-07,  4.2075e+00,  ...,  4.3578e+00,\n",
      "            8.1145e+00, -4.2075e+00],\n",
      "          [-1.1721e+01, -1.4276e+01, -1.3975e+01,  ..., -1.1571e+01,\n",
      "           -1.0068e+01, -5.7102e+00],\n",
      "          [-6.1610e+00,  2.2540e+00, -6.0108e-01,  ...,  1.2021e+00,\n",
      "            5.3740e-07,  9.4669e+00]],\n",
      "\n",
      "         [[ 2.3442e+01,  2.1188e+01,  2.3292e+01,  ...,  2.7649e+01,\n",
      "            3.0955e+01,  3.6515e+01],\n",
      "          [ 2.4494e+01,  1.9986e+01,  1.6530e+01,  ...,  2.9152e+01,\n",
      "            3.0655e+01,  3.4261e+01],\n",
      "          [ 2.2089e+01,  2.2540e+01,  1.6379e+01,  ...,  2.7649e+01,\n",
      "            3.0655e+01,  3.5614e+01],\n",
      "          ...,\n",
      "          [ 2.3292e+01,  2.3592e+01,  2.2390e+01,  ...,  2.4644e+01,\n",
      "            2.7800e+01,  3.0504e+01],\n",
      "          [ 1.9835e+01,  2.3442e+01,  2.2089e+01,  ...,  2.3442e+01,\n",
      "            2.6147e+01,  2.5846e+01],\n",
      "          [ 2.7950e+01,  3.8168e+01,  3.8168e+01,  ...,  3.9070e+01,\n",
      "            4.1775e+01,  3.9821e+01]],\n",
      "\n",
      "         [[-2.5846e+01, -5.9657e+01, -4.5531e+01,  ..., -3.6816e+01,\n",
      "           -2.8100e+01, -5.7102e+00],\n",
      "          [-1.9835e+01, -5.2894e+01, -5.4397e+01,  ..., -3.7417e+01,\n",
      "           -3.0204e+01, -1.1571e+01],\n",
      "          [-2.2691e+01, -3.4411e+01, -6.3714e+01,  ..., -3.4712e+01,\n",
      "           -2.6447e+01, -7.8140e+00],\n",
      "          ...,\n",
      "          [-3.5463e+01, -3.5013e+01, -4.4479e+01,  ..., -3.1857e+01,\n",
      "           -3.2909e+01, -2.0286e+01],\n",
      "          [-5.0791e+01, -5.0190e+01, -4.2827e+01,  ..., -5.1242e+01,\n",
      "           -4.4780e+01, -4.8086e+01],\n",
      "          [-7.0626e+00, -6.4615e+00, -4.0572e+00,  ..., -4.9589e+00,\n",
      "           -3.7567e+00, -2.0887e+01]]],\n",
      "\n",
      "\n",
      "        [[[-2.9002e+01, -2.0136e+01, -1.3975e+01,  ...,  5.7102e+00,\n",
      "           -1.8934e+01, -3.1556e+01],\n",
      "          [-3.2909e+01, -2.0587e+01, -5.8605e+00,  ..., -5.5599e+01,\n",
      "           -3.9521e+01, -1.4877e+01],\n",
      "          [-3.0655e+01, -1.3224e+01, -1.2923e+01,  ...,  1.8032e+00,\n",
      "            5.4097e+00,  2.2540e+00],\n",
      "          ...,\n",
      "          [-2.0437e+01, -1.9084e+01, -1.8182e+01,  ..., -1.8934e+01,\n",
      "           -1.6079e+01, -1.5928e+01],\n",
      "          [-1.8333e+01, -9.1664e+00, -1.4576e+01,  ..., -1.1721e+01,\n",
      "           -1.2021e+01, -1.0519e+01],\n",
      "          [-1.6379e+01, -3.8769e+01, -3.5163e+01,  ..., -3.5463e+01,\n",
      "           -3.7116e+01, -3.4411e+01]],\n",
      "\n",
      "         [[ 2.3292e+01, -1.8483e+01, -1.1721e+01,  ..., -2.8551e+00,\n",
      "            1.6530e+00,  4.0572e+00],\n",
      "          [ 2.2991e+01, -1.3073e+01, -1.1721e+01,  ...,  1.2322e+01,\n",
      "           -5.2594e+00, -7.8140e+00],\n",
      "          [ 2.4794e+01, -5.1091e+00, -5.7102e+00,  ...,  3.7567e+00,\n",
      "            5.1091e+00,  3.4562e+00],\n",
      "          ...,\n",
      "          [ 7.9642e+00, -4.9589e+00, -4.5081e+00,  ...,  3.0054e+00,\n",
      "           -3.9070e+00,  3.3059e+00],\n",
      "          [ 4.3578e+00,  6.0107e-01,  4.5081e+00,  ...,  1.0519e+01,\n",
      "            5.7102e+00,  1.1871e+01],\n",
      "          [-3.4562e+00, -1.9535e+00, -2.1038e+00,  ..., -2.5546e+00,\n",
      "           -3.0054e+00, -1.8032e+00]],\n",
      "\n",
      "         [[-1.1270e+01, -1.2322e+01, -4.8086e+00,  ..., -3.2608e+01,\n",
      "           -3.3961e+01, -3.0805e+01],\n",
      "          [-7.0626e+00, -1.0519e+01, -4.8086e+00,  ..., -1.5027e+00,\n",
      "            7.9642e+00,  4.0572e+00],\n",
      "          [-9.1664e+00, -1.6229e+01, -5.7102e+00,  ..., -1.9535e+00,\n",
      "           -1.2021e+00, -6.0108e-01],\n",
      "          ...,\n",
      "          [-4.0572e+00, -7.9642e+00, -6.4615e+00,  ..., -8.5653e+00,\n",
      "           -8.7156e+00, -5.2594e+00],\n",
      "          [ 4.5080e-01, -3.3059e+00, -3.9070e+00,  ..., -6.4615e+00,\n",
      "           -6.9123e+00, -1.3524e+00],\n",
      "          [-1.1120e+01, -1.4125e+01, -1.1270e+01,  ..., -9.6172e+00,\n",
      "           -1.1270e+01, -3.1556e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6830e+01,  4.6583e+00, -2.4043e+00,  ..., -2.7199e+01,\n",
      "           -2.0887e+01,  5.4097e+00],\n",
      "          [ 1.3975e+01, -6.4615e+00, -1.5177e+01,  ...,  1.3073e+01,\n",
      "            1.0669e+01,  1.3224e+01],\n",
      "          [ 1.0369e+01, -8.7156e+00, -1.6079e+01,  ..., -4.0572e+00,\n",
      "           -2.1338e+01, -3.4411e+01],\n",
      "          ...,\n",
      "          [ 1.5928e+01,  9.7675e+00,  5.8605e+00,  ...,  5.2594e+00,\n",
      "            3.3059e+00, -1.6530e+00],\n",
      "          [ 1.0369e+01, -9.0161e-01, -9.0161e-01,  ...,  5.5599e+00,\n",
      "            1.5027e-01, -3.9070e+00],\n",
      "          [-6.1610e+00, -1.6530e+00,  4.8086e+00,  ...,  7.2129e+00,\n",
      "            6.3113e+00,  5.2594e+00]],\n",
      "\n",
      "         [[ 3.0504e+01,  3.8168e+01,  2.1789e+01,  ...,  1.7732e+01,\n",
      "            2.2390e+01,  1.6980e+01],\n",
      "          [ 2.9002e+01,  3.5764e+01,  1.6980e+01,  ...,  3.7267e+01,\n",
      "            3.7567e+01,  3.1707e+01],\n",
      "          [ 2.5546e+01,  2.6748e+01,  1.4426e+01,  ...,  3.6816e+01,\n",
      "            3.5463e+01,  3.2157e+01],\n",
      "          ...,\n",
      "          [ 2.5245e+01,  3.1556e+01,  2.6898e+01,  ...,  2.7800e+01,\n",
      "            2.7349e+01,  2.7048e+01],\n",
      "          [ 2.6748e+01,  2.8701e+01,  3.0805e+01,  ...,  2.8701e+01,\n",
      "            3.0054e+01,  3.2007e+01],\n",
      "          [ 4.1023e+01,  4.6283e+01,  4.6733e+01,  ...,  4.6283e+01,\n",
      "            4.7635e+01,  4.3878e+01]],\n",
      "\n",
      "         [[-8.1596e+01, -4.2075e+01, -3.4862e+01,  ..., -3.1707e+01,\n",
      "           -8.4150e+00, -2.7048e+01],\n",
      "          [-8.2197e+01, -4.4179e+01, -3.8018e+01,  ..., -1.8182e+01,\n",
      "           -2.9302e+01, -3.9671e+01],\n",
      "          [-7.9191e+01, -3.6665e+01, -2.7499e+01,  ..., -7.8290e+01,\n",
      "           -6.6869e+01, -5.5599e+01],\n",
      "          ...,\n",
      "          [-5.4247e+01, -3.5463e+01, -3.2308e+01,  ..., -3.6966e+01,\n",
      "           -3.4111e+01, -4.1624e+01],\n",
      "          [-5.7553e+01, -4.2376e+01, -4.8988e+01,  ..., -4.7936e+01,\n",
      "           -4.3428e+01, -5.1242e+01],\n",
      "          [-2.4343e+01, -1.4276e+01, -1.7882e+01,  ..., -1.5177e+01,\n",
      "           -1.8784e+01, -3.1406e+01]]]], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "conv_int = torch.nn.Conv2d(in_channels = 64, out_channels=64, kernel_size = 3, bias = False)\n",
    "conv_int.weight = torch.nn.parameter.Parameter(weight_int)\n",
    "\n",
    "output_int =  conv_int(x_int)    # output_int can be calculated with conv_int and x_int\n",
    "output_recovered = output_int*x_delta*w_delta  # recover with x_delta and w_delta\n",
    "print(output_recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "designed-auction",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ResNet_Cifar' object has no attribute 'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_110/3336704267.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconv_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mconv_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moutput_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1615\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ResNet_Cifar' object has no attribute 'features'"
     ]
    }
   ],
   "source": [
    "#### input floating number / weight quantized version\n",
    "\n",
    "conv_ref = torch.nn.Conv2d(in_channels = 64, out_channels=64, kernel_size = 3, bias = False)\n",
    "conv_ref.weight = model.features[3].weight_q \n",
    "\n",
    "output_ref = conv_ref(x)\n",
    "print(output_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157dffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = abs( output_ref - output_recovered )\n",
    "print(difference.mean())  ## It should be small, e.g.,2.3 in my trainned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### input floating number / weight floating number version\n",
    "\n",
    "conv_ref = torch.nn.Conv2d(in_channels = 64, out_channels=64, kernel_size = 3, bias = False)\n",
    "weight = model.features[3].weight\n",
    "mean = weight.data.mean()\n",
    "std = weight.data.std()\n",
    "conv_ref.weight = torch.nn.parameter.Parameter(weight.add(-mean).div(std))\n",
    "\n",
    "output_ref = conv_ref(x)\n",
    "print(output_ref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = abs( output_ref - output_recovered )\n",
    "print(difference.mean())  ## It should be small, e.g.,2.3 in my trainned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-significance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-witch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-barbados",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-serbia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
