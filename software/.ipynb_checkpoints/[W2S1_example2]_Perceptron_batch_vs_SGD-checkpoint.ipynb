{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "miniature-siemens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=2, out_features=1, bias=False)\n",
      ")\n",
      "[Parameter containing:\n",
      "tensor([[ 1., -1.]], requires_grad=True)]\n",
      "Epoch 0 - loss: 9.0\n",
      "Epoch 0 - loss: 60.840003967285156\n",
      "Epoch 0 - loss: 48.16359329223633\n",
      "Epoch 1 - loss: 47.52723693847656\n",
      "Epoch 1 - loss: 193.33233642578125\n",
      "Epoch 1 - loss: 1.0173128843307495\n",
      "Epoch 2 - loss: 0.45298048853874207\n",
      "Epoch 2 - loss: 24.202863693237305\n",
      "Epoch 2 - loss: 88.83402252197266\n",
      "Epoch 3 - loss: 41.247581481933594\n",
      "Epoch 3 - loss: 182.4311065673828\n",
      "Epoch 3 - loss: 1.685847282409668\n",
      "Epoch 4 - loss: 0.5527670979499817\n",
      "Epoch 4 - loss: 23.358642578125\n",
      "Epoch 4 - loss: 89.11278533935547\n",
      "Epoch 5 - loss: 40.98900604248047\n",
      "Epoch 5 - loss: 181.1503143310547\n",
      "Epoch 5 - loss: 1.635256290435791\n",
      "Epoch 6 - loss: 0.573534369468689\n",
      "Epoch 6 - loss: 22.94943618774414\n",
      "Epoch 6 - loss: 88.66230010986328\n",
      "Epoch 7 - loss: 40.82246398925781\n",
      "Epoch 7 - loss: 180.02647399902344\n",
      "Epoch 7 - loss: 1.5735151767730713\n",
      "Epoch 8 - loss: 0.5932254791259766\n",
      "Epoch 8 - loss: 22.552209854125977\n",
      "Epoch 8 - loss: 88.20365142822266\n",
      "Epoch 9 - loss: 40.65843963623047\n",
      "Epoch 9 - loss: 178.91358947753906\n",
      "Epoch 9 - loss: 1.5130443572998047\n",
      "Epoch 10 - loss: 0.6131349205970764\n",
      "Epoch 10 - loss: 22.160335540771484\n",
      "Epoch 10 - loss: 87.74807739257812\n",
      "Epoch 11 - loss: 40.49551010131836\n",
      "Epoch 11 - loss: 177.80923461914062\n",
      "Epoch 11 - loss: 1.4540135860443115\n",
      "Epoch 12 - loss: 0.6332811117172241\n",
      "Epoch 12 - loss: 21.77363395690918\n",
      "Epoch 12 - loss: 87.29572296142578\n",
      "Epoch 13 - loss: 40.33363723754883\n",
      "Epoch 13 - loss: 176.7132568359375\n",
      "Epoch 13 - loss: 1.396427869796753\n",
      "Epoch 14 - loss: 0.6536576747894287\n",
      "Epoch 14 - loss: 21.39208984375\n",
      "Epoch 14 - loss: 86.84661102294922\n",
      "Epoch 15 - loss: 40.17283630371094\n",
      "Epoch 15 - loss: 175.6256866455078\n",
      "Epoch 15 - loss: 1.3402595520019531\n",
      "Epoch 16 - loss: 0.6742618083953857\n",
      "Epoch 16 - loss: 21.01564598083496\n",
      "Epoch 16 - loss: 86.40071105957031\n",
      "Epoch 17 - loss: 40.01309585571289\n",
      "Epoch 17 - loss: 174.54640197753906\n",
      "Epoch 17 - loss: 1.2854949235916138\n",
      "Epoch 18 - loss: 0.695088803768158\n",
      "Epoch 18 - loss: 20.644245147705078\n",
      "Epoch 18 - loss: 85.95800018310547\n",
      "Epoch 19 - loss: 39.854400634765625\n",
      "Epoch 19 - loss: 173.47537231445312\n",
      "Epoch 19 - loss: 1.232109785079956\n",
      "Epoch 20 - loss: 0.7161365151405334\n",
      "Epoch 20 - loss: 20.27781105041504\n",
      "Epoch 20 - loss: 85.51839447021484\n",
      "Epoch 21 - loss: 39.69672393798828\n",
      "Epoch 21 - loss: 172.41246032714844\n",
      "Epoch 21 - loss: 1.180097222328186\n",
      "Epoch 22 - loss: 0.7373993396759033\n",
      "Epoch 22 - loss: 19.91631507873535\n",
      "Epoch 22 - loss: 85.08194732666016\n",
      "Epoch 23 - loss: 39.540077209472656\n",
      "Epoch 23 - loss: 171.35763549804688\n",
      "Epoch 23 - loss: 1.129433274269104\n",
      "Epoch 24 - loss: 0.7588741183280945\n",
      "Epoch 24 - loss: 19.5596923828125\n",
      "Epoch 24 - loss: 84.64859771728516\n",
      "Epoch 25 - loss: 39.38447570800781\n",
      "Epoch 25 - loss: 170.31094360351562\n",
      "Epoch 25 - loss: 1.0801048278808594\n",
      "Epoch 26 - loss: 0.7805564403533936\n",
      "Epoch 26 - loss: 19.207916259765625\n",
      "Epoch 26 - loss: 84.21830749511719\n",
      "Epoch 27 - loss: 39.229881286621094\n",
      "Epoch 27 - loss: 169.2721710205078\n",
      "Epoch 27 - loss: 1.032092809677124\n",
      "Epoch 28 - loss: 0.802444577217102\n",
      "Epoch 28 - loss: 18.860891342163086\n",
      "Epoch 28 - loss: 83.79109191894531\n",
      "Epoch 29 - loss: 39.0762939453125\n",
      "Epoch 29 - loss: 168.2412109375\n",
      "Epoch 29 - loss: 0.9853919744491577\n",
      "Epoch 30 - loss: 0.8245315551757812\n",
      "Epoch 30 - loss: 18.51861572265625\n",
      "Epoch 30 - loss: 83.36691284179688\n",
      "Epoch 31 - loss: 38.923702239990234\n",
      "Epoch 31 - loss: 167.21820068359375\n",
      "Epoch 31 - loss: 0.9399775266647339\n",
      "Epoch 32 - loss: 0.8468149900436401\n",
      "Epoch 32 - loss: 18.181028366088867\n",
      "Epoch 32 - loss: 82.94575500488281\n",
      "Epoch 33 - loss: 38.772117614746094\n",
      "Epoch 33 - loss: 166.2029266357422\n",
      "Epoch 33 - loss: 0.8958330154418945\n",
      "Epoch 34 - loss: 0.8692919611930847\n",
      "Epoch 34 - loss: 17.84805679321289\n",
      "Epoch 34 - loss: 82.52757263183594\n",
      "Epoch 35 - loss: 38.62151336669922\n",
      "Epoch 35 - loss: 165.19546508789062\n",
      "Epoch 35 - loss: 0.8529386520385742\n",
      "Epoch 36 - loss: 0.8919594883918762\n",
      "Epoch 36 - loss: 17.5196533203125\n",
      "Epoch 36 - loss: 82.11231231689453\n",
      "Epoch 37 - loss: 38.47188186645508\n",
      "Epoch 37 - loss: 164.19544982910156\n",
      "Epoch 37 - loss: 0.8112924098968506\n",
      "Epoch 38 - loss: 0.9148129820823669\n",
      "Epoch 38 - loss: 17.195783615112305\n",
      "Epoch 38 - loss: 81.70002746582031\n",
      "Epoch 39 - loss: 38.323219299316406\n",
      "Epoch 39 - loss: 163.20309448242188\n",
      "Epoch 39 - loss: 0.7708677053451538\n",
      "Epoch 40 - loss: 0.9378498196601868\n",
      "Epoch 40 - loss: 16.876386642456055\n",
      "Epoch 40 - loss: 81.29064178466797\n",
      "Epoch 41 - loss: 38.175533294677734\n",
      "Epoch 41 - loss: 162.21827697753906\n",
      "Epoch 41 - loss: 0.7316538095474243\n",
      "Epoch 42 - loss: 0.9610660672187805\n",
      "Epoch 42 - loss: 16.561420440673828\n",
      "Epoch 42 - loss: 80.8841323852539\n",
      "Epoch 43 - loss: 38.02879333496094\n",
      "Epoch 43 - loss: 161.24090576171875\n",
      "Epoch 43 - loss: 0.693635106086731\n",
      "Epoch 44 - loss: 0.9844580292701721\n",
      "Epoch 44 - loss: 16.250837326049805\n",
      "Epoch 44 - loss: 80.48049926757812\n",
      "Epoch 45 - loss: 37.882999420166016\n",
      "Epoch 45 - loss: 160.27090454101562\n",
      "Epoch 45 - loss: 0.6567976474761963\n",
      "Epoch 46 - loss: 1.0080230236053467\n",
      "Epoch 46 - loss: 15.944589614868164\n",
      "Epoch 46 - loss: 80.0797119140625\n",
      "Epoch 47 - loss: 37.73816680908203\n",
      "Epoch 47 - loss: 159.30828857421875\n",
      "Epoch 47 - loss: 0.6211260557174683\n",
      "Epoch 48 - loss: 1.0317561626434326\n",
      "Epoch 48 - loss: 15.642642974853516\n",
      "Epoch 48 - loss: 79.6817626953125\n",
      "Epoch 49 - loss: 37.59426498413086\n",
      "Epoch 49 - loss: 158.35296630859375\n",
      "Epoch 49 - loss: 0.5866096019744873\n",
      "Epoch 50 - loss: 1.0556546449661255\n",
      "Epoch 50 - loss: 15.344953536987305\n",
      "Epoch 50 - loss: 79.28660583496094\n",
      "Epoch 51 - loss: 37.4512939453125\n",
      "Epoch 51 - loss: 157.4048309326172\n",
      "Epoch 51 - loss: 0.5532287359237671\n",
      "Epoch 52 - loss: 1.0797163248062134\n",
      "Epoch 52 - loss: 15.0514554977417\n",
      "Epoch 52 - loss: 78.89422607421875\n",
      "Epoch 53 - loss: 37.30923843383789\n",
      "Epoch 53 - loss: 156.4637908935547\n",
      "Epoch 53 - loss: 0.5209743976593018\n",
      "Epoch 54 - loss: 1.103936791419983\n",
      "Epoch 54 - loss: 14.762120246887207\n",
      "Epoch 54 - loss: 78.50464630126953\n",
      "Epoch 55 - loss: 37.168121337890625\n",
      "Epoch 55 - loss: 155.5299530029297\n",
      "Epoch 55 - loss: 0.48982885479927063\n",
      "Epoch 56 - loss: 1.1283130645751953\n",
      "Epoch 56 - loss: 14.476899147033691\n",
      "Epoch 56 - loss: 78.11776733398438\n",
      "Epoch 57 - loss: 37.027896881103516\n",
      "Epoch 57 - loss: 154.60316467285156\n",
      "Epoch 57 - loss: 0.4597790241241455\n",
      "Epoch 58 - loss: 1.1528418064117432\n",
      "Epoch 58 - loss: 14.195751190185547\n",
      "Epoch 58 - loss: 77.73362731933594\n",
      "Epoch 59 - loss: 36.88858413696289\n",
      "Epoch 59 - loss: 153.68331909179688\n",
      "Epoch 59 - loss: 0.4308067560195923\n",
      "Epoch 60 - loss: 1.1775225400924683\n",
      "Epoch 60 - loss: 13.918590545654297\n",
      "Epoch 60 - loss: 77.35214233398438\n",
      "Epoch 61 - loss: 36.75017166137695\n",
      "Epoch 61 - loss: 152.77041625976562\n",
      "Epoch 61 - loss: 0.4029043912887573\n",
      "Epoch 62 - loss: 1.2023496627807617\n",
      "Epoch 62 - loss: 13.645424842834473\n",
      "Epoch 62 - loss: 76.97335815429688\n",
      "Epoch 63 - loss: 36.612632751464844\n",
      "Epoch 63 - loss: 151.86436462402344\n",
      "Epoch 63 - loss: 0.3760589063167572\n",
      "Epoch 64 - loss: 1.2273201942443848\n",
      "Epoch 64 - loss: 13.376198768615723\n",
      "Epoch 64 - loss: 76.59722137451172\n",
      "Epoch 65 - loss: 36.475990295410156\n",
      "Epoch 65 - loss: 150.9651336669922\n",
      "Epoch 65 - loss: 0.3502528965473175\n",
      "Epoch 66 - loss: 1.2524335384368896\n",
      "Epoch 66 - loss: 13.11085033416748\n",
      "Epoch 66 - loss: 76.22370147705078\n",
      "Epoch 67 - loss: 36.3402214050293\n",
      "Epoch 67 - loss: 150.07264709472656\n",
      "Epoch 67 - loss: 0.32547610998153687\n",
      "Epoch 68 - loss: 1.2776827812194824\n",
      "Epoch 68 - loss: 12.849363327026367\n",
      "Epoch 68 - loss: 75.85279083251953\n",
      "Epoch 69 - loss: 36.20531463623047\n",
      "Epoch 69 - loss: 149.1868438720703\n",
      "Epoch 69 - loss: 0.30171602964401245\n",
      "Epoch 70 - loss: 1.303067922592163\n",
      "Epoch 70 - loss: 12.59168815612793\n",
      "Epoch 70 - loss: 75.48448944091797\n",
      "Epoch 71 - loss: 36.07127380371094\n",
      "Epoch 71 - loss: 148.3076629638672\n",
      "Epoch 71 - loss: 0.27895811200141907\n",
      "Epoch 72 - loss: 1.3285852670669556\n",
      "Epoch 72 - loss: 12.337777137756348\n",
      "Epoch 72 - loss: 75.11873626708984\n",
      "Epoch 73 - loss: 35.93810272216797\n",
      "Epoch 73 - loss: 147.43511962890625\n",
      "Epoch 73 - loss: 0.25719210505485535\n",
      "Epoch 74 - loss: 1.3542306423187256\n",
      "Epoch 74 - loss: 12.087604522705078\n",
      "Epoch 74 - loss: 74.75557708740234\n",
      "Epoch 75 - loss: 35.80579376220703\n",
      "Epoch 75 - loss: 146.56915283203125\n",
      "Epoch 75 - loss: 0.23640374839305878\n",
      "Epoch 76 - loss: 1.3800013065338135\n",
      "Epoch 76 - loss: 11.841129302978516\n",
      "Epoch 76 - loss: 74.39496612548828\n",
      "Epoch 77 - loss: 35.674320220947266\n",
      "Epoch 77 - loss: 145.709716796875\n",
      "Epoch 77 - loss: 0.21657827496528625\n",
      "Epoch 78 - loss: 1.405896782875061\n",
      "Epoch 78 - loss: 11.59829044342041\n",
      "Epoch 78 - loss: 74.03682708740234\n",
      "Epoch 79 - loss: 35.54368591308594\n",
      "Epoch 79 - loss: 144.8566436767578\n",
      "Epoch 79 - loss: 0.1977057158946991\n",
      "Epoch 80 - loss: 1.431913137435913\n",
      "Epoch 80 - loss: 11.35905933380127\n",
      "Epoch 80 - loss: 73.68118286132812\n",
      "Epoch 81 - loss: 35.413883209228516\n",
      "Epoch 81 - loss: 144.0098876953125\n",
      "Epoch 81 - loss: 0.17977581918239594\n",
      "Epoch 82 - loss: 1.4580481052398682\n",
      "Epoch 82 - loss: 11.123392105102539\n",
      "Epoch 82 - loss: 73.32803344726562\n",
      "Epoch 83 - loss: 35.28493118286133\n",
      "Epoch 83 - loss: 143.16958618164062\n",
      "Epoch 83 - loss: 0.16277191042900085\n",
      "Epoch 84 - loss: 1.4842987060546875\n",
      "Epoch 84 - loss: 10.891257286071777\n",
      "Epoch 84 - loss: 72.97732543945312\n",
      "Epoch 85 - loss: 35.156776428222656\n",
      "Epoch 85 - loss: 142.33551025390625\n",
      "Epoch 85 - loss: 0.1466856300830841\n",
      "Epoch 86 - loss: 1.5106598138809204\n",
      "Epoch 86 - loss: 10.662623405456543\n",
      "Epoch 86 - loss: 72.62907409667969\n",
      "Epoch 87 - loss: 35.02945327758789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 - loss: 141.5077362060547\n",
      "Epoch 87 - loss: 0.13150320947170258\n",
      "Epoch 88 - loss: 1.5371311902999878\n",
      "Epoch 88 - loss: 10.437438011169434\n",
      "Epoch 88 - loss: 72.283203125\n",
      "Epoch 89 - loss: 34.902931213378906\n",
      "Epoch 89 - loss: 140.68603515625\n",
      "Epoch 89 - loss: 0.11721332371234894\n",
      "Epoch 90 - loss: 1.5637125968933105\n",
      "Epoch 90 - loss: 10.215654373168945\n",
      "Epoch 90 - loss: 71.93976593017578\n",
      "Epoch 91 - loss: 34.77722930908203\n",
      "Epoch 91 - loss: 139.8705291748047\n",
      "Epoch 91 - loss: 0.10380657762289047\n",
      "Epoch 92 - loss: 1.5903961658477783\n",
      "Epoch 92 - loss: 9.997271537780762\n",
      "Epoch 92 - loss: 71.59872436523438\n",
      "Epoch 93 - loss: 34.65231704711914\n",
      "Epoch 93 - loss: 139.0611572265625\n",
      "Epoch 93 - loss: 0.09126798063516617\n",
      "Epoch 94 - loss: 1.6171818971633911\n",
      "Epoch 94 - loss: 9.782225608825684\n",
      "Epoch 94 - loss: 71.260009765625\n",
      "Epoch 95 - loss: 34.5281982421875\n",
      "Epoch 95 - loss: 138.25772094726562\n",
      "Epoch 95 - loss: 0.07958778738975525\n",
      "Epoch 96 - loss: 1.6440701484680176\n",
      "Epoch 96 - loss: 9.570470809936523\n",
      "Epoch 96 - loss: 70.92364501953125\n",
      "Epoch 97 - loss: 34.40486145019531\n",
      "Epoch 97 - loss: 137.4602508544922\n",
      "Epoch 97 - loss: 0.06875503063201904\n",
      "Epoch 98 - loss: 1.6710543632507324\n",
      "Epoch 98 - loss: 9.361984252929688\n",
      "Epoch 98 - loss: 70.58960723876953\n",
      "Epoch 99 - loss: 34.28231430053711\n",
      "Epoch 99 - loss: 136.66873168945312\n",
      "Epoch 99 - loss: 0.05875876545906067\n",
      "Epoch 100 - loss: 1.6981345415115356\n",
      "Epoch 100 - loss: 9.156733512878418\n",
      "Epoch 100 - loss: 70.25787353515625\n",
      "Epoch 101 - loss: 34.16053771972656\n",
      "Epoch 101 - loss: 135.8831024169922\n",
      "Epoch 101 - loss: 0.04958769679069519\n",
      "Epoch 102 - loss: 1.7253059148788452\n",
      "Epoch 102 - loss: 8.954684257507324\n",
      "Epoch 102 - loss: 69.9284439086914\n",
      "Epoch 103 - loss: 34.03953552246094\n",
      "Epoch 103 - loss: 135.10328674316406\n",
      "Epoch 103 - loss: 0.041231099516153336\n",
      "Epoch 104 - loss: 1.7525678873062134\n",
      "Epoch 104 - loss: 8.755794525146484\n",
      "Epoch 104 - loss: 69.6012954711914\n",
      "Epoch 105 - loss: 33.9193115234375\n",
      "Epoch 105 - loss: 134.329345703125\n",
      "Epoch 105 - loss: 0.0336776077747345\n",
      "Epoch 106 - loss: 1.7799164056777954\n",
      "Epoch 106 - loss: 8.560033798217773\n",
      "Epoch 106 - loss: 69.2763900756836\n",
      "Epoch 107 - loss: 33.799842834472656\n",
      "Epoch 107 - loss: 133.56114196777344\n",
      "Epoch 107 - loss: 0.02691650390625\n",
      "Epoch 108 - loss: 1.8073508739471436\n",
      "Epoch 108 - loss: 8.367361068725586\n",
      "Epoch 108 - loss: 68.95370483398438\n",
      "Epoch 109 - loss: 33.68110656738281\n",
      "Epoch 109 - loss: 132.79849243164062\n",
      "Epoch 109 - loss: 0.02093837969005108\n",
      "Epoch 110 - loss: 1.8348712921142578\n",
      "Epoch 110 - loss: 8.177736282348633\n",
      "Epoch 110 - loss: 68.63325500488281\n",
      "Epoch 111 - loss: 33.56313705444336\n",
      "Epoch 111 - loss: 132.04161071777344\n",
      "Epoch 111 - loss: 0.015731994062662125\n",
      "Epoch 112 - loss: 1.8624694347381592\n",
      "Epoch 112 - loss: 7.991149425506592\n",
      "Epoch 112 - loss: 68.31502532958984\n",
      "Epoch 113 - loss: 33.445919036865234\n",
      "Epoch 113 - loss: 131.29031372070312\n",
      "Epoch 113 - loss: 0.011287805624306202\n",
      "Epoch 114 - loss: 1.8901457786560059\n",
      "Epoch 114 - loss: 7.807559967041016\n",
      "Epoch 114 - loss: 67.99899291992188\n",
      "Epoch 115 - loss: 33.329437255859375\n",
      "Epoch 115 - loss: 130.54464721679688\n",
      "Epoch 115 - loss: 0.007594224996864796\n",
      "Epoch 116 - loss: 1.9178993701934814\n",
      "Epoch 116 - loss: 7.626917839050293\n",
      "Epoch 116 - loss: 67.68510437011719\n",
      "Epoch 117 - loss: 33.213687896728516\n",
      "Epoch 117 - loss: 129.8043975830078\n",
      "Epoch 117 - loss: 0.004642413929104805\n",
      "Epoch 118 - loss: 1.945726990699768\n",
      "Epoch 118 - loss: 7.449202060699463\n",
      "Epoch 118 - loss: 67.37336730957031\n",
      "Epoch 119 - loss: 33.09865951538086\n",
      "Epoch 119 - loss: 129.06964111328125\n",
      "Epoch 119 - loss: 0.0024216780439019203\n",
      "Epoch 120 - loss: 1.973628282546997\n",
      "Epoch 120 - loss: 7.274368762969971\n",
      "Epoch 120 - loss: 67.06376647949219\n",
      "Epoch 121 - loss: 32.98434829711914\n",
      "Epoch 121 - loss: 128.34024047851562\n",
      "Epoch 121 - loss: 0.0009226119145750999\n",
      "Epoch 122 - loss: 2.0015981197357178\n",
      "Epoch 122 - loss: 7.102407932281494\n",
      "Epoch 122 - loss: 66.75631713867188\n",
      "Epoch 123 - loss: 32.87077331542969\n",
      "Epoch 123 - loss: 127.61637115478516\n",
      "Epoch 123 - loss: 0.00013510302233044058\n",
      "Epoch 124 - loss: 2.0296342372894287\n",
      "Epoch 124 - loss: 6.933279991149902\n",
      "Epoch 124 - loss: 66.45097351074219\n",
      "Epoch 125 - loss: 32.75791931152344\n",
      "Epoch 125 - loss: 126.8978042602539\n",
      "Epoch 125 - loss: 4.9588794354349375e-05\n",
      "Epoch 126 - loss: 2.0577361583709717\n",
      "Epoch 126 - loss: 6.76694393157959\n",
      "Epoch 126 - loss: 66.14769744873047\n",
      "Epoch 127 - loss: 32.645748138427734\n",
      "Epoch 127 - loss: 126.18448638916016\n",
      "Epoch 127 - loss: 0.0006565545918419957\n",
      "Epoch 128 - loss: 2.0859038829803467\n",
      "Epoch 128 - loss: 6.60336446762085\n",
      "Epoch 128 - loss: 65.84648895263672\n",
      "Epoch 129 - loss: 32.53429412841797\n",
      "Epoch 129 - loss: 125.4764175415039\n",
      "Epoch 129 - loss: 0.00194639153778553\n",
      "Epoch 130 - loss: 2.114131212234497\n",
      "Epoch 130 - loss: 6.44252872467041\n",
      "Epoch 130 - loss: 65.54735565185547\n",
      "Epoch 131 - loss: 32.423526763916016\n",
      "Epoch 131 - loss: 124.77354431152344\n",
      "Epoch 131 - loss: 0.0039095887914299965\n",
      "Epoch 132 - loss: 2.142418622970581\n",
      "Epoch 132 - loss: 6.284399509429932\n",
      "Epoch 132 - loss: 65.25028228759766\n",
      "Epoch 133 - loss: 32.313472747802734\n",
      "Epoch 133 - loss: 124.07595825195312\n",
      "Epoch 133 - loss: 0.00653728237375617\n",
      "Epoch 134 - loss: 2.170761823654175\n",
      "Epoch 134 - loss: 6.1289448738098145\n",
      "Epoch 134 - loss: 64.95523071289062\n",
      "Epoch 135 - loss: 32.20409393310547\n",
      "Epoch 135 - loss: 123.38346099853516\n",
      "Epoch 135 - loss: 0.00982026569545269\n",
      "Epoch 136 - loss: 2.1991610527038574\n",
      "Epoch 136 - loss: 5.976130485534668\n",
      "Epoch 136 - loss: 64.66216278076172\n",
      "Epoch 137 - loss: 32.09540557861328\n",
      "Epoch 137 - loss: 122.69603729248047\n",
      "Epoch 137 - loss: 0.013749008066952229\n",
      "Epoch 138 - loss: 2.227614164352417\n",
      "Epoch 138 - loss: 5.825935363769531\n",
      "Epoch 138 - loss: 64.37110900878906\n",
      "Epoch 139 - loss: 31.987398147583008\n",
      "Epoch 139 - loss: 122.01364135742188\n",
      "Epoch 139 - loss: 0.018314778804779053\n",
      "Epoch 140 - loss: 2.2561194896698\n",
      "Epoch 140 - loss: 5.678320407867432\n",
      "Epoch 140 - loss: 64.0820541381836\n",
      "Epoch 141 - loss: 31.88006019592285\n",
      "Epoch 141 - loss: 121.33626556396484\n",
      "Epoch 141 - loss: 0.023508287966251373\n",
      "Epoch 142 - loss: 2.284672260284424\n",
      "Epoch 142 - loss: 5.533269882202148\n",
      "Epoch 142 - loss: 63.79496383666992\n",
      "Epoch 143 - loss: 31.773399353027344\n",
      "Epoch 143 - loss: 120.66390991210938\n",
      "Epoch 143 - loss: 0.029322434216737747\n",
      "Epoch 144 - loss: 2.313276767730713\n",
      "Epoch 144 - loss: 5.390729904174805\n",
      "Epoch 144 - loss: 63.50979995727539\n",
      "Epoch 145 - loss: 31.667394638061523\n",
      "Epoch 145 - loss: 119.99639129638672\n",
      "Epoch 145 - loss: 0.03574701026082039\n",
      "Epoch 146 - loss: 2.3419265747070312\n",
      "Epoch 146 - loss: 5.250690937042236\n",
      "Epoch 146 - loss: 63.2265625\n",
      "Epoch 147 - loss: 31.562042236328125\n",
      "Epoch 147 - loss: 119.33377075195312\n",
      "Epoch 147 - loss: 0.042773135006427765\n",
      "Epoch 148 - loss: 2.3706204891204834\n",
      "Epoch 148 - loss: 5.113123416900635\n",
      "Epoch 148 - loss: 62.94527053833008\n",
      "Epoch 149 - loss: 31.45735740661621\n",
      "Epoch 149 - loss: 118.67599487304688\n",
      "Epoch 149 - loss: 0.05039283633232117\n",
      "Epoch 150 - loss: 2.3993561267852783\n",
      "Epoch 150 - loss: 4.977999210357666\n",
      "Epoch 150 - loss: 62.66588592529297\n",
      "Epoch 151 - loss: 31.35331916809082\n",
      "Epoch 151 - loss: 118.02306365966797\n",
      "Epoch 151 - loss: 0.05859844386577606\n",
      "Epoch 152 - loss: 2.4281325340270996\n",
      "Epoch 152 - loss: 4.8452887535095215\n",
      "Epoch 152 - loss: 62.388389587402344\n",
      "Epoch 153 - loss: 31.249935150146484\n",
      "Epoch 153 - loss: 117.37490844726562\n",
      "Epoch 153 - loss: 0.06738011538982391\n",
      "Epoch 154 - loss: 2.4569458961486816\n",
      "Epoch 154 - loss: 4.714975357055664\n",
      "Epoch 154 - loss: 62.11277770996094\n",
      "Epoch 155 - loss: 31.147186279296875\n",
      "Epoch 155 - loss: 116.73150634765625\n",
      "Epoch 155 - loss: 0.07672923803329468\n",
      "Epoch 156 - loss: 2.485795497894287\n",
      "Epoch 156 - loss: 4.58702278137207\n",
      "Epoch 156 - loss: 61.83906555175781\n",
      "Epoch 157 - loss: 31.045089721679688\n",
      "Epoch 157 - loss: 116.09280395507812\n",
      "Epoch 157 - loss: 0.0866406038403511\n",
      "Epoch 158 - loss: 2.5146842002868652\n",
      "Epoch 158 - loss: 4.4613938331604\n",
      "Epoch 158 - loss: 61.56716537475586\n",
      "Epoch 159 - loss: 30.943601608276367\n",
      "Epoch 159 - loss: 115.45870971679688\n",
      "Epoch 159 - loss: 0.09710390120744705\n",
      "Epoch 160 - loss: 2.543605327606201\n",
      "Epoch 160 - loss: 4.338071346282959\n",
      "Epoch 160 - loss: 61.29710006713867\n",
      "Epoch 161 - loss: 30.84275245666504\n",
      "Epoch 161 - loss: 114.82925415039062\n",
      "Epoch 161 - loss: 0.10811145603656769\n",
      "Epoch 162 - loss: 2.572558641433716\n",
      "Epoch 162 - loss: 4.2170305252075195\n",
      "Epoch 162 - loss: 61.02886962890625\n",
      "Epoch 163 - loss: 30.742530822753906\n",
      "Epoch 163 - loss: 114.20439147949219\n",
      "Epoch 163 - loss: 0.11965707689523697\n",
      "Epoch 164 - loss: 2.601544141769409\n",
      "Epoch 164 - loss: 4.098236083984375\n",
      "Epoch 164 - loss: 60.762428283691406\n",
      "Epoch 165 - loss: 30.642927169799805\n",
      "Epoch 165 - loss: 113.58406066894531\n",
      "Epoch 165 - loss: 0.13172948360443115\n",
      "Epoch 166 - loss: 2.6305551528930664\n",
      "Epoch 166 - loss: 3.981679916381836\n",
      "Epoch 166 - loss: 60.497802734375\n",
      "Epoch 167 - loss: 30.5439395904541\n",
      "Epoch 167 - loss: 112.96821594238281\n",
      "Epoch 167 - loss: 0.14432398974895477\n",
      "Epoch 168 - loss: 2.6595964431762695\n",
      "Epoch 168 - loss: 3.8673183917999268\n",
      "Epoch 168 - loss: 60.23495101928711\n",
      "Epoch 169 - loss: 30.445552825927734\n",
      "Epoch 169 - loss: 112.35689544677734\n",
      "Epoch 169 - loss: 0.15743286907672882\n",
      "Epoch 170 - loss: 2.6886651515960693\n",
      "Epoch 170 - loss: 3.75512957572937\n",
      "Epoch 170 - loss: 59.97385025024414\n",
      "Epoch 171 - loss: 30.347776412963867\n",
      "Epoch 171 - loss: 111.7499771118164\n",
      "Epoch 171 - loss: 0.17104679346084595\n",
      "Epoch 172 - loss: 2.71775484085083\n",
      "Epoch 172 - loss: 3.6450998783111572\n",
      "Epoch 172 - loss: 59.71451950073242\n",
      "Epoch 173 - loss: 30.250608444213867\n",
      "Epoch 173 - loss: 111.14743041992188\n",
      "Epoch 173 - loss: 0.18515869975090027\n",
      "Epoch 174 - loss: 2.7468676567077637\n",
      "Epoch 174 - loss: 3.537196159362793\n",
      "Epoch 174 - loss: 59.456932067871094\n",
      "Epoch 175 - loss: 30.154041290283203\n",
      "Epoch 175 - loss: 110.54933166503906\n",
      "Epoch 175 - loss: 0.19976170361042023\n",
      "Epoch 176 - loss: 2.776000499725342\n",
      "Epoch 176 - loss: 3.431399345397949\n",
      "Epoch 176 - loss: 59.201087951660156\n",
      "Epoch 177 - loss: 30.05805778503418\n",
      "Epoch 177 - loss: 109.95552062988281\n",
      "Epoch 177 - loss: 0.21484729647636414\n",
      "Epoch 178 - loss: 2.8051528930664062\n",
      "Epoch 178 - loss: 3.3276827335357666\n",
      "Epoch 178 - loss: 58.94696044921875\n",
      "Epoch 179 - loss: 29.96268081665039\n",
      "Epoch 179 - loss: 109.36605834960938\n",
      "Epoch 179 - loss: 0.23041146993637085\n",
      "Epoch 180 - loss: 2.8343257904052734\n",
      "Epoch 180 - loss: 3.226015090942383\n",
      "Epoch 180 - loss: 58.69451904296875\n",
      "Epoch 181 - loss: 29.867874145507812\n",
      "Epoch 181 - loss: 108.78080749511719\n",
      "Epoch 181 - loss: 0.24644409120082855\n",
      "Epoch 182 - loss: 2.863513946533203\n",
      "Epoch 182 - loss: 3.126377582550049\n",
      "Epoch 182 - loss: 58.44377899169922\n",
      "Epoch 183 - loss: 29.773658752441406\n",
      "Epoch 183 - loss: 108.19984436035156\n",
      "Epoch 183 - loss: 0.26293960213661194\n",
      "Epoch 184 - loss: 2.892717123031616\n",
      "Epoch 184 - loss: 3.0287508964538574\n",
      "Epoch 184 - loss: 58.19470977783203\n",
      "Epoch 185 - loss: 29.680017471313477\n",
      "Epoch 185 - loss: 107.62301635742188\n",
      "Epoch 185 - loss: 0.2798897325992584\n",
      "Epoch 186 - loss: 2.9219348430633545\n",
      "Epoch 186 - loss: 2.9331040382385254\n",
      "Epoch 186 - loss: 57.94730758666992\n",
      "Epoch 187 - loss: 29.586956024169922\n",
      "Epoch 187 - loss: 107.05038452148438\n",
      "Epoch 187 - loss: 0.29728710651397705\n",
      "Epoch 188 - loss: 2.9511616230010986\n",
      "Epoch 188 - loss: 2.8394272327423096\n",
      "Epoch 188 - loss: 57.70157241821289\n",
      "Epoch 189 - loss: 29.494462966918945\n",
      "Epoch 189 - loss: 106.48192596435547\n",
      "Epoch 189 - loss: 0.31512653827667236\n",
      "Epoch 190 - loss: 2.980400562286377\n",
      "Epoch 190 - loss: 2.747687339782715\n",
      "Epoch 190 - loss: 57.45747756958008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191 - loss: 29.402536392211914\n",
      "Epoch 191 - loss: 105.91754913330078\n",
      "Epoch 191 - loss: 0.33339980244636536\n",
      "Epoch 192 - loss: 3.0096497535705566\n",
      "Epoch 192 - loss: 2.657862663269043\n",
      "Epoch 192 - loss: 57.215023040771484\n",
      "Epoch 193 - loss: 29.311180114746094\n",
      "Epoch 193 - loss: 105.35726928710938\n",
      "Epoch 193 - loss: 0.35210320353507996\n",
      "Epoch 194 - loss: 3.0389068126678467\n",
      "Epoch 194 - loss: 2.569927453994751\n",
      "Epoch 194 - loss: 56.97416687011719\n",
      "Epoch 195 - loss: 29.220373153686523\n",
      "Epoch 195 - loss: 104.80096435546875\n",
      "Epoch 195 - loss: 0.3712274730205536\n",
      "Epoch 196 - loss: 3.068171977996826\n",
      "Epoch 196 - loss: 2.4838600158691406\n",
      "Epoch 196 - loss: 56.73491287231445\n",
      "Epoch 197 - loss: 29.13011360168457\n",
      "Epoch 197 - loss: 104.24864196777344\n",
      "Epoch 197 - loss: 0.39076685905456543\n",
      "Epoch 198 - loss: 3.097444772720337\n",
      "Epoch 198 - loss: 2.3996403217315674\n",
      "Epoch 198 - loss: 56.49724197387695\n",
      "Epoch 199 - loss: 29.0404109954834\n",
      "Epoch 199 - loss: 103.7003173828125\n",
      "Epoch 199 - loss: 0.4107156991958618\n",
      "Epoch 200 - loss: 3.1267197132110596\n",
      "Epoch 200 - loss: 2.317248582839966\n",
      "Epoch 200 - loss: 56.26115798950195\n",
      "Epoch 201 - loss: 28.951255798339844\n",
      "Epoch 201 - loss: 103.15596008300781\n",
      "Epoch 201 - loss: 0.43106719851493835\n",
      "Epoch 202 - loss: 3.155998706817627\n",
      "Epoch 202 - loss: 2.236660957336426\n",
      "Epoch 202 - loss: 56.026641845703125\n",
      "Epoch 203 - loss: 28.86264419555664\n",
      "Epoch 203 - loss: 102.61547088623047\n",
      "Epoch 203 - loss: 0.45181208848953247\n",
      "Epoch 204 - loss: 3.1852779388427734\n",
      "Epoch 204 - loss: 2.157862424850464\n",
      "Epoch 204 - loss: 55.79368209838867\n",
      "Epoch 205 - loss: 28.774566650390625\n",
      "Epoch 205 - loss: 102.0788345336914\n",
      "Epoch 205 - loss: 0.47294872999191284\n",
      "Epoch 206 - loss: 3.214561700820923\n",
      "Epoch 206 - loss: 2.0808181762695312\n",
      "Epoch 206 - loss: 55.562252044677734\n",
      "Epoch 207 - loss: 28.687021255493164\n",
      "Epoch 207 - loss: 101.54603576660156\n",
      "Epoch 207 - loss: 0.4944652318954468\n",
      "Epoch 208 - loss: 3.2438409328460693\n",
      "Epoch 208 - loss: 2.005526304244995\n",
      "Epoch 208 - loss: 55.332393646240234\n",
      "Epoch 209 - loss: 28.60002899169922\n",
      "Epoch 209 - loss: 101.01715087890625\n",
      "Epoch 209 - loss: 0.5163602828979492\n",
      "Epoch 210 - loss: 3.273117780685425\n",
      "Epoch 210 - loss: 1.9319578409194946\n",
      "Epoch 210 - loss: 55.104042053222656\n",
      "Epoch 211 - loss: 28.5135440826416\n",
      "Epoch 211 - loss: 100.49201202392578\n",
      "Epoch 211 - loss: 0.5386289358139038\n",
      "Epoch 212 - loss: 3.3023931980133057\n",
      "Epoch 212 - loss: 1.8600832223892212\n",
      "Epoch 212 - loss: 54.877193450927734\n",
      "Epoch 213 - loss: 28.427597045898438\n",
      "Epoch 213 - loss: 99.97061157226562\n",
      "Epoch 213 - loss: 0.5612589716911316\n",
      "Epoch 214 - loss: 3.3316633701324463\n",
      "Epoch 214 - loss: 1.7898938655853271\n",
      "Epoch 214 - loss: 54.651859283447266\n",
      "Epoch 215 - loss: 28.342172622680664\n",
      "Epoch 215 - loss: 99.45295715332031\n",
      "Epoch 215 - loss: 0.5842483043670654\n",
      "Epoch 216 - loss: 3.3609273433685303\n",
      "Epoch 216 - loss: 1.721369743347168\n",
      "Epoch 216 - loss: 54.42802047729492\n",
      "Epoch 217 - loss: 28.257259368896484\n",
      "Epoch 217 - loss: 98.93900299072266\n",
      "Epoch 217 - loss: 0.6075949668884277\n",
      "Epoch 218 - loss: 3.390188217163086\n",
      "Epoch 218 - loss: 1.6544779539108276\n",
      "Epoch 218 - loss: 54.20563507080078\n",
      "Epoch 219 - loss: 28.172861099243164\n",
      "Epoch 219 - loss: 98.4287109375\n",
      "Epoch 219 - loss: 0.6312853693962097\n",
      "Epoch 220 - loss: 3.4194366931915283\n",
      "Epoch 220 - loss: 1.5892165899276733\n",
      "Epoch 220 - loss: 53.984745025634766\n",
      "Epoch 221 - loss: 28.088970184326172\n",
      "Epoch 221 - loss: 97.92207336425781\n",
      "Epoch 221 - loss: 0.6553191542625427\n",
      "Epoch 222 - loss: 3.448678731918335\n",
      "Epoch 222 - loss: 1.525552749633789\n",
      "Epoch 222 - loss: 53.765296936035156\n",
      "Epoch 223 - loss: 28.005599975585938\n",
      "Epoch 223 - loss: 97.41905975341797\n",
      "Epoch 223 - loss: 0.6796887516975403\n",
      "Epoch 224 - loss: 3.4779112339019775\n",
      "Epoch 224 - loss: 1.4634747505187988\n",
      "Epoch 224 - loss: 53.54730224609375\n",
      "Epoch 225 - loss: 27.92272186279297\n",
      "Epoch 225 - loss: 96.91961669921875\n",
      "Epoch 225 - loss: 0.7043895125389099\n",
      "Epoch 226 - loss: 3.5071330070495605\n",
      "Epoch 226 - loss: 1.402957797050476\n",
      "Epoch 226 - loss: 53.33073806762695\n",
      "Epoch 227 - loss: 27.840343475341797\n",
      "Epoch 227 - loss: 96.4237060546875\n",
      "Epoch 227 - loss: 0.7294138669967651\n",
      "Epoch 228 - loss: 3.536341428756714\n",
      "Epoch 228 - loss: 1.343988299369812\n",
      "Epoch 228 - loss: 53.1156005859375\n",
      "Epoch 229 - loss: 27.758466720581055\n",
      "Epoch 229 - loss: 95.93135833740234\n",
      "Epoch 229 - loss: 0.7547574043273926\n",
      "Epoch 230 - loss: 3.5655362606048584\n",
      "Epoch 230 - loss: 1.2865471839904785\n",
      "Epoch 230 - loss: 52.90187454223633\n",
      "Epoch 231 - loss: 27.67708396911621\n",
      "Epoch 231 - loss: 95.44248962402344\n",
      "Epoch 231 - loss: 0.7804157137870789\n",
      "Epoch 232 - loss: 3.5947179794311523\n",
      "Epoch 232 - loss: 1.2306134700775146\n",
      "Epoch 232 - loss: 52.68955993652344\n",
      "Epoch 233 - loss: 27.596195220947266\n",
      "Epoch 233 - loss: 94.95710754394531\n",
      "Epoch 233 - loss: 0.8063812851905823\n",
      "Epoch 234 - loss: 3.6238834857940674\n",
      "Epoch 234 - loss: 1.1761698722839355\n",
      "Epoch 234 - loss: 52.47864532470703\n",
      "Epoch 235 - loss: 27.515790939331055\n",
      "Epoch 235 - loss: 94.47515869140625\n",
      "Epoch 235 - loss: 0.8326517343521118\n",
      "Epoch 236 - loss: 3.6530346870422363\n",
      "Epoch 236 - loss: 1.1231975555419922\n",
      "Epoch 236 - loss: 52.269100189208984\n",
      "Epoch 237 - loss: 27.435869216918945\n",
      "Epoch 237 - loss: 93.99664306640625\n",
      "Epoch 237 - loss: 0.8592230081558228\n",
      "Epoch 238 - loss: 3.6821672916412354\n",
      "Epoch 238 - loss: 1.071677803993225\n",
      "Epoch 238 - loss: 52.06093215942383\n",
      "Epoch 239 - loss: 27.356426239013672\n",
      "Epoch 239 - loss: 93.52151489257812\n",
      "Epoch 239 - loss: 0.8860823512077332\n",
      "Epoch 240 - loss: 3.7112812995910645\n",
      "Epoch 240 - loss: 1.0215988159179688\n",
      "Epoch 240 - loss: 51.8541374206543\n",
      "Epoch 241 - loss: 27.277467727661133\n",
      "Epoch 241 - loss: 93.04976654052734\n",
      "Epoch 241 - loss: 0.9132347702980042\n",
      "Epoch 242 - loss: 3.7403781414031982\n",
      "Epoch 242 - loss: 0.9729334712028503\n",
      "Epoch 242 - loss: 51.6486701965332\n",
      "Epoch 243 - loss: 27.198972702026367\n",
      "Epoch 243 - loss: 92.5813217163086\n",
      "Epoch 243 - loss: 0.9406692385673523\n",
      "Epoch 244 - loss: 3.7694544792175293\n",
      "Epoch 244 - loss: 0.9256703853607178\n",
      "Epoch 244 - loss: 51.44455337524414\n",
      "Epoch 245 - loss: 27.12095069885254\n",
      "Epoch 245 - loss: 92.11619567871094\n",
      "Epoch 245 - loss: 0.9683784246444702\n",
      "Epoch 246 - loss: 3.798509359359741\n",
      "Epoch 246 - loss: 0.8797942996025085\n",
      "Epoch 246 - loss: 51.241783142089844\n",
      "Epoch 247 - loss: 27.043399810791016\n",
      "Epoch 247 - loss: 91.65438079833984\n",
      "Epoch 247 - loss: 0.9963603019714355\n",
      "Epoch 248 - loss: 3.8275415897369385\n",
      "Epoch 248 - loss: 0.8352870941162109\n",
      "Epoch 248 - loss: 51.040348052978516\n",
      "Epoch 249 - loss: 26.96631622314453\n",
      "Epoch 249 - loss: 91.19583892822266\n",
      "Epoch 249 - loss: 1.0246132612228394\n",
      "Epoch 250 - loss: 3.8565514087677\n",
      "Epoch 250 - loss: 0.7921268939971924\n",
      "Epoch 250 - loss: 50.840206146240234\n",
      "Epoch 251 - loss: 26.88968849182129\n",
      "Epoch 251 - loss: 90.74051666259766\n",
      "Epoch 251 - loss: 1.0531281232833862\n",
      "Epoch 252 - loss: 3.8855373859405518\n",
      "Epoch 252 - loss: 0.7503032088279724\n",
      "Epoch 252 - loss: 50.641380310058594\n",
      "Epoch 253 - loss: 26.813520431518555\n",
      "Epoch 253 - loss: 90.28838348388672\n",
      "Epoch 253 - loss: 1.0819014310836792\n",
      "Epoch 254 - loss: 3.914499521255493\n",
      "Epoch 254 - loss: 0.709795355796814\n",
      "Epoch 254 - loss: 50.44384002685547\n",
      "Epoch 255 - loss: 26.737810134887695\n",
      "Epoch 255 - loss: 89.8394775390625\n",
      "Epoch 255 - loss: 1.1109298467636108\n",
      "Epoch 256 - loss: 3.9434359073638916\n",
      "Epoch 256 - loss: 0.670590341091156\n",
      "Epoch 256 - loss: 50.247589111328125\n",
      "Epoch 257 - loss: 26.66255760192871\n",
      "Epoch 257 - loss: 89.39370727539062\n",
      "Epoch 257 - loss: 1.1402060985565186\n",
      "Epoch 258 - loss: 3.9723455905914307\n",
      "Epoch 258 - loss: 0.6326689720153809\n",
      "Epoch 258 - loss: 50.0526123046875\n",
      "Epoch 259 - loss: 26.587736129760742\n",
      "Epoch 259 - loss: 88.95105743408203\n",
      "Epoch 259 - loss: 1.1697227954864502\n",
      "Epoch 260 - loss: 4.001226425170898\n",
      "Epoch 260 - loss: 0.5960198044776917\n",
      "Epoch 260 - loss: 49.858917236328125\n",
      "Epoch 261 - loss: 26.513376235961914\n",
      "Epoch 261 - loss: 88.5115737915039\n",
      "Epoch 261 - loss: 1.199483036994934\n",
      "Epoch 262 - loss: 4.0300798416137695\n",
      "Epoch 262 - loss: 0.5606240034103394\n",
      "Epoch 262 - loss: 49.666473388671875\n",
      "Epoch 263 - loss: 26.43946075439453\n",
      "Epoch 263 - loss: 88.07511138916016\n",
      "Epoch 263 - loss: 1.2294775247573853\n",
      "Epoch 264 - loss: 4.058907508850098\n",
      "Epoch 264 - loss: 0.5264624953269958\n",
      "Epoch 264 - loss: 49.47526931762695\n",
      "Epoch 265 - loss: 26.36597442626953\n",
      "Epoch 265 - loss: 87.64178466796875\n",
      "Epoch 265 - loss: 1.2597053050994873\n",
      "Epoch 266 - loss: 4.087701320648193\n",
      "Epoch 266 - loss: 0.4935261607170105\n",
      "Epoch 266 - loss: 49.285308837890625\n",
      "Epoch 267 - loss: 26.29292869567871\n",
      "Epoch 267 - loss: 87.21146392822266\n",
      "Epoch 267 - loss: 1.2901616096496582\n",
      "Epoch 268 - loss: 4.116469860076904\n",
      "Epoch 268 - loss: 0.4617936313152313\n",
      "Epoch 268 - loss: 49.09656524658203\n",
      "Epoch 269 - loss: 26.220317840576172\n",
      "Epoch 269 - loss: 86.78414154052734\n",
      "Epoch 269 - loss: 1.3208370208740234\n",
      "Epoch 270 - loss: 4.145205020904541\n",
      "Epoch 270 - loss: 0.4312538206577301\n",
      "Epoch 270 - loss: 48.909053802490234\n",
      "Epoch 271 - loss: 26.148136138916016\n",
      "Epoch 271 - loss: 86.35981750488281\n",
      "Epoch 271 - loss: 1.3517264127731323\n",
      "Epoch 272 - loss: 4.173906326293945\n",
      "Epoch 272 - loss: 0.40189412236213684\n",
      "Epoch 272 - loss: 48.72277069091797\n",
      "Epoch 273 - loss: 26.076387405395508\n",
      "Epoch 273 - loss: 85.93851470947266\n",
      "Epoch 273 - loss: 1.382836103439331\n",
      "Epoch 274 - loss: 4.202576160430908\n",
      "Epoch 274 - loss: 0.3736940920352936\n",
      "Epoch 274 - loss: 48.53766632080078\n",
      "Epoch 275 - loss: 26.005062103271484\n",
      "Epoch 275 - loss: 85.52008819580078\n",
      "Epoch 275 - loss: 1.4141522645950317\n",
      "Epoch 276 - loss: 4.23121452331543\n",
      "Epoch 276 - loss: 0.34664103388786316\n",
      "Epoch 276 - loss: 48.35376739501953\n",
      "Epoch 277 - loss: 25.934160232543945\n",
      "Epoch 277 - loss: 85.10460662841797\n",
      "Epoch 277 - loss: 1.4456698894500732\n",
      "Epoch 278 - loss: 4.25981330871582\n",
      "Epoch 278 - loss: 0.32072368264198303\n",
      "Epoch 278 - loss: 48.17106628417969\n",
      "Epoch 279 - loss: 25.863679885864258\n",
      "Epoch 279 - loss: 84.69207000732422\n",
      "Epoch 279 - loss: 1.477393627166748\n",
      "Epoch 280 - loss: 4.288381576538086\n",
      "Epoch 280 - loss: 0.2959221601486206\n",
      "Epoch 280 - loss: 47.989524841308594\n",
      "Epoch 281 - loss: 25.793611526489258\n",
      "Epoch 281 - loss: 84.28238677978516\n",
      "Epoch 281 - loss: 1.509313941001892\n",
      "Epoch 282 - loss: 4.31691312789917\n",
      "Epoch 282 - loss: 0.2722255289554596\n",
      "Epoch 282 - loss: 47.80915832519531\n",
      "Epoch 283 - loss: 25.723960876464844\n",
      "Epoch 283 - loss: 83.87554931640625\n",
      "Epoch 283 - loss: 1.541426181793213\n",
      "Epoch 284 - loss: 4.345408916473389\n",
      "Epoch 284 - loss: 0.24961867928504944\n",
      "Epoch 284 - loss: 47.629966735839844\n",
      "Epoch 285 - loss: 25.654722213745117\n",
      "Epoch 285 - loss: 83.4715576171875\n",
      "Epoch 285 - loss: 1.5737258195877075\n",
      "Epoch 286 - loss: 4.373864650726318\n",
      "Epoch 286 - loss: 0.22809001803398132\n",
      "Epoch 286 - loss: 47.451927185058594\n",
      "Epoch 287 - loss: 25.58589744567871\n",
      "Epoch 287 - loss: 83.07038879394531\n",
      "Epoch 287 - loss: 1.6062079668045044\n",
      "Epoch 288 - loss: 4.402284622192383\n",
      "Epoch 288 - loss: 0.2076241821050644\n",
      "Epoch 288 - loss: 47.2750358581543\n",
      "Epoch 289 - loss: 25.51747703552246\n",
      "Epoch 289 - loss: 82.67204284667969\n",
      "Epoch 289 - loss: 1.6388754844665527\n",
      "Epoch 290 - loss: 4.430662631988525\n",
      "Epoch 290 - loss: 0.18820704519748688\n",
      "Epoch 290 - loss: 47.09926223754883\n",
      "Epoch 291 - loss: 25.449460983276367\n",
      "Epoch 291 - loss: 82.27645111083984\n",
      "Epoch 291 - loss: 1.671721339225769\n",
      "Epoch 292 - loss: 4.459005355834961\n",
      "Epoch 292 - loss: 0.16982391476631165\n",
      "Epoch 292 - loss: 46.92462158203125\n",
      "Epoch 293 - loss: 25.381839752197266\n",
      "Epoch 293 - loss: 81.8835678100586\n",
      "Epoch 293 - loss: 1.7047362327575684\n",
      "Epoch 294 - loss: 4.487308025360107\n",
      "Epoch 294 - loss: 0.1524631232023239\n",
      "Epoch 294 - loss: 46.75111389160156\n",
      "Epoch 295 - loss: 25.31462860107422\n",
      "Epoch 295 - loss: 81.49345397949219\n",
      "Epoch 295 - loss: 1.73792564868927\n",
      "Epoch 296 - loss: 4.515570163726807\n",
      "Epoch 296 - loss: 0.13611064851284027\n",
      "Epoch 296 - loss: 46.57870864868164\n",
      "Epoch 297 - loss: 25.247802734375\n",
      "Epoch 297 - loss: 81.10601806640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297 - loss: 1.7712750434875488\n",
      "Epoch 298 - loss: 4.543789386749268\n",
      "Epoch 298 - loss: 0.12075547873973846\n",
      "Epoch 298 - loss: 46.407413482666016\n",
      "Epoch 299 - loss: 25.181373596191406\n",
      "Epoch 299 - loss: 80.72132110595703\n",
      "Epoch 299 - loss: 1.804795265197754\n",
      "when x = tensor([1., 3.]), y = tensor([3.1382], grad_fn=<SqueezeBackward4>)\n",
      "when x = tensor([2., 6.]), y = tensor([6.2764], grad_fn=<SqueezeBackward4>)\n",
      "when x = tensor([3., 9.]), y = tensor([9.4146], grad_fn=<SqueezeBackward4>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f17904d2a90>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2,1,bias=False)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "\n",
    "net.fc1.weight = torch.nn.Parameter(torch.tensor([[1., -1.]], requires_grad=True))\n",
    "\n",
    "print(list(net.parameters()))\n",
    "\n",
    "#input = torch.randn(1,2)\n",
    "#out = net(input)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "#def criterion(out, label):\n",
    "#    return ((label - out)**2).mean()\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
    "\n",
    "\n",
    "data = torch.tensor([[1.,3.], [2.,6.], [3.,9.]], dtype=torch.float)\n",
    "target = torch.tensor([[1.],[5.],[13.]], dtype=torch.float)\n",
    "\n",
    "hist = []\n",
    "\n",
    "############## Batch GD based update ##############       \n",
    "      \n",
    "for epoch in range(300): \n",
    "    for i, (ip,op) in enumerate(zip(data,target)):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(ip)\n",
    "        loss = criterion(outputs, op)\n",
    "        loss.backward()\n",
    "        hist.append(loss.detach())\n",
    "        optimizer.step()\n",
    "        print(\"Epoch {} - loss: {}\".format(epoch, loss))\n",
    "####################################################\n",
    "\n",
    "### Test the trained network ###\n",
    "for i, current_data in enumerate(data):\n",
    "    out = net(current_data)  \n",
    "    print(\"when x = {}, y = {}\".format(current_data, out))\n",
    "    \n",
    "plt.plot(hist, label = \"training curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "functional-booking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=2, out_features=1, bias=False)\n",
      ")\n",
      "[Parameter containing:\n",
      "tensor([[ 1., -1.]], requires_grad=True)]\n",
      "Epoch 0 - loss: 150.3333282470703\n",
      "Epoch 1 - loss: 6.120000839233398\n",
      "Epoch 2 - loss: 36.42483139038086\n",
      "Epoch 3 - loss: 18.104551315307617\n",
      "Epoch 4 - loss: 6.065778732299805\n",
      "Epoch 5 - loss: 10.36883544921875\n",
      "Epoch 6 - loss: 6.2322306632995605\n",
      "Epoch 7 - loss: 5.852260589599609\n",
      "Epoch 8 - loss: 6.088119983673096\n",
      "Epoch 9 - loss: 5.494865417480469\n",
      "Epoch 10 - loss: 5.574592590332031\n",
      "Epoch 11 - loss: 5.536750793457031\n",
      "Epoch 12 - loss: 5.476492404937744\n",
      "Epoch 13 - loss: 5.4938530921936035\n",
      "Epoch 14 - loss: 5.480627536773682\n",
      "Epoch 15 - loss: 5.477013111114502\n",
      "Epoch 16 - loss: 5.478647232055664\n",
      "Epoch 17 - loss: 5.476379871368408\n",
      "Epoch 18 - loss: 5.476480007171631\n",
      "Epoch 19 - loss: 5.4764628410339355\n",
      "Epoch 20 - loss: 5.47619104385376\n",
      "Epoch 21 - loss: 5.476251602172852\n",
      "Epoch 22 - loss: 5.476212978363037\n",
      "Epoch 23 - loss: 5.476190567016602\n",
      "Epoch 24 - loss: 5.476199626922607\n",
      "Epoch 25 - loss: 5.476192474365234\n",
      "Epoch 26 - loss: 5.476190567016602\n",
      "Epoch 27 - loss: 5.476191997528076\n",
      "Epoch 28 - loss: 5.476190090179443\n",
      "Epoch 29 - loss: 5.476190567016602\n",
      "Epoch 30 - loss: 5.476190090179443\n",
      "Epoch 31 - loss: 5.476190567016602\n",
      "Epoch 32 - loss: 5.47619104385376\n",
      "Epoch 33 - loss: 5.476190090179443\n",
      "Epoch 34 - loss: 5.476190090179443\n",
      "Epoch 35 - loss: 5.476190567016602\n",
      "Epoch 36 - loss: 5.476190090179443\n",
      "Epoch 37 - loss: 5.47619104385376\n",
      "Epoch 38 - loss: 5.47619104385376\n",
      "Epoch 39 - loss: 5.476190567016602\n",
      "Epoch 40 - loss: 5.47619104385376\n",
      "Epoch 41 - loss: 5.476188659667969\n",
      "Epoch 42 - loss: 5.476190090179443\n",
      "Epoch 43 - loss: 5.476189136505127\n",
      "Epoch 44 - loss: 5.476190090179443\n",
      "Epoch 45 - loss: 5.476191997528076\n",
      "Epoch 46 - loss: 5.476191997528076\n",
      "Epoch 47 - loss: 5.476190090179443\n",
      "Epoch 48 - loss: 5.476190567016602\n",
      "Epoch 49 - loss: 5.476190567016602\n",
      "Epoch 50 - loss: 5.476190090179443\n",
      "Epoch 51 - loss: 5.47619104385376\n",
      "Epoch 52 - loss: 5.476190567016602\n",
      "Epoch 53 - loss: 5.47619104385376\n",
      "Epoch 54 - loss: 5.47619104385376\n",
      "Epoch 55 - loss: 5.47619104385376\n",
      "Epoch 56 - loss: 5.476190567016602\n",
      "Epoch 57 - loss: 5.47619104385376\n",
      "Epoch 58 - loss: 5.47619104385376\n",
      "Epoch 59 - loss: 5.47619104385376\n",
      "Epoch 60 - loss: 5.476190567016602\n",
      "Epoch 61 - loss: 5.47619104385376\n",
      "Epoch 62 - loss: 5.47619104385376\n",
      "Epoch 63 - loss: 5.47619104385376\n",
      "Epoch 64 - loss: 5.476190567016602\n",
      "Epoch 65 - loss: 5.47619104385376\n",
      "Epoch 66 - loss: 5.47619104385376\n",
      "Epoch 67 - loss: 5.47619104385376\n",
      "Epoch 68 - loss: 5.476190567016602\n",
      "Epoch 69 - loss: 5.47619104385376\n",
      "Epoch 70 - loss: 5.47619104385376\n",
      "Epoch 71 - loss: 5.47619104385376\n",
      "Epoch 72 - loss: 5.476190567016602\n",
      "Epoch 73 - loss: 5.47619104385376\n",
      "Epoch 74 - loss: 5.47619104385376\n",
      "Epoch 75 - loss: 5.47619104385376\n",
      "Epoch 76 - loss: 5.476190567016602\n",
      "Epoch 77 - loss: 5.47619104385376\n",
      "Epoch 78 - loss: 5.47619104385376\n",
      "Epoch 79 - loss: 5.47619104385376\n",
      "Epoch 80 - loss: 5.476190567016602\n",
      "Epoch 81 - loss: 5.47619104385376\n",
      "Epoch 82 - loss: 5.47619104385376\n",
      "Epoch 83 - loss: 5.47619104385376\n",
      "Epoch 84 - loss: 5.476190567016602\n",
      "Epoch 85 - loss: 5.47619104385376\n",
      "Epoch 86 - loss: 5.47619104385376\n",
      "Epoch 87 - loss: 5.47619104385376\n",
      "Epoch 88 - loss: 5.476190567016602\n",
      "Epoch 89 - loss: 5.47619104385376\n",
      "Epoch 90 - loss: 5.47619104385376\n",
      "Epoch 91 - loss: 5.47619104385376\n",
      "Epoch 92 - loss: 5.476190567016602\n",
      "Epoch 93 - loss: 5.47619104385376\n",
      "Epoch 94 - loss: 5.47619104385376\n",
      "Epoch 95 - loss: 5.47619104385376\n",
      "Epoch 96 - loss: 5.476190567016602\n",
      "Epoch 97 - loss: 5.47619104385376\n",
      "Epoch 98 - loss: 5.47619104385376\n",
      "Epoch 99 - loss: 5.47619104385376\n",
      "Epoch 100 - loss: 5.476190567016602\n",
      "Epoch 101 - loss: 5.47619104385376\n",
      "Epoch 102 - loss: 5.47619104385376\n",
      "Epoch 103 - loss: 5.47619104385376\n",
      "Epoch 104 - loss: 5.476190567016602\n",
      "Epoch 105 - loss: 5.47619104385376\n",
      "Epoch 106 - loss: 5.47619104385376\n",
      "Epoch 107 - loss: 5.47619104385376\n",
      "Epoch 108 - loss: 5.476190567016602\n",
      "Epoch 109 - loss: 5.47619104385376\n",
      "Epoch 110 - loss: 5.47619104385376\n",
      "Epoch 111 - loss: 5.47619104385376\n",
      "Epoch 112 - loss: 5.476190567016602\n",
      "Epoch 113 - loss: 5.47619104385376\n",
      "Epoch 114 - loss: 5.47619104385376\n",
      "Epoch 115 - loss: 5.47619104385376\n",
      "Epoch 116 - loss: 5.476190567016602\n",
      "Epoch 117 - loss: 5.47619104385376\n",
      "Epoch 118 - loss: 5.47619104385376\n",
      "Epoch 119 - loss: 5.47619104385376\n",
      "Epoch 120 - loss: 5.476190567016602\n",
      "Epoch 121 - loss: 5.47619104385376\n",
      "Epoch 122 - loss: 5.47619104385376\n",
      "Epoch 123 - loss: 5.47619104385376\n",
      "Epoch 124 - loss: 5.476190567016602\n",
      "Epoch 125 - loss: 5.47619104385376\n",
      "Epoch 126 - loss: 5.47619104385376\n",
      "Epoch 127 - loss: 5.47619104385376\n",
      "Epoch 128 - loss: 5.476190567016602\n",
      "Epoch 129 - loss: 5.47619104385376\n",
      "Epoch 130 - loss: 5.47619104385376\n",
      "Epoch 131 - loss: 5.47619104385376\n",
      "Epoch 132 - loss: 5.476190567016602\n",
      "Epoch 133 - loss: 5.47619104385376\n",
      "Epoch 134 - loss: 5.47619104385376\n",
      "Epoch 135 - loss: 5.47619104385376\n",
      "Epoch 136 - loss: 5.476190567016602\n",
      "Epoch 137 - loss: 5.47619104385376\n",
      "Epoch 138 - loss: 5.47619104385376\n",
      "Epoch 139 - loss: 5.47619104385376\n",
      "Epoch 140 - loss: 5.476190567016602\n",
      "Epoch 141 - loss: 5.47619104385376\n",
      "Epoch 142 - loss: 5.47619104385376\n",
      "Epoch 143 - loss: 5.47619104385376\n",
      "Epoch 144 - loss: 5.476190567016602\n",
      "Epoch 145 - loss: 5.47619104385376\n",
      "Epoch 146 - loss: 5.47619104385376\n",
      "Epoch 147 - loss: 5.47619104385376\n",
      "Epoch 148 - loss: 5.476190567016602\n",
      "Epoch 149 - loss: 5.47619104385376\n",
      "Epoch 150 - loss: 5.47619104385376\n",
      "Epoch 151 - loss: 5.47619104385376\n",
      "Epoch 152 - loss: 5.476190567016602\n",
      "Epoch 153 - loss: 5.47619104385376\n",
      "Epoch 154 - loss: 5.47619104385376\n",
      "Epoch 155 - loss: 5.47619104385376\n",
      "Epoch 156 - loss: 5.476190567016602\n",
      "Epoch 157 - loss: 5.47619104385376\n",
      "Epoch 158 - loss: 5.47619104385376\n",
      "Epoch 159 - loss: 5.47619104385376\n",
      "Epoch 160 - loss: 5.476190567016602\n",
      "Epoch 161 - loss: 5.47619104385376\n",
      "Epoch 162 - loss: 5.47619104385376\n",
      "Epoch 163 - loss: 5.47619104385376\n",
      "Epoch 164 - loss: 5.476190567016602\n",
      "Epoch 165 - loss: 5.47619104385376\n",
      "Epoch 166 - loss: 5.47619104385376\n",
      "Epoch 167 - loss: 5.47619104385376\n",
      "Epoch 168 - loss: 5.476190567016602\n",
      "Epoch 169 - loss: 5.47619104385376\n",
      "Epoch 170 - loss: 5.47619104385376\n",
      "Epoch 171 - loss: 5.47619104385376\n",
      "Epoch 172 - loss: 5.476190567016602\n",
      "Epoch 173 - loss: 5.47619104385376\n",
      "Epoch 174 - loss: 5.47619104385376\n",
      "Epoch 175 - loss: 5.47619104385376\n",
      "Epoch 176 - loss: 5.476190567016602\n",
      "Epoch 177 - loss: 5.47619104385376\n",
      "Epoch 178 - loss: 5.47619104385376\n",
      "Epoch 179 - loss: 5.47619104385376\n",
      "Epoch 180 - loss: 5.476190567016602\n",
      "Epoch 181 - loss: 5.47619104385376\n",
      "Epoch 182 - loss: 5.47619104385376\n",
      "Epoch 183 - loss: 5.47619104385376\n",
      "Epoch 184 - loss: 5.476190567016602\n",
      "Epoch 185 - loss: 5.47619104385376\n",
      "Epoch 186 - loss: 5.47619104385376\n",
      "Epoch 187 - loss: 5.47619104385376\n",
      "Epoch 188 - loss: 5.476190567016602\n",
      "Epoch 189 - loss: 5.47619104385376\n",
      "Epoch 190 - loss: 5.47619104385376\n",
      "Epoch 191 - loss: 5.47619104385376\n",
      "Epoch 192 - loss: 5.476190567016602\n",
      "Epoch 193 - loss: 5.47619104385376\n",
      "Epoch 194 - loss: 5.47619104385376\n",
      "Epoch 195 - loss: 5.47619104385376\n",
      "Epoch 196 - loss: 5.476190567016602\n",
      "Epoch 197 - loss: 5.47619104385376\n",
      "Epoch 198 - loss: 5.47619104385376\n",
      "Epoch 199 - loss: 5.47619104385376\n",
      "Epoch 200 - loss: 5.476190567016602\n",
      "Epoch 201 - loss: 5.47619104385376\n",
      "Epoch 202 - loss: 5.47619104385376\n",
      "Epoch 203 - loss: 5.47619104385376\n",
      "Epoch 204 - loss: 5.476190567016602\n",
      "Epoch 205 - loss: 5.47619104385376\n",
      "Epoch 206 - loss: 5.47619104385376\n",
      "Epoch 207 - loss: 5.47619104385376\n",
      "Epoch 208 - loss: 5.476190567016602\n",
      "Epoch 209 - loss: 5.47619104385376\n",
      "Epoch 210 - loss: 5.47619104385376\n",
      "Epoch 211 - loss: 5.47619104385376\n",
      "Epoch 212 - loss: 5.476190567016602\n",
      "Epoch 213 - loss: 5.47619104385376\n",
      "Epoch 214 - loss: 5.47619104385376\n",
      "Epoch 215 - loss: 5.47619104385376\n",
      "Epoch 216 - loss: 5.476190567016602\n",
      "Epoch 217 - loss: 5.47619104385376\n",
      "Epoch 218 - loss: 5.47619104385376\n",
      "Epoch 219 - loss: 5.47619104385376\n",
      "Epoch 220 - loss: 5.476190567016602\n",
      "Epoch 221 - loss: 5.47619104385376\n",
      "Epoch 222 - loss: 5.47619104385376\n",
      "Epoch 223 - loss: 5.47619104385376\n",
      "Epoch 224 - loss: 5.476190567016602\n",
      "Epoch 225 - loss: 5.47619104385376\n",
      "Epoch 226 - loss: 5.47619104385376\n",
      "Epoch 227 - loss: 5.47619104385376\n",
      "Epoch 228 - loss: 5.476190567016602\n",
      "Epoch 229 - loss: 5.47619104385376\n",
      "Epoch 230 - loss: 5.47619104385376\n",
      "Epoch 231 - loss: 5.47619104385376\n",
      "Epoch 232 - loss: 5.476190567016602\n",
      "Epoch 233 - loss: 5.47619104385376\n",
      "Epoch 234 - loss: 5.47619104385376\n",
      "Epoch 235 - loss: 5.47619104385376\n",
      "Epoch 236 - loss: 5.476190567016602\n",
      "Epoch 237 - loss: 5.47619104385376\n",
      "Epoch 238 - loss: 5.47619104385376\n",
      "Epoch 239 - loss: 5.47619104385376\n",
      "Epoch 240 - loss: 5.476190567016602\n",
      "Epoch 241 - loss: 5.47619104385376\n",
      "Epoch 242 - loss: 5.47619104385376\n",
      "Epoch 243 - loss: 5.47619104385376\n",
      "Epoch 244 - loss: 5.476190567016602\n",
      "Epoch 245 - loss: 5.47619104385376\n",
      "Epoch 246 - loss: 5.47619104385376\n",
      "Epoch 247 - loss: 5.47619104385376\n",
      "Epoch 248 - loss: 5.476190567016602\n",
      "Epoch 249 - loss: 5.47619104385376\n",
      "Epoch 250 - loss: 5.47619104385376\n",
      "Epoch 251 - loss: 5.47619104385376\n",
      "Epoch 252 - loss: 5.476190567016602\n",
      "Epoch 253 - loss: 5.47619104385376\n",
      "Epoch 254 - loss: 5.47619104385376\n",
      "Epoch 255 - loss: 5.47619104385376\n",
      "Epoch 256 - loss: 5.476190567016602\n",
      "Epoch 257 - loss: 5.47619104385376\n",
      "Epoch 258 - loss: 5.47619104385376\n",
      "Epoch 259 - loss: 5.47619104385376\n",
      "Epoch 260 - loss: 5.476190567016602\n",
      "Epoch 261 - loss: 5.47619104385376\n",
      "Epoch 262 - loss: 5.47619104385376\n",
      "Epoch 263 - loss: 5.47619104385376\n",
      "Epoch 264 - loss: 5.476190567016602\n",
      "Epoch 265 - loss: 5.47619104385376\n",
      "Epoch 266 - loss: 5.47619104385376\n",
      "Epoch 267 - loss: 5.47619104385376\n",
      "Epoch 268 - loss: 5.476190567016602\n",
      "Epoch 269 - loss: 5.47619104385376\n",
      "Epoch 270 - loss: 5.47619104385376\n",
      "Epoch 271 - loss: 5.47619104385376\n",
      "Epoch 272 - loss: 5.476190567016602\n",
      "Epoch 273 - loss: 5.47619104385376\n",
      "Epoch 274 - loss: 5.47619104385376\n",
      "Epoch 275 - loss: 5.47619104385376\n",
      "Epoch 276 - loss: 5.476190567016602\n",
      "Epoch 277 - loss: 5.47619104385376\n",
      "Epoch 278 - loss: 5.47619104385376\n",
      "Epoch 279 - loss: 5.47619104385376\n",
      "Epoch 280 - loss: 5.476190567016602\n",
      "Epoch 281 - loss: 5.47619104385376\n",
      "Epoch 282 - loss: 5.47619104385376\n",
      "Epoch 283 - loss: 5.47619104385376\n",
      "Epoch 284 - loss: 5.476190567016602\n",
      "Epoch 285 - loss: 5.47619104385376\n",
      "Epoch 286 - loss: 5.47619104385376\n",
      "Epoch 287 - loss: 5.47619104385376\n",
      "Epoch 288 - loss: 5.476190567016602\n",
      "Epoch 289 - loss: 5.47619104385376\n",
      "Epoch 290 - loss: 5.47619104385376\n",
      "Epoch 291 - loss: 5.47619104385376\n",
      "Epoch 292 - loss: 5.476190567016602\n",
      "Epoch 293 - loss: 5.47619104385376\n",
      "Epoch 294 - loss: 5.47619104385376\n",
      "Epoch 295 - loss: 5.47619104385376\n",
      "Epoch 296 - loss: 5.476190567016602\n",
      "Epoch 297 - loss: 5.47619104385376\n",
      "Epoch 298 - loss: 5.47619104385376\n",
      "Epoch 299 - loss: 5.47619104385376\n",
      "when x = tensor([1., 3.]), y = tensor([3.5714], grad_fn=<SqueezeBackward3>)\n",
      "when x = tensor([2., 6.]), y = tensor([7.1429], grad_fn=<SqueezeBackward3>)\n",
      "when x = tensor([3., 9.]), y = tensor([10.7143], grad_fn=<SqueezeBackward3>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-eeb08814664f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"when x = {}, y = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"training curve\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2838\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2839\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2840\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2841\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1741\u001b[0m         \"\"\"\n\u001b[1;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mindex_of\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1642\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1643\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1644\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVisibleDeprecationWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \u001b[0;31m# NumPy 1.19 will warn on ragged input, and we can't actually use it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_check_1d\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1293\u001b[0m     \u001b[0;34m\"\"\"Convert scalars to 1d arrays; pass-through arrays as is.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36matleast_1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36matleast_1d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevant_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-packet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-survivor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-light",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-aviation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-buyer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
